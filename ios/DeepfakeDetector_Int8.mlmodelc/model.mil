program(1.0)
[buildInfo = dict<tensor<string, []>, tensor<string, []>>({{"coremlc-component-MIL", "3510.2.1"}, {"coremlc-version", "3500.32.1"}})]
{
    func main<ios16>(tensor<fp32, [1, 20, 224, 224, 3]> input_1) {
            tensor<int32, []> model_bidirectional_forward_lstm_PartitionedCall_time = const()[name = tensor<string, []>("model_bidirectional_forward_lstm_PartitionedCall_time"), val = tensor<int32, []>(0)];
            tensor<int32, []> model_bidirectional_forward_lstm_PartitionedCall_TensorArrayV2_1_num_elements = const()[name = tensor<string, []>("model_bidirectional_forward_lstm_PartitionedCall_TensorArrayV2_1_num_elements"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_time_distributed_Reshape_shape = const()[name = tensor<string, []>("model_time_distributed_Reshape_shape"), val = tensor<int32, [4]>([-1, 224, 224, 3])];
            tensor<int32, [3]> model_time_distributed_1_Reshape_1_shape = const()[name = tensor<string, []>("model_time_distributed_1_Reshape_1_shape"), val = tensor<int32, [3]>([-1, 20, 576])];
            tensor<int32, [3]> model_bidirectional_forward_lstm_PartitionedCall_transpose_perm = const()[name = tensor<string, []>("model_bidirectional_forward_lstm_PartitionedCall_transpose_perm"), val = tensor<int32, [3]>([1, 0, 2])];
            tensor<int32, []> model_bidirectional_backward_lstm_PartitionedCall_time = const()[name = tensor<string, []>("model_bidirectional_backward_lstm_PartitionedCall_time"), val = tensor<int32, []>(0)];
            tensor<int32, []> model_bidirectional_backward_lstm_PartitionedCall_TensorArrayV2_1_num_elements = const()[name = tensor<string, []>("model_bidirectional_backward_lstm_PartitionedCall_TensorArrayV2_1_num_elements"), val = tensor<int32, []>(1)];
            tensor<int32, [1]> model_bidirectional_backward_lstm_PartitionedCall_ReverseV2_axis = const()[name = tensor<string, []>("model_bidirectional_backward_lstm_PartitionedCall_ReverseV2_axis"), val = tensor<int32, [1]>([0])];
            tensor<int32, []> model_bidirectional_concat_axis = const()[name = tensor<string, []>("model_bidirectional_concat_axis"), val = tensor<int32, []>(1)];
            tensor<string, []> model_bidirectional_forward_lstm_PartitionedCall_TensorArrayV2_1_dtype_0 = const()[name = tensor<string, []>("model_bidirectional_forward_lstm_PartitionedCall_TensorArrayV2_1_dtype_0"), val = tensor<string, []>("fp32")];
            tensor<bool, []> model_bidirectional_forward_lstm_PartitionedCall_TensorArrayV2_1_dynamic_length_0 = const()[name = tensor<string, []>("model_bidirectional_forward_lstm_PartitionedCall_TensorArrayV2_1_dynamic_length_0"), val = tensor<bool, []>(false)];
            tensor<int32, []> model_bidirectional_forward_lstm_PartitionedCall_TensorArrayV2_1_elem_shape0_0 = const()[name = tensor<string, []>("model_bidirectional_forward_lstm_PartitionedCall_TensorArrayV2_1_elem_shape0_0"), val = tensor<int32, []>(1)];
            tensor<int32, []> model_bidirectional_forward_lstm_PartitionedCall_TensorArrayV2_1_elem_shape1_0 = const()[name = tensor<string, []>("model_bidirectional_forward_lstm_PartitionedCall_TensorArrayV2_1_elem_shape1_0"), val = tensor<int32, []>(64)];
            list<tensor<fp32, [1, 64]>, 1> model_bidirectional_forward_lstm_PartitionedCall_TensorArrayV2_1 = make_list(dtype = model_bidirectional_forward_lstm_PartitionedCall_TensorArrayV2_1_dtype_0, dynamic_length = model_bidirectional_forward_lstm_PartitionedCall_TensorArrayV2_1_dynamic_length_0, elem_shape = (model_bidirectional_forward_lstm_PartitionedCall_TensorArrayV2_1_elem_shape0_0, model_bidirectional_forward_lstm_PartitionedCall_TensorArrayV2_1_elem_shape1_0), init_length = model_bidirectional_forward_lstm_PartitionedCall_TensorArrayV2_1_num_elements)[name = tensor<string, []>("model_bidirectional_forward_lstm_PartitionedCall_TensorArrayV2_1")];
            tensor<string, []> input_1_to_fp16_dtype_0 = const()[name = tensor<string, []>("input_1_to_fp16_dtype_0"), val = tensor<string, []>("fp16")];
            tensor<fp16, [1, 20, 224, 224, 3]> cast_53 = cast(dtype = input_1_to_fp16_dtype_0, x = input_1)[name = tensor<string, []>("cast_15")];
            tensor<fp16, [20, 224, 224, 3]> model_time_distributed_Reshape_cast_fp16 = reshape(shape = model_time_distributed_Reshape_shape, x = cast_53)[name = tensor<string, []>("model_time_distributed_Reshape_cast_fp16")];
            tensor<string, []> model_bidirectional_backward_lstm_PartitionedCall_TensorArrayV2_1_dtype_0 = const()[name = tensor<string, []>("model_bidirectional_backward_lstm_PartitionedCall_TensorArrayV2_1_dtype_0"), val = tensor<string, []>("fp32")];
            tensor<bool, []> model_bidirectional_backward_lstm_PartitionedCall_TensorArrayV2_1_dynamic_length_0 = const()[name = tensor<string, []>("model_bidirectional_backward_lstm_PartitionedCall_TensorArrayV2_1_dynamic_length_0"), val = tensor<bool, []>(false)];
            tensor<int32, []> model_bidirectional_backward_lstm_PartitionedCall_TensorArrayV2_1_elem_shape0_0 = const()[name = tensor<string, []>("model_bidirectional_backward_lstm_PartitionedCall_TensorArrayV2_1_elem_shape0_0"), val = tensor<int32, []>(1)];
            tensor<int32, []> model_bidirectional_backward_lstm_PartitionedCall_TensorArrayV2_1_elem_shape1_0 = const()[name = tensor<string, []>("model_bidirectional_backward_lstm_PartitionedCall_TensorArrayV2_1_elem_shape1_0"), val = tensor<int32, []>(64)];
            list<tensor<fp32, [1, 64]>, 1> model_bidirectional_backward_lstm_PartitionedCall_TensorArrayV2_1 = make_list(dtype = model_bidirectional_backward_lstm_PartitionedCall_TensorArrayV2_1_dtype_0, dynamic_length = model_bidirectional_backward_lstm_PartitionedCall_TensorArrayV2_1_dynamic_length_0, elem_shape = (model_bidirectional_backward_lstm_PartitionedCall_TensorArrayV2_1_elem_shape0_0, model_bidirectional_backward_lstm_PartitionedCall_TensorArrayV2_1_elem_shape1_0), init_length = model_bidirectional_backward_lstm_PartitionedCall_TensorArrayV2_1_num_elements)[name = tensor<string, []>("model_bidirectional_backward_lstm_PartitionedCall_TensorArrayV2_1")];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_rescaling_Cast_x_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_rescaling_Cast_x_to_fp16"), val = tensor<fp16, []>(0x1.01p-7)];
            tensor<fp16, [20, 224, 224, 3]> model_time_distributed_MobilenetV3small_rescaling_mul_cast_fp16 = mul(x = model_time_distributed_Reshape_cast_fp16, y = model_time_distributed_MobilenetV3small_rescaling_Cast_x_to_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_rescaling_mul_cast_fp16")];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_rescaling_Cast_1_x_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_rescaling_Cast_1_x_to_fp16"), val = tensor<fp16, []>(-0x1p+0)];
            tensor<fp16, [20, 224, 224, 3]> model_time_distributed_MobilenetV3small_rescaling_add_cast_fp16 = add(x = model_time_distributed_MobilenetV3small_rescaling_mul_cast_fp16, y = model_time_distributed_MobilenetV3small_rescaling_Cast_1_x_to_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_rescaling_add_cast_fp16")];
            tensor<int32, [4]> transpose_1_perm_0 = const()[name = tensor<string, []>("transpose_1_perm_0"), val = tensor<int32, [4]>([0, 3, 1, 2])];
            tensor<string, []> model_time_distributed_MobilenetV3small_Conv_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_Conv_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_Conv_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_Conv_Conv2Dx_strides_0"), val = tensor<int32, [2]>([2, 2])];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_Conv_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_Conv_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_time_distributed_MobilenetV3small_Conv_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_Conv_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_Conv_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_Conv_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 3, 3, 3]> const_4 = const()[name = tensor<string, []>("const_4"), val = tensor<fp16, [16, 3, 3, 3]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(64)))];
            tensor<fp16, [16]> const_5 = const()[name = tensor<string, []>("const_5"), val = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(1024)))];
            tensor<fp16, [20, 3, 224, 224]> transpose_280 = transpose(perm = transpose_1_perm_0, x = model_time_distributed_MobilenetV3small_rescaling_add_cast_fp16)[name = tensor<string, []>("transpose_102")];
            tensor<fp16, [20, 16, 112, 112]> model_time_distributed_MobilenetV3small_Conv_BatchNorm_FusedBatchNormV3_nchw_cast_fp16 = conv(bias = const_5, dilations = model_time_distributed_MobilenetV3small_Conv_Conv2Dx_dilations_0, groups = model_time_distributed_MobilenetV3small_Conv_Conv2Dx_groups_0, pad = model_time_distributed_MobilenetV3small_Conv_Conv2Dx_pad_0, pad_type = model_time_distributed_MobilenetV3small_Conv_Conv2Dx_pad_type_0, strides = model_time_distributed_MobilenetV3small_Conv_Conv2Dx_strides_0, weight = const_4, x = transpose_280)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_Conv_BatchNorm_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_Conv_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_Conv_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0"), val = tensor<int32, [4]>([0, 2, 3, 1])];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_tf_math_add_Add_y_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_add_Add_y_to_fp16"), val = tensor<fp16, []>(0x1.8p+1)];
            tensor<fp16, [20, 112, 112, 16]> transpose_279 = transpose(perm = model_time_distributed_MobilenetV3small_Conv_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0, x = model_time_distributed_MobilenetV3small_Conv_BatchNorm_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("transpose_101")];
            tensor<fp16, [20, 112, 112, 16]> model_time_distributed_MobilenetV3small_tf_math_add_Add_cast_fp16 = add(x = transpose_279, y = model_time_distributed_MobilenetV3small_tf_math_add_Add_y_to_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_add_Add_cast_fp16")];
            tensor<fp16, [20, 112, 112, 16]> model_time_distributed_MobilenetV3small_re_lu_Relu6_cast_fp16 = relu6(x = model_time_distributed_MobilenetV3small_tf_math_add_Add_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_re_lu_Relu6_cast_fp16")];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_tf_math_multiply_Mul_y_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_multiply_Mul_y_to_fp16"), val = tensor<fp16, []>(0x1.554p-3)];
            tensor<fp16, [20, 112, 112, 16]> model_time_distributed_MobilenetV3small_tf_math_multiply_Mul_cast_fp16 = mul(x = model_time_distributed_MobilenetV3small_re_lu_Relu6_cast_fp16, y = model_time_distributed_MobilenetV3small_tf_math_multiply_Mul_y_to_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_multiply_Mul_cast_fp16")];
            tensor<fp16, [20, 112, 112, 16]> model_time_distributed_MobilenetV3small_multiply_mul_cast_fp16 = mul(x = transpose_279, y = model_time_distributed_MobilenetV3small_tf_math_multiply_Mul_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_multiply_mul_cast_fp16")];
            tensor<string, []> pad_0_mode_0 = const()[name = tensor<string, []>("pad_0_mode_0"), val = tensor<string, []>("constant")];
            tensor<int32, [4]> transpose_139_perm_0 = const()[name = tensor<string, []>("transpose_139_perm_0"), val = tensor<int32, [4]>([0, 3, 1, 2])];
            tensor<int32, [8]> pad_4_pad_0 = const()[name = tensor<string, []>("pad_4_pad_0"), val = tensor<int32, [8]>([0, 0, 0, 0, 0, 1, 0, 1])];
            tensor<fp16, []> const_0_to_fp16 = const()[name = tensor<string, []>("const_0_to_fp16"), val = tensor<fp16, []>(0x0p+0)];
            tensor<fp16, [20, 16, 112, 112]> transpose_278 = transpose(perm = transpose_139_perm_0, x = model_time_distributed_MobilenetV3small_multiply_mul_cast_fp16)[name = tensor<string, []>("transpose_100")];
            tensor<fp16, [20, 16, 113, 113]> pad_4_cast_fp16 = pad(constant_val = const_0_to_fp16, mode = pad_0_mode_0, pad = pad_4_pad_0, x = transpose_278)[name = tensor<string, []>("pad_4_cast_fp16")];
            tensor<string, []> model_time_distributed_MobilenetV3small_expanded_conv_depthwise_depthwisex_pad_type_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_depthwise_depthwisex_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_depthwise_depthwisex_strides_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_depthwise_depthwisex_strides_0"), val = tensor<int32, [2]>([2, 2])];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_depthwise_depthwisex_dilations_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_depthwise_depthwisex_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_time_distributed_MobilenetV3small_expanded_conv_depthwise_depthwisex_groups_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_depthwise_depthwisex_groups_0"), val = tensor<int32, []>(16)];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_depthwise_depthwisex_pad_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_depthwise_depthwisex_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 1, 3, 3]> const_6 = const()[name = tensor<string, []>("const_6"), val = tensor<fp16, [16, 1, 3, 3]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(1152)))];
            tensor<fp16, [16]> const_7 = const()[name = tensor<string, []>("const_7"), val = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(1536)))];
            tensor<fp16, [20, 16, 56, 56]> model_time_distributed_MobilenetV3small_expanded_conv_depthwise_BatchNorm_FusedBatchNormV3_nchw_cast_fp16 = conv(bias = const_7, dilations = model_time_distributed_MobilenetV3small_expanded_conv_depthwise_depthwisex_dilations_0, groups = model_time_distributed_MobilenetV3small_expanded_conv_depthwise_depthwisex_groups_0, pad = model_time_distributed_MobilenetV3small_expanded_conv_depthwise_depthwisex_pad_0, pad_type = model_time_distributed_MobilenetV3small_expanded_conv_depthwise_depthwisex_pad_type_0, strides = model_time_distributed_MobilenetV3small_expanded_conv_depthwise_depthwisex_strides_0, weight = const_6, x = pad_4_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_depthwise_BatchNorm_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_depthwise_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_depthwise_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0"), val = tensor<int32, [4]>([0, 2, 3, 1])];
            tensor<fp16, [20, 56, 56, 16]> transpose_277 = transpose(perm = model_time_distributed_MobilenetV3small_expanded_conv_depthwise_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_depthwise_BatchNorm_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("transpose_99")];
            tensor<fp16, [20, 56, 56, 16]> model_time_distributed_MobilenetV3small_re_lu_1_Relu_cast_fp16 = relu(x = transpose_277)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_re_lu_1_Relu_cast_fp16")];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_squeeze_excite_AvgPool_Mean_axes_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_squeeze_excite_AvgPool_Mean_axes_0"), val = tensor<int32, [2]>([1, 2])];
            tensor<bool, []> model_time_distributed_MobilenetV3small_expanded_conv_squeeze_excite_AvgPool_Mean_keep_dims_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_squeeze_excite_AvgPool_Mean_keep_dims_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [20, 1, 1, 16]> model_time_distributed_MobilenetV3small_expanded_conv_squeeze_excite_AvgPool_Mean_cast_fp16 = reduce_mean(axes = model_time_distributed_MobilenetV3small_expanded_conv_squeeze_excite_AvgPool_Mean_axes_0, keep_dims = model_time_distributed_MobilenetV3small_expanded_conv_squeeze_excite_AvgPool_Mean_keep_dims_0, x = model_time_distributed_MobilenetV3small_re_lu_1_Relu_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_squeeze_excite_AvgPool_Mean_cast_fp16")];
            tensor<int32, [4]> transpose_7_perm_0 = const()[name = tensor<string, []>("transpose_7_perm_0"), val = tensor<int32, [4]>([0, 3, 1, 2])];
            tensor<string, []> model_time_distributed_MobilenetV3small_expanded_conv_squeeze_excite_Conv_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_squeeze_excite_Conv_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_squeeze_excite_Conv_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_squeeze_excite_Conv_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_squeeze_excite_Conv_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_squeeze_excite_Conv_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_time_distributed_MobilenetV3small_expanded_conv_squeeze_excite_Conv_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_squeeze_excite_Conv_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_squeeze_excite_Conv_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_squeeze_excite_Conv_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [8, 16, 1, 1]> conv_0_weight_0_to_fp16 = const()[name = tensor<string, []>("conv_0_weight_0_to_fp16"), val = tensor<fp16, [8, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(1664)))];
            tensor<fp16, [8]> conv_0_bias_0_to_fp16 = const()[name = tensor<string, []>("conv_0_bias_0_to_fp16"), val = tensor<fp16, [8]>([0x1.53p-1, -0x1.618p+0, 0x1.e78p-3, 0x1.7bp+1, -0x1.7e8p+0, -0x1.1f4p+1, 0x1.59cp+1, 0x1.91cp+0])];
            tensor<fp16, [20, 16, 1, 1]> transpose_276 = transpose(perm = transpose_7_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_squeeze_excite_AvgPool_Mean_cast_fp16)[name = tensor<string, []>("transpose_98")];
            tensor<fp16, [20, 8, 1, 1]> conv_0_cast_fp16 = conv(bias = conv_0_bias_0_to_fp16, dilations = model_time_distributed_MobilenetV3small_expanded_conv_squeeze_excite_Conv_Conv2Dx_dilations_0, groups = model_time_distributed_MobilenetV3small_expanded_conv_squeeze_excite_Conv_Conv2Dx_groups_0, pad = model_time_distributed_MobilenetV3small_expanded_conv_squeeze_excite_Conv_Conv2Dx_pad_0, pad_type = model_time_distributed_MobilenetV3small_expanded_conv_squeeze_excite_Conv_Conv2Dx_pad_type_0, strides = model_time_distributed_MobilenetV3small_expanded_conv_squeeze_excite_Conv_Conv2Dx_strides_0, weight = conv_0_weight_0_to_fp16, x = transpose_276)[name = tensor<string, []>("conv_0_cast_fp16")];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_squeeze_excite_Conv_Conv2D_perm_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_squeeze_excite_Conv_Conv2D_perm_0"), val = tensor<int32, [4]>([0, 2, 3, 1])];
            tensor<fp16, [20, 1, 1, 8]> transpose_275 = transpose(perm = model_time_distributed_MobilenetV3small_expanded_conv_squeeze_excite_Conv_Conv2D_perm_0, x = conv_0_cast_fp16)[name = tensor<string, []>("transpose_97")];
            tensor<fp16, [20, 1, 1, 8]> model_time_distributed_MobilenetV3small_expanded_conv_squeeze_excite_Relu_Relu_cast_fp16 = relu(x = transpose_275)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_squeeze_excite_Relu_Relu_cast_fp16")];
            tensor<int32, [4]> transpose_9_perm_0 = const()[name = tensor<string, []>("transpose_9_perm_0"), val = tensor<int32, [4]>([0, 3, 1, 2])];
            tensor<string, []> model_time_distributed_MobilenetV3small_expanded_conv_squeeze_excite_Conv_1_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_squeeze_excite_Conv_1_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_squeeze_excite_Conv_1_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_squeeze_excite_Conv_1_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_squeeze_excite_Conv_1_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_squeeze_excite_Conv_1_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_time_distributed_MobilenetV3small_expanded_conv_squeeze_excite_Conv_1_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_squeeze_excite_Conv_1_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_squeeze_excite_Conv_1_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_squeeze_excite_Conv_1_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 8, 1, 1]> conv_18_weight_0_to_fp16 = const()[name = tensor<string, []>("conv_18_weight_0_to_fp16"), val = tensor<fp16, [16, 8, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(1984)))];
            tensor<fp16, [16]> conv_18_bias_0_to_fp16 = const()[name = tensor<string, []>("conv_18_bias_0_to_fp16"), val = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(2304)))];
            tensor<fp16, [20, 8, 1, 1]> transpose_274 = transpose(perm = transpose_9_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_squeeze_excite_Relu_Relu_cast_fp16)[name = tensor<string, []>("transpose_96")];
            tensor<fp16, [20, 16, 1, 1]> conv_18_cast_fp16 = conv(bias = conv_18_bias_0_to_fp16, dilations = model_time_distributed_MobilenetV3small_expanded_conv_squeeze_excite_Conv_1_Conv2Dx_dilations_0, groups = model_time_distributed_MobilenetV3small_expanded_conv_squeeze_excite_Conv_1_Conv2Dx_groups_0, pad = model_time_distributed_MobilenetV3small_expanded_conv_squeeze_excite_Conv_1_Conv2Dx_pad_0, pad_type = model_time_distributed_MobilenetV3small_expanded_conv_squeeze_excite_Conv_1_Conv2Dx_pad_type_0, strides = model_time_distributed_MobilenetV3small_expanded_conv_squeeze_excite_Conv_1_Conv2Dx_strides_0, weight = conv_18_weight_0_to_fp16, x = transpose_274)[name = tensor<string, []>("conv_18_cast_fp16")];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_squeeze_excite_Conv_1_Conv2D_perm_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_squeeze_excite_Conv_1_Conv2D_perm_0"), val = tensor<int32, [4]>([0, 2, 3, 1])];
            tensor<fp16, [20, 1, 1, 16]> transpose_273 = transpose(perm = model_time_distributed_MobilenetV3small_expanded_conv_squeeze_excite_Conv_1_Conv2D_perm_0, x = conv_18_cast_fp16)[name = tensor<string, []>("transpose_95")];
            tensor<fp16, [20, 1, 1, 16]> model_time_distributed_MobilenetV3small_re_lu_2_Relu6_cast_fp16 = relu6(x = transpose_273)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_re_lu_2_Relu6_cast_fp16")];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_tf_math_multiply_1_Mul_y_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_multiply_1_Mul_y_to_fp16"), val = tensor<fp16, []>(0x1.554p-3)];
            tensor<fp16, [20, 1, 1, 16]> model_time_distributed_MobilenetV3small_tf_math_multiply_1_Mul_cast_fp16 = mul(x = model_time_distributed_MobilenetV3small_re_lu_2_Relu6_cast_fp16, y = model_time_distributed_MobilenetV3small_tf_math_multiply_1_Mul_y_to_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_multiply_1_Mul_cast_fp16")];
            tensor<fp16, [20, 56, 56, 16]> model_time_distributed_MobilenetV3small_expanded_conv_squeeze_excite_Mul_mul_cast_fp16 = mul(x = model_time_distributed_MobilenetV3small_re_lu_1_Relu_cast_fp16, y = model_time_distributed_MobilenetV3small_tf_math_multiply_1_Mul_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_squeeze_excite_Mul_mul_cast_fp16")];
            tensor<int32, [4]> transpose_11_perm_0 = const()[name = tensor<string, []>("transpose_11_perm_0"), val = tensor<int32, [4]>([0, 3, 1, 2])];
            tensor<string, []> model_time_distributed_MobilenetV3small_expanded_conv_project_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_project_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_project_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_project_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_project_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_project_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_time_distributed_MobilenetV3small_expanded_conv_project_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_project_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_project_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_project_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [16, 16, 1, 1]> const_8 = const()[name = tensor<string, []>("const_8"), val = tensor<fp16, [16, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(2432)))];
            tensor<fp16, [16]> const_9 = const()[name = tensor<string, []>("const_9"), val = tensor<fp16, [16]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(3008)))];
            tensor<fp16, [20, 16, 56, 56]> transpose_272 = transpose(perm = transpose_11_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_squeeze_excite_Mul_mul_cast_fp16)[name = tensor<string, []>("transpose_94")];
            tensor<fp16, [20, 16, 56, 56]> model_time_distributed_MobilenetV3small_expanded_conv_project_BatchNorm_FusedBatchNormV3_nchw_cast_fp16 = conv(bias = const_9, dilations = model_time_distributed_MobilenetV3small_expanded_conv_project_Conv2Dx_dilations_0, groups = model_time_distributed_MobilenetV3small_expanded_conv_project_Conv2Dx_groups_0, pad = model_time_distributed_MobilenetV3small_expanded_conv_project_Conv2Dx_pad_0, pad_type = model_time_distributed_MobilenetV3small_expanded_conv_project_Conv2Dx_pad_type_0, strides = model_time_distributed_MobilenetV3small_expanded_conv_project_Conv2Dx_strides_0, weight = const_8, x = transpose_272)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_project_BatchNorm_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<string, []> model_time_distributed_MobilenetV3small_expanded_conv_1_expand_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_1_expand_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_1_expand_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_1_expand_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_1_expand_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_1_expand_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_time_distributed_MobilenetV3small_expanded_conv_1_expand_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_1_expand_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_1_expand_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_1_expand_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [72, 16, 1, 1]> const_10 = const()[name = tensor<string, []>("const_10"), val = tensor<fp16, [72, 16, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(3136)))];
            tensor<fp16, [72]> const_11 = const()[name = tensor<string, []>("const_11"), val = tensor<fp16, [72]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(5504)))];
            tensor<fp16, [20, 72, 56, 56]> model_time_distributed_MobilenetV3small_expanded_conv_1_expand_BatchNorm_FusedBatchNormV3_nchw_cast_fp16 = conv(bias = const_11, dilations = model_time_distributed_MobilenetV3small_expanded_conv_1_expand_Conv2Dx_dilations_0, groups = model_time_distributed_MobilenetV3small_expanded_conv_1_expand_Conv2Dx_groups_0, pad = model_time_distributed_MobilenetV3small_expanded_conv_1_expand_Conv2Dx_pad_0, pad_type = model_time_distributed_MobilenetV3small_expanded_conv_1_expand_Conv2Dx_pad_type_0, strides = model_time_distributed_MobilenetV3small_expanded_conv_1_expand_Conv2Dx_strides_0, weight = const_10, x = model_time_distributed_MobilenetV3small_expanded_conv_project_BatchNorm_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_1_expand_BatchNorm_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_1_expand_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_1_expand_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0"), val = tensor<int32, [4]>([0, 2, 3, 1])];
            tensor<fp16, [20, 56, 56, 72]> transpose_271 = transpose(perm = model_time_distributed_MobilenetV3small_expanded_conv_1_expand_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_1_expand_BatchNorm_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("transpose_93")];
            tensor<fp16, [20, 56, 56, 72]> model_time_distributed_MobilenetV3small_re_lu_3_Relu_cast_fp16 = relu(x = transpose_271)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_re_lu_3_Relu_cast_fp16")];
            tensor<string, []> pad_1_mode_0 = const()[name = tensor<string, []>("pad_1_mode_0"), val = tensor<string, []>("constant")];
            tensor<int32, [4]> transpose_140_perm_0 = const()[name = tensor<string, []>("transpose_140_perm_0"), val = tensor<int32, [4]>([0, 3, 1, 2])];
            tensor<int32, [8]> pad_5_pad_0 = const()[name = tensor<string, []>("pad_5_pad_0"), val = tensor<int32, [8]>([0, 0, 0, 0, 0, 1, 0, 1])];
            tensor<fp16, []> const_1_to_fp16 = const()[name = tensor<string, []>("const_1_to_fp16"), val = tensor<fp16, []>(0x0p+0)];
            tensor<fp16, [20, 72, 56, 56]> transpose_270 = transpose(perm = transpose_140_perm_0, x = model_time_distributed_MobilenetV3small_re_lu_3_Relu_cast_fp16)[name = tensor<string, []>("transpose_92")];
            tensor<fp16, [20, 72, 57, 57]> pad_5_cast_fp16 = pad(constant_val = const_1_to_fp16, mode = pad_1_mode_0, pad = pad_5_pad_0, x = transpose_270)[name = tensor<string, []>("pad_5_cast_fp16")];
            tensor<string, []> model_time_distributed_MobilenetV3small_expanded_conv_1_depthwise_depthwisex_pad_type_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_1_depthwise_depthwisex_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_1_depthwise_depthwisex_strides_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_1_depthwise_depthwisex_strides_0"), val = tensor<int32, [2]>([2, 2])];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_1_depthwise_depthwisex_dilations_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_1_depthwise_depthwisex_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_time_distributed_MobilenetV3small_expanded_conv_1_depthwise_depthwisex_groups_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_1_depthwise_depthwisex_groups_0"), val = tensor<int32, []>(72)];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_1_depthwise_depthwisex_pad_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_1_depthwise_depthwisex_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [72, 1, 3, 3]> const_12 = const()[name = tensor<string, []>("const_12"), val = tensor<fp16, [72, 1, 3, 3]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(5760)))];
            tensor<fp16, [72]> const_13 = const()[name = tensor<string, []>("const_13"), val = tensor<fp16, [72]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(7168)))];
            tensor<fp16, [20, 72, 28, 28]> model_time_distributed_MobilenetV3small_expanded_conv_1_depthwise_BatchNorm_FusedBatchNormV3_nchw_cast_fp16 = conv(bias = const_13, dilations = model_time_distributed_MobilenetV3small_expanded_conv_1_depthwise_depthwisex_dilations_0, groups = model_time_distributed_MobilenetV3small_expanded_conv_1_depthwise_depthwisex_groups_0, pad = model_time_distributed_MobilenetV3small_expanded_conv_1_depthwise_depthwisex_pad_0, pad_type = model_time_distributed_MobilenetV3small_expanded_conv_1_depthwise_depthwisex_pad_type_0, strides = model_time_distributed_MobilenetV3small_expanded_conv_1_depthwise_depthwisex_strides_0, weight = const_12, x = pad_5_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_1_depthwise_BatchNorm_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_1_depthwise_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_1_depthwise_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0"), val = tensor<int32, [4]>([0, 2, 3, 1])];
            tensor<fp16, [20, 28, 28, 72]> transpose_269 = transpose(perm = model_time_distributed_MobilenetV3small_expanded_conv_1_depthwise_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_1_depthwise_BatchNorm_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("transpose_91")];
            tensor<fp16, [20, 28, 28, 72]> model_time_distributed_MobilenetV3small_re_lu_4_Relu_cast_fp16 = relu(x = transpose_269)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_re_lu_4_Relu_cast_fp16")];
            tensor<int32, [4]> transpose_20_perm_0 = const()[name = tensor<string, []>("transpose_20_perm_0"), val = tensor<int32, [4]>([0, 3, 1, 2])];
            tensor<string, []> model_time_distributed_MobilenetV3small_expanded_conv_1_project_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_1_project_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_1_project_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_1_project_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_1_project_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_1_project_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_time_distributed_MobilenetV3small_expanded_conv_1_project_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_1_project_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_1_project_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_1_project_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [24, 72, 1, 1]> const_14 = const()[name = tensor<string, []>("const_14"), val = tensor<fp16, [24, 72, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(7424)))];
            tensor<fp16, [24]> const_15 = const()[name = tensor<string, []>("const_15"), val = tensor<fp16, [24]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(10944)))];
            tensor<fp16, [20, 72, 28, 28]> transpose_268 = transpose(perm = transpose_20_perm_0, x = model_time_distributed_MobilenetV3small_re_lu_4_Relu_cast_fp16)[name = tensor<string, []>("transpose_90")];
            tensor<fp16, [20, 24, 28, 28]> model_time_distributed_MobilenetV3small_expanded_conv_1_project_BatchNorm_FusedBatchNormV3_nchw_cast_fp16 = conv(bias = const_15, dilations = model_time_distributed_MobilenetV3small_expanded_conv_1_project_Conv2Dx_dilations_0, groups = model_time_distributed_MobilenetV3small_expanded_conv_1_project_Conv2Dx_groups_0, pad = model_time_distributed_MobilenetV3small_expanded_conv_1_project_Conv2Dx_pad_0, pad_type = model_time_distributed_MobilenetV3small_expanded_conv_1_project_Conv2Dx_pad_type_0, strides = model_time_distributed_MobilenetV3small_expanded_conv_1_project_Conv2Dx_strides_0, weight = const_14, x = transpose_268)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_1_project_BatchNorm_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_1_project_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_1_project_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0"), val = tensor<int32, [4]>([0, 2, 3, 1])];
            tensor<int32, [4]> transpose_23_perm_0 = const()[name = tensor<string, []>("transpose_23_perm_0"), val = tensor<int32, [4]>([0, 3, 1, 2])];
            tensor<string, []> model_time_distributed_MobilenetV3small_expanded_conv_2_expand_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_2_expand_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_2_expand_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_2_expand_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_2_expand_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_2_expand_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_time_distributed_MobilenetV3small_expanded_conv_2_expand_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_2_expand_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_2_expand_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_2_expand_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [88, 24, 1, 1]> transpose_22_to_fp16_quantized = constexpr_affine_dequantize()[axis = tensor<int32, []>(0), name = tensor<string, []>("transpose_22_to_fp16_quantized"), quantized_data = tensor<int8, [88, 24, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(11072))), scale = tensor<fp16, [88]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(13440))), zero_point = tensor<int8, [88]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(13248)))];
            tensor<fp16, [20, 28, 28, 24]> transpose_267 = transpose(perm = model_time_distributed_MobilenetV3small_expanded_conv_1_project_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_1_project_BatchNorm_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("transpose_89")];
            tensor<fp16, [20, 24, 28, 28]> transpose_266 = transpose(perm = transpose_23_perm_0, x = transpose_267)[name = tensor<string, []>("transpose_88")];
            tensor<fp16, [20, 88, 28, 28]> model_time_distributed_MobilenetV3small_expanded_conv_2_expand_Conv2Dx_cast_fp16 = conv(dilations = model_time_distributed_MobilenetV3small_expanded_conv_2_expand_Conv2Dx_dilations_0, groups = model_time_distributed_MobilenetV3small_expanded_conv_2_expand_Conv2Dx_groups_0, pad = model_time_distributed_MobilenetV3small_expanded_conv_2_expand_Conv2Dx_pad_0, pad_type = model_time_distributed_MobilenetV3small_expanded_conv_2_expand_Conv2Dx_pad_type_0, strides = model_time_distributed_MobilenetV3small_expanded_conv_2_expand_Conv2Dx_strides_0, weight = transpose_22_to_fp16_quantized, x = transpose_266)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_2_expand_Conv2Dx_cast_fp16")];
            tensor<fp16, [88]> model_time_distributed_MobilenetV3small_expanded_conv_2_expand_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_2_expand_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16"), val = tensor<fp16, [88]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(13696)))];
            tensor<fp16, [88]> model_time_distributed_MobilenetV3small_expanded_conv_2_expand_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_2_expand_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16"), val = tensor<fp16, [88]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(13952)))];
            tensor<fp16, [88]> model_time_distributed_MobilenetV3small_expanded_conv_2_expand_BatchNorm_ReadVariableOp_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_2_expand_BatchNorm_ReadVariableOp_to_fp16"), val = tensor<fp16, [88]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(14208)))];
            tensor<fp16, [88]> model_time_distributed_MobilenetV3small_expanded_conv_2_expand_BatchNorm_ReadVariableOp_1_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_2_expand_BatchNorm_ReadVariableOp_1_to_fp16"), val = tensor<fp16, [88]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(14464)))];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_expanded_conv_2_expand_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_2_expand_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.064p-10)];
            tensor<fp16, [20, 88, 28, 28]> model_time_distributed_MobilenetV3small_expanded_conv_2_expand_BatchNorm_FusedBatchNormV3_nchw_cast_fp16 = batch_norm(beta = model_time_distributed_MobilenetV3small_expanded_conv_2_expand_BatchNorm_ReadVariableOp_1_to_fp16, epsilon = model_time_distributed_MobilenetV3small_expanded_conv_2_expand_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16, gamma = model_time_distributed_MobilenetV3small_expanded_conv_2_expand_BatchNorm_ReadVariableOp_to_fp16, mean = model_time_distributed_MobilenetV3small_expanded_conv_2_expand_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16, variance = model_time_distributed_MobilenetV3small_expanded_conv_2_expand_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16, x = model_time_distributed_MobilenetV3small_expanded_conv_2_expand_Conv2Dx_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_2_expand_BatchNorm_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_2_expand_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_2_expand_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0"), val = tensor<int32, [4]>([0, 2, 3, 1])];
            tensor<fp16, [20, 28, 28, 88]> transpose_265 = transpose(perm = model_time_distributed_MobilenetV3small_expanded_conv_2_expand_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_2_expand_BatchNorm_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("transpose_87")];
            tensor<fp16, [20, 28, 28, 88]> model_time_distributed_MobilenetV3small_re_lu_5_Relu_cast_fp16 = relu(x = transpose_265)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_re_lu_5_Relu_cast_fp16")];
            tensor<int32, [4]> transpose_26_perm_0 = const()[name = tensor<string, []>("transpose_26_perm_0"), val = tensor<int32, [4]>([0, 3, 1, 2])];
            tensor<string, []> model_time_distributed_MobilenetV3small_expanded_conv_2_depthwise_depthwisex_pad_type_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_2_depthwise_depthwisex_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_2_depthwise_depthwisex_strides_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_2_depthwise_depthwisex_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_2_depthwise_depthwisex_dilations_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_2_depthwise_depthwisex_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_time_distributed_MobilenetV3small_expanded_conv_2_depthwise_depthwisex_groups_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_2_depthwise_depthwisex_groups_0"), val = tensor<int32, []>(88)];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_2_depthwise_depthwisex_pad_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_2_depthwise_depthwisex_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [88, 1, 3, 3]> const_16 = const()[name = tensor<string, []>("const_16"), val = tensor<fp16, [88, 1, 3, 3]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(14720)))];
            tensor<fp16, [88]> const_17 = const()[name = tensor<string, []>("const_17"), val = tensor<fp16, [88]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(16384)))];
            tensor<fp16, [20, 88, 28, 28]> transpose_264 = transpose(perm = transpose_26_perm_0, x = model_time_distributed_MobilenetV3small_re_lu_5_Relu_cast_fp16)[name = tensor<string, []>("transpose_86")];
            tensor<fp16, [20, 88, 28, 28]> model_time_distributed_MobilenetV3small_expanded_conv_2_depthwise_BatchNorm_FusedBatchNormV3_nchw_cast_fp16 = conv(bias = const_17, dilations = model_time_distributed_MobilenetV3small_expanded_conv_2_depthwise_depthwisex_dilations_0, groups = model_time_distributed_MobilenetV3small_expanded_conv_2_depthwise_depthwisex_groups_0, pad = model_time_distributed_MobilenetV3small_expanded_conv_2_depthwise_depthwisex_pad_0, pad_type = model_time_distributed_MobilenetV3small_expanded_conv_2_depthwise_depthwisex_pad_type_0, strides = model_time_distributed_MobilenetV3small_expanded_conv_2_depthwise_depthwisex_strides_0, weight = const_16, x = transpose_264)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_2_depthwise_BatchNorm_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_2_depthwise_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_2_depthwise_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0"), val = tensor<int32, [4]>([0, 2, 3, 1])];
            tensor<fp16, [20, 28, 28, 88]> transpose_263 = transpose(perm = model_time_distributed_MobilenetV3small_expanded_conv_2_depthwise_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_2_depthwise_BatchNorm_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("transpose_85")];
            tensor<fp16, [20, 28, 28, 88]> model_time_distributed_MobilenetV3small_re_lu_6_Relu_cast_fp16 = relu(x = transpose_263)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_re_lu_6_Relu_cast_fp16")];
            tensor<int32, [4]> transpose_29_perm_0 = const()[name = tensor<string, []>("transpose_29_perm_0"), val = tensor<int32, [4]>([0, 3, 1, 2])];
            tensor<string, []> model_time_distributed_MobilenetV3small_expanded_conv_2_project_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_2_project_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_2_project_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_2_project_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_2_project_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_2_project_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_time_distributed_MobilenetV3small_expanded_conv_2_project_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_2_project_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_2_project_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_2_project_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [24, 88, 1, 1]> transpose_28_to_fp16_quantized = constexpr_affine_dequantize()[axis = tensor<int32, []>(0), name = tensor<string, []>("transpose_28_to_fp16_quantized"), quantized_data = tensor<int8, [24, 88, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(16640))), scale = tensor<fp16, [24]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(18944))), zero_point = tensor<int8, [24]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(18816)))];
            tensor<fp16, [20, 88, 28, 28]> transpose_262 = transpose(perm = transpose_29_perm_0, x = model_time_distributed_MobilenetV3small_re_lu_6_Relu_cast_fp16)[name = tensor<string, []>("transpose_84")];
            tensor<fp16, [20, 24, 28, 28]> model_time_distributed_MobilenetV3small_expanded_conv_2_project_Conv2Dx_cast_fp16 = conv(dilations = model_time_distributed_MobilenetV3small_expanded_conv_2_project_Conv2Dx_dilations_0, groups = model_time_distributed_MobilenetV3small_expanded_conv_2_project_Conv2Dx_groups_0, pad = model_time_distributed_MobilenetV3small_expanded_conv_2_project_Conv2Dx_pad_0, pad_type = model_time_distributed_MobilenetV3small_expanded_conv_2_project_Conv2Dx_pad_type_0, strides = model_time_distributed_MobilenetV3small_expanded_conv_2_project_Conv2Dx_strides_0, weight = transpose_28_to_fp16_quantized, x = transpose_262)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_2_project_Conv2Dx_cast_fp16")];
            tensor<fp16, [24]> model_time_distributed_MobilenetV3small_expanded_conv_2_project_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_2_project_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16"), val = tensor<fp16, [24]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(19072)))];
            tensor<fp16, [24]> model_time_distributed_MobilenetV3small_expanded_conv_2_project_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_2_project_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16"), val = tensor<fp16, [24]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(19200)))];
            tensor<fp16, [24]> model_time_distributed_MobilenetV3small_expanded_conv_2_project_BatchNorm_ReadVariableOp_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_2_project_BatchNorm_ReadVariableOp_to_fp16"), val = tensor<fp16, [24]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(19328)))];
            tensor<fp16, [24]> model_time_distributed_MobilenetV3small_expanded_conv_2_project_BatchNorm_ReadVariableOp_1_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_2_project_BatchNorm_ReadVariableOp_1_to_fp16"), val = tensor<fp16, [24]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(19456)))];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_expanded_conv_2_project_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_2_project_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.064p-10)];
            tensor<fp16, [20, 24, 28, 28]> model_time_distributed_MobilenetV3small_expanded_conv_2_project_BatchNorm_FusedBatchNormV3_nchw_cast_fp16 = batch_norm(beta = model_time_distributed_MobilenetV3small_expanded_conv_2_project_BatchNorm_ReadVariableOp_1_to_fp16, epsilon = model_time_distributed_MobilenetV3small_expanded_conv_2_project_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16, gamma = model_time_distributed_MobilenetV3small_expanded_conv_2_project_BatchNorm_ReadVariableOp_to_fp16, mean = model_time_distributed_MobilenetV3small_expanded_conv_2_project_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16, variance = model_time_distributed_MobilenetV3small_expanded_conv_2_project_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16, x = model_time_distributed_MobilenetV3small_expanded_conv_2_project_Conv2Dx_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_2_project_BatchNorm_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_2_project_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_2_project_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0"), val = tensor<int32, [4]>([0, 2, 3, 1])];
            tensor<fp16, [20, 28, 28, 24]> transpose_261 = transpose(perm = model_time_distributed_MobilenetV3small_expanded_conv_2_project_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_2_project_BatchNorm_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("transpose_83")];
            tensor<fp16, [20, 28, 28, 24]> model_time_distributed_MobilenetV3small_expanded_conv_2_Add_add_cast_fp16 = add(x = transpose_267, y = transpose_261)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_2_Add_add_cast_fp16")];
            tensor<int32, [4]> transpose_32_perm_0 = const()[name = tensor<string, []>("transpose_32_perm_0"), val = tensor<int32, [4]>([0, 3, 1, 2])];
            tensor<string, []> model_time_distributed_MobilenetV3small_expanded_conv_3_expand_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_3_expand_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_3_expand_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_3_expand_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_3_expand_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_3_expand_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_time_distributed_MobilenetV3small_expanded_conv_3_expand_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_3_expand_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_3_expand_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_3_expand_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [96, 24, 1, 1]> transpose_31_to_fp16_quantized = constexpr_affine_dequantize()[axis = tensor<int32, []>(0), name = tensor<string, []>("transpose_31_to_fp16_quantized"), quantized_data = tensor<int8, [96, 24, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(19584))), scale = tensor<fp16, [96]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(22144))), zero_point = tensor<int8, [96]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(21952)))];
            tensor<fp16, [20, 24, 28, 28]> transpose_260 = transpose(perm = transpose_32_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_2_Add_add_cast_fp16)[name = tensor<string, []>("transpose_82")];
            tensor<fp16, [20, 96, 28, 28]> model_time_distributed_MobilenetV3small_expanded_conv_3_expand_Conv2Dx_cast_fp16 = conv(dilations = model_time_distributed_MobilenetV3small_expanded_conv_3_expand_Conv2Dx_dilations_0, groups = model_time_distributed_MobilenetV3small_expanded_conv_3_expand_Conv2Dx_groups_0, pad = model_time_distributed_MobilenetV3small_expanded_conv_3_expand_Conv2Dx_pad_0, pad_type = model_time_distributed_MobilenetV3small_expanded_conv_3_expand_Conv2Dx_pad_type_0, strides = model_time_distributed_MobilenetV3small_expanded_conv_3_expand_Conv2Dx_strides_0, weight = transpose_31_to_fp16_quantized, x = transpose_260)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_3_expand_Conv2Dx_cast_fp16")];
            tensor<fp16, [96]> model_time_distributed_MobilenetV3small_expanded_conv_3_expand_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_3_expand_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16"), val = tensor<fp16, [96]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(22400)))];
            tensor<fp16, [96]> model_time_distributed_MobilenetV3small_expanded_conv_3_expand_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_3_expand_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16"), val = tensor<fp16, [96]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(22656)))];
            tensor<fp16, [96]> model_time_distributed_MobilenetV3small_expanded_conv_3_expand_BatchNorm_ReadVariableOp_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_3_expand_BatchNorm_ReadVariableOp_to_fp16"), val = tensor<fp16, [96]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(22912)))];
            tensor<fp16, [96]> model_time_distributed_MobilenetV3small_expanded_conv_3_expand_BatchNorm_ReadVariableOp_1_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_3_expand_BatchNorm_ReadVariableOp_1_to_fp16"), val = tensor<fp16, [96]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(23168)))];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_expanded_conv_3_expand_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_3_expand_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.064p-10)];
            tensor<fp16, [20, 96, 28, 28]> model_time_distributed_MobilenetV3small_expanded_conv_3_expand_BatchNorm_FusedBatchNormV3_nchw_cast_fp16 = batch_norm(beta = model_time_distributed_MobilenetV3small_expanded_conv_3_expand_BatchNorm_ReadVariableOp_1_to_fp16, epsilon = model_time_distributed_MobilenetV3small_expanded_conv_3_expand_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16, gamma = model_time_distributed_MobilenetV3small_expanded_conv_3_expand_BatchNorm_ReadVariableOp_to_fp16, mean = model_time_distributed_MobilenetV3small_expanded_conv_3_expand_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16, variance = model_time_distributed_MobilenetV3small_expanded_conv_3_expand_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16, x = model_time_distributed_MobilenetV3small_expanded_conv_3_expand_Conv2Dx_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_3_expand_BatchNorm_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_3_expand_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_3_expand_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0"), val = tensor<int32, [4]>([0, 2, 3, 1])];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_tf_math_add_2_Add_y_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_add_2_Add_y_to_fp16"), val = tensor<fp16, []>(0x1.8p+1)];
            tensor<fp16, [20, 28, 28, 96]> transpose_259 = transpose(perm = model_time_distributed_MobilenetV3small_expanded_conv_3_expand_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_3_expand_BatchNorm_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("transpose_81")];
            tensor<fp16, [20, 28, 28, 96]> model_time_distributed_MobilenetV3small_tf_math_add_2_Add_cast_fp16 = add(x = transpose_259, y = model_time_distributed_MobilenetV3small_tf_math_add_2_Add_y_to_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_add_2_Add_cast_fp16")];
            tensor<fp16, [20, 28, 28, 96]> model_time_distributed_MobilenetV3small_re_lu_7_Relu6_cast_fp16 = relu6(x = model_time_distributed_MobilenetV3small_tf_math_add_2_Add_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_re_lu_7_Relu6_cast_fp16")];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_tf_math_multiply_2_Mul_y_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_multiply_2_Mul_y_to_fp16"), val = tensor<fp16, []>(0x1.554p-3)];
            tensor<fp16, [20, 28, 28, 96]> model_time_distributed_MobilenetV3small_tf_math_multiply_2_Mul_cast_fp16 = mul(x = model_time_distributed_MobilenetV3small_re_lu_7_Relu6_cast_fp16, y = model_time_distributed_MobilenetV3small_tf_math_multiply_2_Mul_y_to_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_multiply_2_Mul_cast_fp16")];
            tensor<fp16, [20, 28, 28, 96]> model_time_distributed_MobilenetV3small_multiply_1_mul_cast_fp16 = mul(x = transpose_259, y = model_time_distributed_MobilenetV3small_tf_math_multiply_2_Mul_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_multiply_1_mul_cast_fp16")];
            tensor<string, []> pad_2_mode_0 = const()[name = tensor<string, []>("pad_2_mode_0"), val = tensor<string, []>("constant")];
            tensor<int32, [4]> transpose_141_perm_0 = const()[name = tensor<string, []>("transpose_141_perm_0"), val = tensor<int32, [4]>([0, 3, 1, 2])];
            tensor<int32, [8]> pad_6_pad_0 = const()[name = tensor<string, []>("pad_6_pad_0"), val = tensor<int32, [8]>([0, 0, 0, 0, 1, 2, 1, 2])];
            tensor<fp16, []> const_2_to_fp16 = const()[name = tensor<string, []>("const_2_to_fp16"), val = tensor<fp16, []>(0x0p+0)];
            tensor<fp16, [20, 96, 28, 28]> transpose_258 = transpose(perm = transpose_141_perm_0, x = model_time_distributed_MobilenetV3small_multiply_1_mul_cast_fp16)[name = tensor<string, []>("transpose_80")];
            tensor<fp16, [20, 96, 31, 31]> pad_6_cast_fp16 = pad(constant_val = const_2_to_fp16, mode = pad_2_mode_0, pad = pad_6_pad_0, x = transpose_258)[name = tensor<string, []>("pad_6_cast_fp16")];
            tensor<string, []> model_time_distributed_MobilenetV3small_expanded_conv_3_depthwise_depthwisex_pad_type_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_3_depthwise_depthwisex_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_3_depthwise_depthwisex_strides_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_3_depthwise_depthwisex_strides_0"), val = tensor<int32, [2]>([2, 2])];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_3_depthwise_depthwisex_dilations_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_3_depthwise_depthwisex_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_time_distributed_MobilenetV3small_expanded_conv_3_depthwise_depthwisex_groups_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_3_depthwise_depthwisex_groups_0"), val = tensor<int32, []>(96)];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_3_depthwise_depthwisex_pad_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_3_depthwise_depthwisex_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [96, 1, 5, 5]> transpose_34_to_fp16_quantized = constexpr_affine_dequantize()[axis = tensor<int32, []>(0), name = tensor<string, []>("transpose_34_to_fp16_quantized"), quantized_data = tensor<int8, [96, 1, 5, 5]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(23424))), scale = tensor<fp16, [96]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(26112))), zero_point = tensor<int8, [96]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(25920)))];
            tensor<fp16, [20, 96, 14, 14]> model_time_distributed_MobilenetV3small_expanded_conv_3_depthwise_depthwisex_cast_fp16 = conv(dilations = model_time_distributed_MobilenetV3small_expanded_conv_3_depthwise_depthwisex_dilations_0, groups = model_time_distributed_MobilenetV3small_expanded_conv_3_depthwise_depthwisex_groups_0, pad = model_time_distributed_MobilenetV3small_expanded_conv_3_depthwise_depthwisex_pad_0, pad_type = model_time_distributed_MobilenetV3small_expanded_conv_3_depthwise_depthwisex_pad_type_0, strides = model_time_distributed_MobilenetV3small_expanded_conv_3_depthwise_depthwisex_strides_0, weight = transpose_34_to_fp16_quantized, x = pad_6_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_3_depthwise_depthwisex_cast_fp16")];
            tensor<fp16, [96]> model_time_distributed_MobilenetV3small_expanded_conv_3_depthwise_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_3_depthwise_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16"), val = tensor<fp16, [96]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(26368)))];
            tensor<fp16, [96]> model_time_distributed_MobilenetV3small_expanded_conv_3_depthwise_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_3_depthwise_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16"), val = tensor<fp16, [96]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(26624)))];
            tensor<fp16, [96]> model_time_distributed_MobilenetV3small_expanded_conv_3_depthwise_BatchNorm_ReadVariableOp_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_3_depthwise_BatchNorm_ReadVariableOp_to_fp16"), val = tensor<fp16, [96]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(26880)))];
            tensor<fp16, [96]> model_time_distributed_MobilenetV3small_expanded_conv_3_depthwise_BatchNorm_ReadVariableOp_1_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_3_depthwise_BatchNorm_ReadVariableOp_1_to_fp16"), val = tensor<fp16, [96]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(27136)))];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_expanded_conv_3_depthwise_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_3_depthwise_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.064p-10)];
            tensor<fp16, [20, 96, 14, 14]> model_time_distributed_MobilenetV3small_expanded_conv_3_depthwise_BatchNorm_FusedBatchNormV3_nchw_cast_fp16 = batch_norm(beta = model_time_distributed_MobilenetV3small_expanded_conv_3_depthwise_BatchNorm_ReadVariableOp_1_to_fp16, epsilon = model_time_distributed_MobilenetV3small_expanded_conv_3_depthwise_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16, gamma = model_time_distributed_MobilenetV3small_expanded_conv_3_depthwise_BatchNorm_ReadVariableOp_to_fp16, mean = model_time_distributed_MobilenetV3small_expanded_conv_3_depthwise_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16, variance = model_time_distributed_MobilenetV3small_expanded_conv_3_depthwise_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16, x = model_time_distributed_MobilenetV3small_expanded_conv_3_depthwise_depthwisex_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_3_depthwise_BatchNorm_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_3_depthwise_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_3_depthwise_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0"), val = tensor<int32, [4]>([0, 2, 3, 1])];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_tf_math_add_3_Add_y_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_add_3_Add_y_to_fp16"), val = tensor<fp16, []>(0x1.8p+1)];
            tensor<fp16, [20, 14, 14, 96]> transpose_257 = transpose(perm = model_time_distributed_MobilenetV3small_expanded_conv_3_depthwise_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_3_depthwise_BatchNorm_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("transpose_79")];
            tensor<fp16, [20, 14, 14, 96]> model_time_distributed_MobilenetV3small_tf_math_add_3_Add_cast_fp16 = add(x = transpose_257, y = model_time_distributed_MobilenetV3small_tf_math_add_3_Add_y_to_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_add_3_Add_cast_fp16")];
            tensor<fp16, [20, 14, 14, 96]> model_time_distributed_MobilenetV3small_re_lu_8_Relu6_cast_fp16 = relu6(x = model_time_distributed_MobilenetV3small_tf_math_add_3_Add_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_re_lu_8_Relu6_cast_fp16")];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_tf_math_multiply_3_Mul_y_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_multiply_3_Mul_y_to_fp16"), val = tensor<fp16, []>(0x1.554p-3)];
            tensor<fp16, [20, 14, 14, 96]> model_time_distributed_MobilenetV3small_tf_math_multiply_3_Mul_cast_fp16 = mul(x = model_time_distributed_MobilenetV3small_re_lu_8_Relu6_cast_fp16, y = model_time_distributed_MobilenetV3small_tf_math_multiply_3_Mul_y_to_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_multiply_3_Mul_cast_fp16")];
            tensor<fp16, [20, 14, 14, 96]> model_time_distributed_MobilenetV3small_multiply_2_mul_cast_fp16 = mul(x = transpose_257, y = model_time_distributed_MobilenetV3small_tf_math_multiply_3_Mul_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_multiply_2_mul_cast_fp16")];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_3_squeeze_excite_AvgPool_Mean_axes_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_3_squeeze_excite_AvgPool_Mean_axes_0"), val = tensor<int32, [2]>([1, 2])];
            tensor<bool, []> model_time_distributed_MobilenetV3small_expanded_conv_3_squeeze_excite_AvgPool_Mean_keep_dims_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_3_squeeze_excite_AvgPool_Mean_keep_dims_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [20, 1, 1, 96]> model_time_distributed_MobilenetV3small_expanded_conv_3_squeeze_excite_AvgPool_Mean_cast_fp16 = reduce_mean(axes = model_time_distributed_MobilenetV3small_expanded_conv_3_squeeze_excite_AvgPool_Mean_axes_0, keep_dims = model_time_distributed_MobilenetV3small_expanded_conv_3_squeeze_excite_AvgPool_Mean_keep_dims_0, x = model_time_distributed_MobilenetV3small_multiply_2_mul_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_3_squeeze_excite_AvgPool_Mean_cast_fp16")];
            tensor<int32, [4]> transpose_38_perm_0 = const()[name = tensor<string, []>("transpose_38_perm_0"), val = tensor<int32, [4]>([0, 3, 1, 2])];
            tensor<string, []> model_time_distributed_MobilenetV3small_expanded_conv_3_squeeze_excite_Conv_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_3_squeeze_excite_Conv_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_3_squeeze_excite_Conv_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_3_squeeze_excite_Conv_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_3_squeeze_excite_Conv_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_3_squeeze_excite_Conv_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_time_distributed_MobilenetV3small_expanded_conv_3_squeeze_excite_Conv_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_3_squeeze_excite_Conv_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_3_squeeze_excite_Conv_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_3_squeeze_excite_Conv_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [24, 96, 1, 1]> conv_2_weight_0_to_fp16_quantized = constexpr_affine_dequantize()[axis = tensor<int32, []>(0), name = tensor<string, []>("conv_2_weight_0_to_fp16_quantized"), quantized_data = tensor<int8, [24, 96, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(27392))), scale = tensor<fp16, [24]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(29888))), zero_point = tensor<int8, [24]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(29760)))];
            tensor<fp16, [24]> conv_2_bias_0_to_fp16 = const()[name = tensor<string, []>("conv_2_bias_0_to_fp16"), val = tensor<fp16, [24]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(30016)))];
            tensor<fp16, [20, 96, 1, 1]> transpose_256 = transpose(perm = transpose_38_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_3_squeeze_excite_AvgPool_Mean_cast_fp16)[name = tensor<string, []>("transpose_78")];
            tensor<fp16, [20, 24, 1, 1]> conv_2_cast_fp16 = conv(bias = conv_2_bias_0_to_fp16, dilations = model_time_distributed_MobilenetV3small_expanded_conv_3_squeeze_excite_Conv_Conv2Dx_dilations_0, groups = model_time_distributed_MobilenetV3small_expanded_conv_3_squeeze_excite_Conv_Conv2Dx_groups_0, pad = model_time_distributed_MobilenetV3small_expanded_conv_3_squeeze_excite_Conv_Conv2Dx_pad_0, pad_type = model_time_distributed_MobilenetV3small_expanded_conv_3_squeeze_excite_Conv_Conv2Dx_pad_type_0, strides = model_time_distributed_MobilenetV3small_expanded_conv_3_squeeze_excite_Conv_Conv2Dx_strides_0, weight = conv_2_weight_0_to_fp16_quantized, x = transpose_256)[name = tensor<string, []>("conv_2_cast_fp16")];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_3_squeeze_excite_Conv_Conv2D_perm_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_3_squeeze_excite_Conv_Conv2D_perm_0"), val = tensor<int32, [4]>([0, 2, 3, 1])];
            tensor<fp16, [20, 1, 1, 24]> transpose_255 = transpose(perm = model_time_distributed_MobilenetV3small_expanded_conv_3_squeeze_excite_Conv_Conv2D_perm_0, x = conv_2_cast_fp16)[name = tensor<string, []>("transpose_77")];
            tensor<fp16, [20, 1, 1, 24]> model_time_distributed_MobilenetV3small_expanded_conv_3_squeeze_excite_Relu_Relu_cast_fp16 = relu(x = transpose_255)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_3_squeeze_excite_Relu_Relu_cast_fp16")];
            tensor<int32, [4]> transpose_40_perm_0 = const()[name = tensor<string, []>("transpose_40_perm_0"), val = tensor<int32, [4]>([0, 3, 1, 2])];
            tensor<string, []> model_time_distributed_MobilenetV3small_expanded_conv_3_squeeze_excite_Conv_1_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_3_squeeze_excite_Conv_1_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_3_squeeze_excite_Conv_1_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_3_squeeze_excite_Conv_1_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_3_squeeze_excite_Conv_1_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_3_squeeze_excite_Conv_1_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_time_distributed_MobilenetV3small_expanded_conv_3_squeeze_excite_Conv_1_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_3_squeeze_excite_Conv_1_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_3_squeeze_excite_Conv_1_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_3_squeeze_excite_Conv_1_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [96, 24, 1, 1]> conv_19_weight_0_to_fp16_quantized = constexpr_affine_dequantize()[axis = tensor<int32, []>(0), name = tensor<string, []>("conv_19_weight_0_to_fp16_quantized"), quantized_data = tensor<int8, [96, 24, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(30144))), scale = tensor<fp16, [96]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(32704))), zero_point = tensor<int8, [96]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(32512)))];
            tensor<fp16, [96]> conv_19_bias_0_to_fp16 = const()[name = tensor<string, []>("conv_19_bias_0_to_fp16"), val = tensor<fp16, [96]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(32960)))];
            tensor<fp16, [20, 24, 1, 1]> transpose_254 = transpose(perm = transpose_40_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_3_squeeze_excite_Relu_Relu_cast_fp16)[name = tensor<string, []>("transpose_76")];
            tensor<fp16, [20, 96, 1, 1]> conv_19_cast_fp16 = conv(bias = conv_19_bias_0_to_fp16, dilations = model_time_distributed_MobilenetV3small_expanded_conv_3_squeeze_excite_Conv_1_Conv2Dx_dilations_0, groups = model_time_distributed_MobilenetV3small_expanded_conv_3_squeeze_excite_Conv_1_Conv2Dx_groups_0, pad = model_time_distributed_MobilenetV3small_expanded_conv_3_squeeze_excite_Conv_1_Conv2Dx_pad_0, pad_type = model_time_distributed_MobilenetV3small_expanded_conv_3_squeeze_excite_Conv_1_Conv2Dx_pad_type_0, strides = model_time_distributed_MobilenetV3small_expanded_conv_3_squeeze_excite_Conv_1_Conv2Dx_strides_0, weight = conv_19_weight_0_to_fp16_quantized, x = transpose_254)[name = tensor<string, []>("conv_19_cast_fp16")];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_3_squeeze_excite_Conv_1_Conv2D_perm_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_3_squeeze_excite_Conv_1_Conv2D_perm_0"), val = tensor<int32, [4]>([0, 2, 3, 1])];
            tensor<fp16, [20, 1, 1, 96]> transpose_253 = transpose(perm = model_time_distributed_MobilenetV3small_expanded_conv_3_squeeze_excite_Conv_1_Conv2D_perm_0, x = conv_19_cast_fp16)[name = tensor<string, []>("transpose_75")];
            tensor<fp16, [20, 1, 1, 96]> model_time_distributed_MobilenetV3small_re_lu_9_Relu6_cast_fp16 = relu6(x = transpose_253)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_re_lu_9_Relu6_cast_fp16")];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_tf_math_multiply_4_Mul_y_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_multiply_4_Mul_y_to_fp16"), val = tensor<fp16, []>(0x1.554p-3)];
            tensor<fp16, [20, 1, 1, 96]> model_time_distributed_MobilenetV3small_tf_math_multiply_4_Mul_cast_fp16 = mul(x = model_time_distributed_MobilenetV3small_re_lu_9_Relu6_cast_fp16, y = model_time_distributed_MobilenetV3small_tf_math_multiply_4_Mul_y_to_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_multiply_4_Mul_cast_fp16")];
            tensor<fp16, [20, 14, 14, 96]> model_time_distributed_MobilenetV3small_expanded_conv_3_squeeze_excite_Mul_mul_cast_fp16 = mul(x = model_time_distributed_MobilenetV3small_multiply_2_mul_cast_fp16, y = model_time_distributed_MobilenetV3small_tf_math_multiply_4_Mul_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_3_squeeze_excite_Mul_mul_cast_fp16")];
            tensor<int32, [4]> transpose_42_perm_0 = const()[name = tensor<string, []>("transpose_42_perm_0"), val = tensor<int32, [4]>([0, 3, 1, 2])];
            tensor<string, []> model_time_distributed_MobilenetV3small_expanded_conv_3_project_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_3_project_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_3_project_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_3_project_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_3_project_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_3_project_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_time_distributed_MobilenetV3small_expanded_conv_3_project_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_3_project_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_3_project_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_3_project_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [40, 96, 1, 1]> transpose_41_to_fp16_quantized = constexpr_affine_dequantize()[axis = tensor<int32, []>(0), name = tensor<string, []>("transpose_41_to_fp16_quantized"), quantized_data = tensor<int8, [40, 96, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(33216))), scale = tensor<fp16, [40]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(37248))), zero_point = tensor<int8, [40]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(37120)))];
            tensor<fp16, [20, 96, 14, 14]> transpose_252 = transpose(perm = transpose_42_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_3_squeeze_excite_Mul_mul_cast_fp16)[name = tensor<string, []>("transpose_74")];
            tensor<fp16, [20, 40, 14, 14]> model_time_distributed_MobilenetV3small_expanded_conv_3_project_Conv2Dx_cast_fp16 = conv(dilations = model_time_distributed_MobilenetV3small_expanded_conv_3_project_Conv2Dx_dilations_0, groups = model_time_distributed_MobilenetV3small_expanded_conv_3_project_Conv2Dx_groups_0, pad = model_time_distributed_MobilenetV3small_expanded_conv_3_project_Conv2Dx_pad_0, pad_type = model_time_distributed_MobilenetV3small_expanded_conv_3_project_Conv2Dx_pad_type_0, strides = model_time_distributed_MobilenetV3small_expanded_conv_3_project_Conv2Dx_strides_0, weight = transpose_41_to_fp16_quantized, x = transpose_252)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_3_project_Conv2Dx_cast_fp16")];
            tensor<fp16, [40]> model_time_distributed_MobilenetV3small_expanded_conv_3_project_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_3_project_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16"), val = tensor<fp16, [40]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(37440)))];
            tensor<fp16, [40]> model_time_distributed_MobilenetV3small_expanded_conv_3_project_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_3_project_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16"), val = tensor<fp16, [40]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(37632)))];
            tensor<fp16, [40]> model_time_distributed_MobilenetV3small_expanded_conv_3_project_BatchNorm_ReadVariableOp_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_3_project_BatchNorm_ReadVariableOp_to_fp16"), val = tensor<fp16, [40]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(37824)))];
            tensor<fp16, [40]> model_time_distributed_MobilenetV3small_expanded_conv_3_project_BatchNorm_ReadVariableOp_1_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_3_project_BatchNorm_ReadVariableOp_1_to_fp16"), val = tensor<fp16, [40]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(38016)))];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_expanded_conv_3_project_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_3_project_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.064p-10)];
            tensor<fp16, [20, 40, 14, 14]> model_time_distributed_MobilenetV3small_expanded_conv_3_project_BatchNorm_FusedBatchNormV3_nchw_cast_fp16 = batch_norm(beta = model_time_distributed_MobilenetV3small_expanded_conv_3_project_BatchNorm_ReadVariableOp_1_to_fp16, epsilon = model_time_distributed_MobilenetV3small_expanded_conv_3_project_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16, gamma = model_time_distributed_MobilenetV3small_expanded_conv_3_project_BatchNorm_ReadVariableOp_to_fp16, mean = model_time_distributed_MobilenetV3small_expanded_conv_3_project_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16, variance = model_time_distributed_MobilenetV3small_expanded_conv_3_project_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16, x = model_time_distributed_MobilenetV3small_expanded_conv_3_project_Conv2Dx_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_3_project_BatchNorm_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_3_project_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_3_project_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0"), val = tensor<int32, [4]>([0, 2, 3, 1])];
            tensor<int32, [4]> transpose_45_perm_0 = const()[name = tensor<string, []>("transpose_45_perm_0"), val = tensor<int32, [4]>([0, 3, 1, 2])];
            tensor<string, []> model_time_distributed_MobilenetV3small_expanded_conv_4_expand_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_4_expand_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_4_expand_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_4_expand_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_4_expand_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_4_expand_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_time_distributed_MobilenetV3small_expanded_conv_4_expand_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_4_expand_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_4_expand_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_4_expand_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [240, 40, 1, 1]> transpose_44_to_fp16_quantized = constexpr_affine_dequantize()[axis = tensor<int32, []>(0), name = tensor<string, []>("transpose_44_to_fp16_quantized"), quantized_data = tensor<int8, [240, 40, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(38208))), scale = tensor<fp16, [240]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(48192))), zero_point = tensor<int8, [240]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(47872)))];
            tensor<fp16, [20, 14, 14, 40]> transpose_251 = transpose(perm = model_time_distributed_MobilenetV3small_expanded_conv_3_project_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_3_project_BatchNorm_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("transpose_73")];
            tensor<fp16, [20, 40, 14, 14]> transpose_250 = transpose(perm = transpose_45_perm_0, x = transpose_251)[name = tensor<string, []>("transpose_72")];
            tensor<fp16, [20, 240, 14, 14]> model_time_distributed_MobilenetV3small_expanded_conv_4_expand_Conv2Dx_cast_fp16 = conv(dilations = model_time_distributed_MobilenetV3small_expanded_conv_4_expand_Conv2Dx_dilations_0, groups = model_time_distributed_MobilenetV3small_expanded_conv_4_expand_Conv2Dx_groups_0, pad = model_time_distributed_MobilenetV3small_expanded_conv_4_expand_Conv2Dx_pad_0, pad_type = model_time_distributed_MobilenetV3small_expanded_conv_4_expand_Conv2Dx_pad_type_0, strides = model_time_distributed_MobilenetV3small_expanded_conv_4_expand_Conv2Dx_strides_0, weight = transpose_44_to_fp16_quantized, x = transpose_250)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_4_expand_Conv2Dx_cast_fp16")];
            tensor<fp16, [240]> model_time_distributed_MobilenetV3small_expanded_conv_4_expand_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_4_expand_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16"), val = tensor<fp16, [240]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(48768)))];
            tensor<fp16, [240]> model_time_distributed_MobilenetV3small_expanded_conv_4_expand_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_4_expand_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16"), val = tensor<fp16, [240]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(49344)))];
            tensor<fp16, [240]> model_time_distributed_MobilenetV3small_expanded_conv_4_expand_BatchNorm_ReadVariableOp_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_4_expand_BatchNorm_ReadVariableOp_to_fp16"), val = tensor<fp16, [240]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(49920)))];
            tensor<fp16, [240]> model_time_distributed_MobilenetV3small_expanded_conv_4_expand_BatchNorm_ReadVariableOp_1_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_4_expand_BatchNorm_ReadVariableOp_1_to_fp16"), val = tensor<fp16, [240]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(50496)))];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_expanded_conv_4_expand_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_4_expand_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.064p-10)];
            tensor<fp16, [20, 240, 14, 14]> model_time_distributed_MobilenetV3small_expanded_conv_4_expand_BatchNorm_FusedBatchNormV3_nchw_cast_fp16 = batch_norm(beta = model_time_distributed_MobilenetV3small_expanded_conv_4_expand_BatchNorm_ReadVariableOp_1_to_fp16, epsilon = model_time_distributed_MobilenetV3small_expanded_conv_4_expand_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16, gamma = model_time_distributed_MobilenetV3small_expanded_conv_4_expand_BatchNorm_ReadVariableOp_to_fp16, mean = model_time_distributed_MobilenetV3small_expanded_conv_4_expand_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16, variance = model_time_distributed_MobilenetV3small_expanded_conv_4_expand_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16, x = model_time_distributed_MobilenetV3small_expanded_conv_4_expand_Conv2Dx_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_4_expand_BatchNorm_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_4_expand_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_4_expand_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0"), val = tensor<int32, [4]>([0, 2, 3, 1])];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_tf_math_add_5_Add_y_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_add_5_Add_y_to_fp16"), val = tensor<fp16, []>(0x1.8p+1)];
            tensor<fp16, [20, 14, 14, 240]> transpose_249 = transpose(perm = model_time_distributed_MobilenetV3small_expanded_conv_4_expand_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_4_expand_BatchNorm_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("transpose_71")];
            tensor<fp16, [20, 14, 14, 240]> model_time_distributed_MobilenetV3small_tf_math_add_5_Add_cast_fp16 = add(x = transpose_249, y = model_time_distributed_MobilenetV3small_tf_math_add_5_Add_y_to_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_add_5_Add_cast_fp16")];
            tensor<fp16, [20, 14, 14, 240]> model_time_distributed_MobilenetV3small_re_lu_10_Relu6_cast_fp16 = relu6(x = model_time_distributed_MobilenetV3small_tf_math_add_5_Add_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_re_lu_10_Relu6_cast_fp16")];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_tf_math_multiply_5_Mul_y_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_multiply_5_Mul_y_to_fp16"), val = tensor<fp16, []>(0x1.554p-3)];
            tensor<fp16, [20, 14, 14, 240]> model_time_distributed_MobilenetV3small_tf_math_multiply_5_Mul_cast_fp16 = mul(x = model_time_distributed_MobilenetV3small_re_lu_10_Relu6_cast_fp16, y = model_time_distributed_MobilenetV3small_tf_math_multiply_5_Mul_y_to_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_multiply_5_Mul_cast_fp16")];
            tensor<fp16, [20, 14, 14, 240]> model_time_distributed_MobilenetV3small_multiply_3_mul_cast_fp16 = mul(x = transpose_249, y = model_time_distributed_MobilenetV3small_tf_math_multiply_5_Mul_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_multiply_3_mul_cast_fp16")];
            tensor<int32, [4]> transpose_48_perm_0 = const()[name = tensor<string, []>("transpose_48_perm_0"), val = tensor<int32, [4]>([0, 3, 1, 2])];
            tensor<string, []> model_time_distributed_MobilenetV3small_expanded_conv_4_depthwise_depthwisex_pad_type_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_4_depthwise_depthwisex_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_4_depthwise_depthwisex_strides_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_4_depthwise_depthwisex_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_4_depthwise_depthwisex_dilations_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_4_depthwise_depthwisex_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_time_distributed_MobilenetV3small_expanded_conv_4_depthwise_depthwisex_groups_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_4_depthwise_depthwisex_groups_0"), val = tensor<int32, []>(240)];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_4_depthwise_depthwisex_pad_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_4_depthwise_depthwisex_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [240, 1, 5, 5]> transpose_47_to_fp16_quantized = constexpr_affine_dequantize()[axis = tensor<int32, []>(0), name = tensor<string, []>("transpose_47_to_fp16_quantized"), quantized_data = tensor<int8, [240, 1, 5, 5]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(51072))), scale = tensor<fp16, [240]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(57152))), zero_point = tensor<int8, [240]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(47872)))];
            tensor<fp16, [20, 240, 14, 14]> transpose_248 = transpose(perm = transpose_48_perm_0, x = model_time_distributed_MobilenetV3small_multiply_3_mul_cast_fp16)[name = tensor<string, []>("transpose_70")];
            tensor<fp16, [20, 240, 14, 14]> model_time_distributed_MobilenetV3small_expanded_conv_4_depthwise_depthwisex_cast_fp16 = conv(dilations = model_time_distributed_MobilenetV3small_expanded_conv_4_depthwise_depthwisex_dilations_0, groups = model_time_distributed_MobilenetV3small_expanded_conv_4_depthwise_depthwisex_groups_0, pad = model_time_distributed_MobilenetV3small_expanded_conv_4_depthwise_depthwisex_pad_0, pad_type = model_time_distributed_MobilenetV3small_expanded_conv_4_depthwise_depthwisex_pad_type_0, strides = model_time_distributed_MobilenetV3small_expanded_conv_4_depthwise_depthwisex_strides_0, weight = transpose_47_to_fp16_quantized, x = transpose_248)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_4_depthwise_depthwisex_cast_fp16")];
            tensor<fp16, [240]> model_time_distributed_MobilenetV3small_expanded_conv_4_depthwise_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_4_depthwise_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16"), val = tensor<fp16, [240]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(57728)))];
            tensor<fp16, [240]> model_time_distributed_MobilenetV3small_expanded_conv_4_depthwise_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_4_depthwise_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16"), val = tensor<fp16, [240]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(58304)))];
            tensor<fp16, [240]> model_time_distributed_MobilenetV3small_expanded_conv_4_depthwise_BatchNorm_ReadVariableOp_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_4_depthwise_BatchNorm_ReadVariableOp_to_fp16"), val = tensor<fp16, [240]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(58880)))];
            tensor<fp16, [240]> model_time_distributed_MobilenetV3small_expanded_conv_4_depthwise_BatchNorm_ReadVariableOp_1_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_4_depthwise_BatchNorm_ReadVariableOp_1_to_fp16"), val = tensor<fp16, [240]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(59456)))];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_expanded_conv_4_depthwise_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_4_depthwise_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.064p-10)];
            tensor<fp16, [20, 240, 14, 14]> model_time_distributed_MobilenetV3small_expanded_conv_4_depthwise_BatchNorm_FusedBatchNormV3_nchw_cast_fp16 = batch_norm(beta = model_time_distributed_MobilenetV3small_expanded_conv_4_depthwise_BatchNorm_ReadVariableOp_1_to_fp16, epsilon = model_time_distributed_MobilenetV3small_expanded_conv_4_depthwise_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16, gamma = model_time_distributed_MobilenetV3small_expanded_conv_4_depthwise_BatchNorm_ReadVariableOp_to_fp16, mean = model_time_distributed_MobilenetV3small_expanded_conv_4_depthwise_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16, variance = model_time_distributed_MobilenetV3small_expanded_conv_4_depthwise_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16, x = model_time_distributed_MobilenetV3small_expanded_conv_4_depthwise_depthwisex_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_4_depthwise_BatchNorm_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_4_depthwise_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_4_depthwise_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0"), val = tensor<int32, [4]>([0, 2, 3, 1])];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_tf_math_add_6_Add_y_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_add_6_Add_y_to_fp16"), val = tensor<fp16, []>(0x1.8p+1)];
            tensor<fp16, [20, 14, 14, 240]> transpose_247 = transpose(perm = model_time_distributed_MobilenetV3small_expanded_conv_4_depthwise_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_4_depthwise_BatchNorm_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("transpose_69")];
            tensor<fp16, [20, 14, 14, 240]> model_time_distributed_MobilenetV3small_tf_math_add_6_Add_cast_fp16 = add(x = transpose_247, y = model_time_distributed_MobilenetV3small_tf_math_add_6_Add_y_to_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_add_6_Add_cast_fp16")];
            tensor<fp16, [20, 14, 14, 240]> model_time_distributed_MobilenetV3small_re_lu_11_Relu6_cast_fp16 = relu6(x = model_time_distributed_MobilenetV3small_tf_math_add_6_Add_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_re_lu_11_Relu6_cast_fp16")];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_tf_math_multiply_6_Mul_y_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_multiply_6_Mul_y_to_fp16"), val = tensor<fp16, []>(0x1.554p-3)];
            tensor<fp16, [20, 14, 14, 240]> model_time_distributed_MobilenetV3small_tf_math_multiply_6_Mul_cast_fp16 = mul(x = model_time_distributed_MobilenetV3small_re_lu_11_Relu6_cast_fp16, y = model_time_distributed_MobilenetV3small_tf_math_multiply_6_Mul_y_to_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_multiply_6_Mul_cast_fp16")];
            tensor<fp16, [20, 14, 14, 240]> model_time_distributed_MobilenetV3small_multiply_4_mul_cast_fp16 = mul(x = transpose_247, y = model_time_distributed_MobilenetV3small_tf_math_multiply_6_Mul_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_multiply_4_mul_cast_fp16")];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_4_squeeze_excite_AvgPool_Mean_axes_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_4_squeeze_excite_AvgPool_Mean_axes_0"), val = tensor<int32, [2]>([1, 2])];
            tensor<bool, []> model_time_distributed_MobilenetV3small_expanded_conv_4_squeeze_excite_AvgPool_Mean_keep_dims_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_4_squeeze_excite_AvgPool_Mean_keep_dims_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [20, 1, 1, 240]> model_time_distributed_MobilenetV3small_expanded_conv_4_squeeze_excite_AvgPool_Mean_cast_fp16 = reduce_mean(axes = model_time_distributed_MobilenetV3small_expanded_conv_4_squeeze_excite_AvgPool_Mean_axes_0, keep_dims = model_time_distributed_MobilenetV3small_expanded_conv_4_squeeze_excite_AvgPool_Mean_keep_dims_0, x = model_time_distributed_MobilenetV3small_multiply_4_mul_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_4_squeeze_excite_AvgPool_Mean_cast_fp16")];
            tensor<int32, [4]> transpose_51_perm_0 = const()[name = tensor<string, []>("transpose_51_perm_0"), val = tensor<int32, [4]>([0, 3, 1, 2])];
            tensor<string, []> model_time_distributed_MobilenetV3small_expanded_conv_4_squeeze_excite_Conv_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_4_squeeze_excite_Conv_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_4_squeeze_excite_Conv_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_4_squeeze_excite_Conv_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_4_squeeze_excite_Conv_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_4_squeeze_excite_Conv_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_time_distributed_MobilenetV3small_expanded_conv_4_squeeze_excite_Conv_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_4_squeeze_excite_Conv_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_4_squeeze_excite_Conv_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_4_squeeze_excite_Conv_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [64, 240, 1, 1]> conv_4_weight_0_to_fp16_quantized = constexpr_affine_dequantize()[axis = tensor<int32, []>(0), name = tensor<string, []>("conv_4_weight_0_to_fp16_quantized"), quantized_data = tensor<int8, [64, 240, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(60032))), scale = tensor<fp16, [64]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(75584))), zero_point = tensor<int8, [64]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(75456)))];
            tensor<fp16, [64]> conv_4_bias_0_to_fp16 = const()[name = tensor<string, []>("conv_4_bias_0_to_fp16"), val = tensor<fp16, [64]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(75776)))];
            tensor<fp16, [20, 240, 1, 1]> transpose_246 = transpose(perm = transpose_51_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_4_squeeze_excite_AvgPool_Mean_cast_fp16)[name = tensor<string, []>("transpose_68")];
            tensor<fp16, [20, 64, 1, 1]> conv_4_cast_fp16 = conv(bias = conv_4_bias_0_to_fp16, dilations = model_time_distributed_MobilenetV3small_expanded_conv_4_squeeze_excite_Conv_Conv2Dx_dilations_0, groups = model_time_distributed_MobilenetV3small_expanded_conv_4_squeeze_excite_Conv_Conv2Dx_groups_0, pad = model_time_distributed_MobilenetV3small_expanded_conv_4_squeeze_excite_Conv_Conv2Dx_pad_0, pad_type = model_time_distributed_MobilenetV3small_expanded_conv_4_squeeze_excite_Conv_Conv2Dx_pad_type_0, strides = model_time_distributed_MobilenetV3small_expanded_conv_4_squeeze_excite_Conv_Conv2Dx_strides_0, weight = conv_4_weight_0_to_fp16_quantized, x = transpose_246)[name = tensor<string, []>("conv_4_cast_fp16")];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_4_squeeze_excite_Conv_Conv2D_perm_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_4_squeeze_excite_Conv_Conv2D_perm_0"), val = tensor<int32, [4]>([0, 2, 3, 1])];
            tensor<fp16, [20, 1, 1, 64]> transpose_245 = transpose(perm = model_time_distributed_MobilenetV3small_expanded_conv_4_squeeze_excite_Conv_Conv2D_perm_0, x = conv_4_cast_fp16)[name = tensor<string, []>("transpose_67")];
            tensor<fp16, [20, 1, 1, 64]> model_time_distributed_MobilenetV3small_expanded_conv_4_squeeze_excite_Relu_Relu_cast_fp16 = relu(x = transpose_245)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_4_squeeze_excite_Relu_Relu_cast_fp16")];
            tensor<int32, [4]> transpose_53_perm_0 = const()[name = tensor<string, []>("transpose_53_perm_0"), val = tensor<int32, [4]>([0, 3, 1, 2])];
            tensor<string, []> model_time_distributed_MobilenetV3small_expanded_conv_4_squeeze_excite_Conv_1_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_4_squeeze_excite_Conv_1_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_4_squeeze_excite_Conv_1_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_4_squeeze_excite_Conv_1_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_4_squeeze_excite_Conv_1_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_4_squeeze_excite_Conv_1_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_time_distributed_MobilenetV3small_expanded_conv_4_squeeze_excite_Conv_1_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_4_squeeze_excite_Conv_1_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_4_squeeze_excite_Conv_1_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_4_squeeze_excite_Conv_1_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [240, 64, 1, 1]> conv_20_weight_0_to_fp16_quantized = constexpr_affine_dequantize()[axis = tensor<int32, []>(0), name = tensor<string, []>("conv_20_weight_0_to_fp16_quantized"), quantized_data = tensor<int8, [240, 64, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(75968))), scale = tensor<fp16, [240]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(91392))), zero_point = tensor<int8, [240]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(47872)))];
            tensor<fp16, [240]> conv_20_bias_0_to_fp16 = const()[name = tensor<string, []>("conv_20_bias_0_to_fp16"), val = tensor<fp16, [240]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(91968)))];
            tensor<fp16, [20, 64, 1, 1]> transpose_244 = transpose(perm = transpose_53_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_4_squeeze_excite_Relu_Relu_cast_fp16)[name = tensor<string, []>("transpose_66")];
            tensor<fp16, [20, 240, 1, 1]> conv_20_cast_fp16 = conv(bias = conv_20_bias_0_to_fp16, dilations = model_time_distributed_MobilenetV3small_expanded_conv_4_squeeze_excite_Conv_1_Conv2Dx_dilations_0, groups = model_time_distributed_MobilenetV3small_expanded_conv_4_squeeze_excite_Conv_1_Conv2Dx_groups_0, pad = model_time_distributed_MobilenetV3small_expanded_conv_4_squeeze_excite_Conv_1_Conv2Dx_pad_0, pad_type = model_time_distributed_MobilenetV3small_expanded_conv_4_squeeze_excite_Conv_1_Conv2Dx_pad_type_0, strides = model_time_distributed_MobilenetV3small_expanded_conv_4_squeeze_excite_Conv_1_Conv2Dx_strides_0, weight = conv_20_weight_0_to_fp16_quantized, x = transpose_244)[name = tensor<string, []>("conv_20_cast_fp16")];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_4_squeeze_excite_Conv_1_Conv2D_perm_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_4_squeeze_excite_Conv_1_Conv2D_perm_0"), val = tensor<int32, [4]>([0, 2, 3, 1])];
            tensor<fp16, [20, 1, 1, 240]> transpose_243 = transpose(perm = model_time_distributed_MobilenetV3small_expanded_conv_4_squeeze_excite_Conv_1_Conv2D_perm_0, x = conv_20_cast_fp16)[name = tensor<string, []>("transpose_65")];
            tensor<fp16, [20, 1, 1, 240]> model_time_distributed_MobilenetV3small_re_lu_12_Relu6_cast_fp16 = relu6(x = transpose_243)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_re_lu_12_Relu6_cast_fp16")];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_tf_math_multiply_7_Mul_y_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_multiply_7_Mul_y_to_fp16"), val = tensor<fp16, []>(0x1.554p-3)];
            tensor<fp16, [20, 1, 1, 240]> model_time_distributed_MobilenetV3small_tf_math_multiply_7_Mul_cast_fp16 = mul(x = model_time_distributed_MobilenetV3small_re_lu_12_Relu6_cast_fp16, y = model_time_distributed_MobilenetV3small_tf_math_multiply_7_Mul_y_to_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_multiply_7_Mul_cast_fp16")];
            tensor<fp16, [20, 14, 14, 240]> model_time_distributed_MobilenetV3small_expanded_conv_4_squeeze_excite_Mul_mul_cast_fp16 = mul(x = model_time_distributed_MobilenetV3small_multiply_4_mul_cast_fp16, y = model_time_distributed_MobilenetV3small_tf_math_multiply_7_Mul_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_4_squeeze_excite_Mul_mul_cast_fp16")];
            tensor<int32, [4]> transpose_55_perm_0 = const()[name = tensor<string, []>("transpose_55_perm_0"), val = tensor<int32, [4]>([0, 3, 1, 2])];
            tensor<string, []> model_time_distributed_MobilenetV3small_expanded_conv_4_project_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_4_project_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_4_project_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_4_project_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_4_project_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_4_project_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_time_distributed_MobilenetV3small_expanded_conv_4_project_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_4_project_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_4_project_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_4_project_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [40, 240, 1, 1]> transpose_54_to_fp16_quantized = constexpr_affine_dequantize()[axis = tensor<int32, []>(0), name = tensor<string, []>("transpose_54_to_fp16_quantized"), quantized_data = tensor<int8, [40, 240, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(92544))), scale = tensor<fp16, [40]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(102336))), zero_point = tensor<int8, [40]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(102208)))];
            tensor<fp16, [20, 240, 14, 14]> transpose_242 = transpose(perm = transpose_55_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_4_squeeze_excite_Mul_mul_cast_fp16)[name = tensor<string, []>("transpose_64")];
            tensor<fp16, [20, 40, 14, 14]> model_time_distributed_MobilenetV3small_expanded_conv_4_project_Conv2Dx_cast_fp16 = conv(dilations = model_time_distributed_MobilenetV3small_expanded_conv_4_project_Conv2Dx_dilations_0, groups = model_time_distributed_MobilenetV3small_expanded_conv_4_project_Conv2Dx_groups_0, pad = model_time_distributed_MobilenetV3small_expanded_conv_4_project_Conv2Dx_pad_0, pad_type = model_time_distributed_MobilenetV3small_expanded_conv_4_project_Conv2Dx_pad_type_0, strides = model_time_distributed_MobilenetV3small_expanded_conv_4_project_Conv2Dx_strides_0, weight = transpose_54_to_fp16_quantized, x = transpose_242)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_4_project_Conv2Dx_cast_fp16")];
            tensor<fp16, [40]> model_time_distributed_MobilenetV3small_expanded_conv_4_project_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_4_project_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16"), val = tensor<fp16, [40]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(102528)))];
            tensor<fp16, [40]> model_time_distributed_MobilenetV3small_expanded_conv_4_project_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_4_project_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16"), val = tensor<fp16, [40]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(102720)))];
            tensor<fp16, [40]> model_time_distributed_MobilenetV3small_expanded_conv_4_project_BatchNorm_ReadVariableOp_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_4_project_BatchNorm_ReadVariableOp_to_fp16"), val = tensor<fp16, [40]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(102912)))];
            tensor<fp16, [40]> model_time_distributed_MobilenetV3small_expanded_conv_4_project_BatchNorm_ReadVariableOp_1_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_4_project_BatchNorm_ReadVariableOp_1_to_fp16"), val = tensor<fp16, [40]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(103104)))];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_expanded_conv_4_project_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_4_project_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.064p-10)];
            tensor<fp16, [20, 40, 14, 14]> model_time_distributed_MobilenetV3small_expanded_conv_4_project_BatchNorm_FusedBatchNormV3_nchw_cast_fp16 = batch_norm(beta = model_time_distributed_MobilenetV3small_expanded_conv_4_project_BatchNorm_ReadVariableOp_1_to_fp16, epsilon = model_time_distributed_MobilenetV3small_expanded_conv_4_project_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16, gamma = model_time_distributed_MobilenetV3small_expanded_conv_4_project_BatchNorm_ReadVariableOp_to_fp16, mean = model_time_distributed_MobilenetV3small_expanded_conv_4_project_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16, variance = model_time_distributed_MobilenetV3small_expanded_conv_4_project_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16, x = model_time_distributed_MobilenetV3small_expanded_conv_4_project_Conv2Dx_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_4_project_BatchNorm_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_4_project_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_4_project_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0"), val = tensor<int32, [4]>([0, 2, 3, 1])];
            tensor<fp16, [20, 14, 14, 40]> transpose_241 = transpose(perm = model_time_distributed_MobilenetV3small_expanded_conv_4_project_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_4_project_BatchNorm_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("transpose_63")];
            tensor<fp16, [20, 14, 14, 40]> model_time_distributed_MobilenetV3small_expanded_conv_4_Add_add_cast_fp16 = add(x = transpose_251, y = transpose_241)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_4_Add_add_cast_fp16")];
            tensor<int32, [4]> transpose_58_perm_0 = const()[name = tensor<string, []>("transpose_58_perm_0"), val = tensor<int32, [4]>([0, 3, 1, 2])];
            tensor<string, []> model_time_distributed_MobilenetV3small_expanded_conv_5_expand_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_5_expand_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_5_expand_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_5_expand_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_5_expand_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_5_expand_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_time_distributed_MobilenetV3small_expanded_conv_5_expand_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_5_expand_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_5_expand_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_5_expand_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [240, 40, 1, 1]> transpose_57_to_fp16_quantized = constexpr_affine_dequantize()[axis = tensor<int32, []>(0), name = tensor<string, []>("transpose_57_to_fp16_quantized"), quantized_data = tensor<int8, [240, 40, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(103296))), scale = tensor<fp16, [240]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(112960))), zero_point = tensor<int8, [240]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(47872)))];
            tensor<fp16, [20, 40, 14, 14]> transpose_240 = transpose(perm = transpose_58_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_4_Add_add_cast_fp16)[name = tensor<string, []>("transpose_62")];
            tensor<fp16, [20, 240, 14, 14]> model_time_distributed_MobilenetV3small_expanded_conv_5_expand_Conv2Dx_cast_fp16 = conv(dilations = model_time_distributed_MobilenetV3small_expanded_conv_5_expand_Conv2Dx_dilations_0, groups = model_time_distributed_MobilenetV3small_expanded_conv_5_expand_Conv2Dx_groups_0, pad = model_time_distributed_MobilenetV3small_expanded_conv_5_expand_Conv2Dx_pad_0, pad_type = model_time_distributed_MobilenetV3small_expanded_conv_5_expand_Conv2Dx_pad_type_0, strides = model_time_distributed_MobilenetV3small_expanded_conv_5_expand_Conv2Dx_strides_0, weight = transpose_57_to_fp16_quantized, x = transpose_240)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_5_expand_Conv2Dx_cast_fp16")];
            tensor<fp16, [240]> model_time_distributed_MobilenetV3small_expanded_conv_5_expand_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_5_expand_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16"), val = tensor<fp16, [240]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(113536)))];
            tensor<fp16, [240]> model_time_distributed_MobilenetV3small_expanded_conv_5_expand_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_5_expand_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16"), val = tensor<fp16, [240]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(114112)))];
            tensor<fp16, [240]> model_time_distributed_MobilenetV3small_expanded_conv_5_expand_BatchNorm_ReadVariableOp_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_5_expand_BatchNorm_ReadVariableOp_to_fp16"), val = tensor<fp16, [240]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(114688)))];
            tensor<fp16, [240]> model_time_distributed_MobilenetV3small_expanded_conv_5_expand_BatchNorm_ReadVariableOp_1_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_5_expand_BatchNorm_ReadVariableOp_1_to_fp16"), val = tensor<fp16, [240]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(115264)))];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_expanded_conv_5_expand_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_5_expand_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.064p-10)];
            tensor<fp16, [20, 240, 14, 14]> model_time_distributed_MobilenetV3small_expanded_conv_5_expand_BatchNorm_FusedBatchNormV3_nchw_cast_fp16 = batch_norm(beta = model_time_distributed_MobilenetV3small_expanded_conv_5_expand_BatchNorm_ReadVariableOp_1_to_fp16, epsilon = model_time_distributed_MobilenetV3small_expanded_conv_5_expand_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16, gamma = model_time_distributed_MobilenetV3small_expanded_conv_5_expand_BatchNorm_ReadVariableOp_to_fp16, mean = model_time_distributed_MobilenetV3small_expanded_conv_5_expand_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16, variance = model_time_distributed_MobilenetV3small_expanded_conv_5_expand_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16, x = model_time_distributed_MobilenetV3small_expanded_conv_5_expand_Conv2Dx_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_5_expand_BatchNorm_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_5_expand_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_5_expand_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0"), val = tensor<int32, [4]>([0, 2, 3, 1])];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_tf_math_add_8_Add_y_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_add_8_Add_y_to_fp16"), val = tensor<fp16, []>(0x1.8p+1)];
            tensor<fp16, [20, 14, 14, 240]> transpose_239 = transpose(perm = model_time_distributed_MobilenetV3small_expanded_conv_5_expand_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_5_expand_BatchNorm_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("transpose_61")];
            tensor<fp16, [20, 14, 14, 240]> model_time_distributed_MobilenetV3small_tf_math_add_8_Add_cast_fp16 = add(x = transpose_239, y = model_time_distributed_MobilenetV3small_tf_math_add_8_Add_y_to_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_add_8_Add_cast_fp16")];
            tensor<fp16, [20, 14, 14, 240]> model_time_distributed_MobilenetV3small_re_lu_13_Relu6_cast_fp16 = relu6(x = model_time_distributed_MobilenetV3small_tf_math_add_8_Add_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_re_lu_13_Relu6_cast_fp16")];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_tf_math_multiply_8_Mul_y_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_multiply_8_Mul_y_to_fp16"), val = tensor<fp16, []>(0x1.554p-3)];
            tensor<fp16, [20, 14, 14, 240]> model_time_distributed_MobilenetV3small_tf_math_multiply_8_Mul_cast_fp16 = mul(x = model_time_distributed_MobilenetV3small_re_lu_13_Relu6_cast_fp16, y = model_time_distributed_MobilenetV3small_tf_math_multiply_8_Mul_y_to_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_multiply_8_Mul_cast_fp16")];
            tensor<fp16, [20, 14, 14, 240]> model_time_distributed_MobilenetV3small_multiply_5_mul_cast_fp16 = mul(x = transpose_239, y = model_time_distributed_MobilenetV3small_tf_math_multiply_8_Mul_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_multiply_5_mul_cast_fp16")];
            tensor<int32, [4]> transpose_61_perm_0 = const()[name = tensor<string, []>("transpose_61_perm_0"), val = tensor<int32, [4]>([0, 3, 1, 2])];
            tensor<string, []> model_time_distributed_MobilenetV3small_expanded_conv_5_depthwise_depthwisex_pad_type_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_5_depthwise_depthwisex_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_5_depthwise_depthwisex_strides_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_5_depthwise_depthwisex_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_5_depthwise_depthwisex_dilations_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_5_depthwise_depthwisex_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_time_distributed_MobilenetV3small_expanded_conv_5_depthwise_depthwisex_groups_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_5_depthwise_depthwisex_groups_0"), val = tensor<int32, []>(240)];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_5_depthwise_depthwisex_pad_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_5_depthwise_depthwisex_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [240, 1, 5, 5]> transpose_60_to_fp16_quantized = constexpr_affine_dequantize()[axis = tensor<int32, []>(0), name = tensor<string, []>("transpose_60_to_fp16_quantized"), quantized_data = tensor<int8, [240, 1, 5, 5]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(115840))), scale = tensor<fp16, [240]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(121920))), zero_point = tensor<int8, [240]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(47872)))];
            tensor<fp16, [20, 240, 14, 14]> transpose_238 = transpose(perm = transpose_61_perm_0, x = model_time_distributed_MobilenetV3small_multiply_5_mul_cast_fp16)[name = tensor<string, []>("transpose_60")];
            tensor<fp16, [20, 240, 14, 14]> model_time_distributed_MobilenetV3small_expanded_conv_5_depthwise_depthwisex_cast_fp16 = conv(dilations = model_time_distributed_MobilenetV3small_expanded_conv_5_depthwise_depthwisex_dilations_0, groups = model_time_distributed_MobilenetV3small_expanded_conv_5_depthwise_depthwisex_groups_0, pad = model_time_distributed_MobilenetV3small_expanded_conv_5_depthwise_depthwisex_pad_0, pad_type = model_time_distributed_MobilenetV3small_expanded_conv_5_depthwise_depthwisex_pad_type_0, strides = model_time_distributed_MobilenetV3small_expanded_conv_5_depthwise_depthwisex_strides_0, weight = transpose_60_to_fp16_quantized, x = transpose_238)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_5_depthwise_depthwisex_cast_fp16")];
            tensor<fp16, [240]> model_time_distributed_MobilenetV3small_expanded_conv_5_depthwise_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_5_depthwise_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16"), val = tensor<fp16, [240]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(122496)))];
            tensor<fp16, [240]> model_time_distributed_MobilenetV3small_expanded_conv_5_depthwise_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_5_depthwise_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16"), val = tensor<fp16, [240]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(123072)))];
            tensor<fp16, [240]> model_time_distributed_MobilenetV3small_expanded_conv_5_depthwise_BatchNorm_ReadVariableOp_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_5_depthwise_BatchNorm_ReadVariableOp_to_fp16"), val = tensor<fp16, [240]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(123648)))];
            tensor<fp16, [240]> model_time_distributed_MobilenetV3small_expanded_conv_5_depthwise_BatchNorm_ReadVariableOp_1_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_5_depthwise_BatchNorm_ReadVariableOp_1_to_fp16"), val = tensor<fp16, [240]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(124224)))];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_expanded_conv_5_depthwise_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_5_depthwise_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.064p-10)];
            tensor<fp16, [20, 240, 14, 14]> model_time_distributed_MobilenetV3small_expanded_conv_5_depthwise_BatchNorm_FusedBatchNormV3_nchw_cast_fp16 = batch_norm(beta = model_time_distributed_MobilenetV3small_expanded_conv_5_depthwise_BatchNorm_ReadVariableOp_1_to_fp16, epsilon = model_time_distributed_MobilenetV3small_expanded_conv_5_depthwise_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16, gamma = model_time_distributed_MobilenetV3small_expanded_conv_5_depthwise_BatchNorm_ReadVariableOp_to_fp16, mean = model_time_distributed_MobilenetV3small_expanded_conv_5_depthwise_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16, variance = model_time_distributed_MobilenetV3small_expanded_conv_5_depthwise_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16, x = model_time_distributed_MobilenetV3small_expanded_conv_5_depthwise_depthwisex_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_5_depthwise_BatchNorm_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_5_depthwise_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_5_depthwise_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0"), val = tensor<int32, [4]>([0, 2, 3, 1])];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_tf_math_add_9_Add_y_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_add_9_Add_y_to_fp16"), val = tensor<fp16, []>(0x1.8p+1)];
            tensor<fp16, [20, 14, 14, 240]> transpose_237 = transpose(perm = model_time_distributed_MobilenetV3small_expanded_conv_5_depthwise_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_5_depthwise_BatchNorm_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("transpose_59")];
            tensor<fp16, [20, 14, 14, 240]> model_time_distributed_MobilenetV3small_tf_math_add_9_Add_cast_fp16 = add(x = transpose_237, y = model_time_distributed_MobilenetV3small_tf_math_add_9_Add_y_to_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_add_9_Add_cast_fp16")];
            tensor<fp16, [20, 14, 14, 240]> model_time_distributed_MobilenetV3small_re_lu_14_Relu6_cast_fp16 = relu6(x = model_time_distributed_MobilenetV3small_tf_math_add_9_Add_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_re_lu_14_Relu6_cast_fp16")];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_tf_math_multiply_9_Mul_y_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_multiply_9_Mul_y_to_fp16"), val = tensor<fp16, []>(0x1.554p-3)];
            tensor<fp16, [20, 14, 14, 240]> model_time_distributed_MobilenetV3small_tf_math_multiply_9_Mul_cast_fp16 = mul(x = model_time_distributed_MobilenetV3small_re_lu_14_Relu6_cast_fp16, y = model_time_distributed_MobilenetV3small_tf_math_multiply_9_Mul_y_to_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_multiply_9_Mul_cast_fp16")];
            tensor<fp16, [20, 14, 14, 240]> model_time_distributed_MobilenetV3small_multiply_6_mul_cast_fp16 = mul(x = transpose_237, y = model_time_distributed_MobilenetV3small_tf_math_multiply_9_Mul_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_multiply_6_mul_cast_fp16")];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_5_squeeze_excite_AvgPool_Mean_axes_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_5_squeeze_excite_AvgPool_Mean_axes_0"), val = tensor<int32, [2]>([1, 2])];
            tensor<bool, []> model_time_distributed_MobilenetV3small_expanded_conv_5_squeeze_excite_AvgPool_Mean_keep_dims_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_5_squeeze_excite_AvgPool_Mean_keep_dims_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [20, 1, 1, 240]> model_time_distributed_MobilenetV3small_expanded_conv_5_squeeze_excite_AvgPool_Mean_cast_fp16 = reduce_mean(axes = model_time_distributed_MobilenetV3small_expanded_conv_5_squeeze_excite_AvgPool_Mean_axes_0, keep_dims = model_time_distributed_MobilenetV3small_expanded_conv_5_squeeze_excite_AvgPool_Mean_keep_dims_0, x = model_time_distributed_MobilenetV3small_multiply_6_mul_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_5_squeeze_excite_AvgPool_Mean_cast_fp16")];
            tensor<int32, [4]> transpose_64_perm_0 = const()[name = tensor<string, []>("transpose_64_perm_0"), val = tensor<int32, [4]>([0, 3, 1, 2])];
            tensor<string, []> model_time_distributed_MobilenetV3small_expanded_conv_5_squeeze_excite_Conv_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_5_squeeze_excite_Conv_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_5_squeeze_excite_Conv_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_5_squeeze_excite_Conv_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_5_squeeze_excite_Conv_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_5_squeeze_excite_Conv_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_time_distributed_MobilenetV3small_expanded_conv_5_squeeze_excite_Conv_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_5_squeeze_excite_Conv_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_5_squeeze_excite_Conv_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_5_squeeze_excite_Conv_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [64, 240, 1, 1]> conv_6_weight_0_to_fp16_quantized = constexpr_affine_dequantize()[axis = tensor<int32, []>(0), name = tensor<string, []>("conv_6_weight_0_to_fp16_quantized"), quantized_data = tensor<int8, [64, 240, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(124800))), scale = tensor<fp16, [64]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(140352))), zero_point = tensor<int8, [64]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(140224)))];
            tensor<fp16, [64]> conv_6_bias_0_to_fp16 = const()[name = tensor<string, []>("conv_6_bias_0_to_fp16"), val = tensor<fp16, [64]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(140544)))];
            tensor<fp16, [20, 240, 1, 1]> transpose_236 = transpose(perm = transpose_64_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_5_squeeze_excite_AvgPool_Mean_cast_fp16)[name = tensor<string, []>("transpose_58")];
            tensor<fp16, [20, 64, 1, 1]> conv_6_cast_fp16 = conv(bias = conv_6_bias_0_to_fp16, dilations = model_time_distributed_MobilenetV3small_expanded_conv_5_squeeze_excite_Conv_Conv2Dx_dilations_0, groups = model_time_distributed_MobilenetV3small_expanded_conv_5_squeeze_excite_Conv_Conv2Dx_groups_0, pad = model_time_distributed_MobilenetV3small_expanded_conv_5_squeeze_excite_Conv_Conv2Dx_pad_0, pad_type = model_time_distributed_MobilenetV3small_expanded_conv_5_squeeze_excite_Conv_Conv2Dx_pad_type_0, strides = model_time_distributed_MobilenetV3small_expanded_conv_5_squeeze_excite_Conv_Conv2Dx_strides_0, weight = conv_6_weight_0_to_fp16_quantized, x = transpose_236)[name = tensor<string, []>("conv_6_cast_fp16")];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_5_squeeze_excite_Conv_Conv2D_perm_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_5_squeeze_excite_Conv_Conv2D_perm_0"), val = tensor<int32, [4]>([0, 2, 3, 1])];
            tensor<fp16, [20, 1, 1, 64]> transpose_235 = transpose(perm = model_time_distributed_MobilenetV3small_expanded_conv_5_squeeze_excite_Conv_Conv2D_perm_0, x = conv_6_cast_fp16)[name = tensor<string, []>("transpose_57")];
            tensor<fp16, [20, 1, 1, 64]> model_time_distributed_MobilenetV3small_expanded_conv_5_squeeze_excite_Relu_Relu_cast_fp16 = relu(x = transpose_235)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_5_squeeze_excite_Relu_Relu_cast_fp16")];
            tensor<int32, [4]> transpose_66_perm_0 = const()[name = tensor<string, []>("transpose_66_perm_0"), val = tensor<int32, [4]>([0, 3, 1, 2])];
            tensor<string, []> model_time_distributed_MobilenetV3small_expanded_conv_5_squeeze_excite_Conv_1_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_5_squeeze_excite_Conv_1_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_5_squeeze_excite_Conv_1_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_5_squeeze_excite_Conv_1_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_5_squeeze_excite_Conv_1_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_5_squeeze_excite_Conv_1_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_time_distributed_MobilenetV3small_expanded_conv_5_squeeze_excite_Conv_1_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_5_squeeze_excite_Conv_1_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_5_squeeze_excite_Conv_1_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_5_squeeze_excite_Conv_1_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [240, 64, 1, 1]> conv_21_weight_0_to_fp16_quantized = constexpr_affine_dequantize()[axis = tensor<int32, []>(0), name = tensor<string, []>("conv_21_weight_0_to_fp16_quantized"), quantized_data = tensor<int8, [240, 64, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(140736))), scale = tensor<fp16, [240]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(156160))), zero_point = tensor<int8, [240]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(47872)))];
            tensor<fp16, [240]> conv_21_bias_0_to_fp16 = const()[name = tensor<string, []>("conv_21_bias_0_to_fp16"), val = tensor<fp16, [240]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(156736)))];
            tensor<fp16, [20, 64, 1, 1]> transpose_234 = transpose(perm = transpose_66_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_5_squeeze_excite_Relu_Relu_cast_fp16)[name = tensor<string, []>("transpose_56")];
            tensor<fp16, [20, 240, 1, 1]> conv_21_cast_fp16 = conv(bias = conv_21_bias_0_to_fp16, dilations = model_time_distributed_MobilenetV3small_expanded_conv_5_squeeze_excite_Conv_1_Conv2Dx_dilations_0, groups = model_time_distributed_MobilenetV3small_expanded_conv_5_squeeze_excite_Conv_1_Conv2Dx_groups_0, pad = model_time_distributed_MobilenetV3small_expanded_conv_5_squeeze_excite_Conv_1_Conv2Dx_pad_0, pad_type = model_time_distributed_MobilenetV3small_expanded_conv_5_squeeze_excite_Conv_1_Conv2Dx_pad_type_0, strides = model_time_distributed_MobilenetV3small_expanded_conv_5_squeeze_excite_Conv_1_Conv2Dx_strides_0, weight = conv_21_weight_0_to_fp16_quantized, x = transpose_234)[name = tensor<string, []>("conv_21_cast_fp16")];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_5_squeeze_excite_Conv_1_Conv2D_perm_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_5_squeeze_excite_Conv_1_Conv2D_perm_0"), val = tensor<int32, [4]>([0, 2, 3, 1])];
            tensor<fp16, [20, 1, 1, 240]> transpose_233 = transpose(perm = model_time_distributed_MobilenetV3small_expanded_conv_5_squeeze_excite_Conv_1_Conv2D_perm_0, x = conv_21_cast_fp16)[name = tensor<string, []>("transpose_55")];
            tensor<fp16, [20, 1, 1, 240]> model_time_distributed_MobilenetV3small_re_lu_15_Relu6_cast_fp16 = relu6(x = transpose_233)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_re_lu_15_Relu6_cast_fp16")];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_tf_math_multiply_10_Mul_y_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_multiply_10_Mul_y_to_fp16"), val = tensor<fp16, []>(0x1.554p-3)];
            tensor<fp16, [20, 1, 1, 240]> model_time_distributed_MobilenetV3small_tf_math_multiply_10_Mul_cast_fp16 = mul(x = model_time_distributed_MobilenetV3small_re_lu_15_Relu6_cast_fp16, y = model_time_distributed_MobilenetV3small_tf_math_multiply_10_Mul_y_to_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_multiply_10_Mul_cast_fp16")];
            tensor<fp16, [20, 14, 14, 240]> model_time_distributed_MobilenetV3small_expanded_conv_5_squeeze_excite_Mul_mul_cast_fp16 = mul(x = model_time_distributed_MobilenetV3small_multiply_6_mul_cast_fp16, y = model_time_distributed_MobilenetV3small_tf_math_multiply_10_Mul_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_5_squeeze_excite_Mul_mul_cast_fp16")];
            tensor<int32, [4]> transpose_68_perm_0 = const()[name = tensor<string, []>("transpose_68_perm_0"), val = tensor<int32, [4]>([0, 3, 1, 2])];
            tensor<string, []> model_time_distributed_MobilenetV3small_expanded_conv_5_project_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_5_project_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_5_project_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_5_project_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_5_project_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_5_project_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_time_distributed_MobilenetV3small_expanded_conv_5_project_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_5_project_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_5_project_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_5_project_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [40, 240, 1, 1]> transpose_67_to_fp16_quantized = constexpr_affine_dequantize()[axis = tensor<int32, []>(0), name = tensor<string, []>("transpose_67_to_fp16_quantized"), quantized_data = tensor<int8, [40, 240, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(157312))), scale = tensor<fp16, [40]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(167104))), zero_point = tensor<int8, [40]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(166976)))];
            tensor<fp16, [20, 240, 14, 14]> transpose_232 = transpose(perm = transpose_68_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_5_squeeze_excite_Mul_mul_cast_fp16)[name = tensor<string, []>("transpose_54")];
            tensor<fp16, [20, 40, 14, 14]> model_time_distributed_MobilenetV3small_expanded_conv_5_project_Conv2Dx_cast_fp16 = conv(dilations = model_time_distributed_MobilenetV3small_expanded_conv_5_project_Conv2Dx_dilations_0, groups = model_time_distributed_MobilenetV3small_expanded_conv_5_project_Conv2Dx_groups_0, pad = model_time_distributed_MobilenetV3small_expanded_conv_5_project_Conv2Dx_pad_0, pad_type = model_time_distributed_MobilenetV3small_expanded_conv_5_project_Conv2Dx_pad_type_0, strides = model_time_distributed_MobilenetV3small_expanded_conv_5_project_Conv2Dx_strides_0, weight = transpose_67_to_fp16_quantized, x = transpose_232)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_5_project_Conv2Dx_cast_fp16")];
            tensor<fp16, [40]> model_time_distributed_MobilenetV3small_expanded_conv_5_project_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_5_project_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16"), val = tensor<fp16, [40]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(167296)))];
            tensor<fp16, [40]> model_time_distributed_MobilenetV3small_expanded_conv_5_project_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_5_project_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16"), val = tensor<fp16, [40]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(167488)))];
            tensor<fp16, [40]> model_time_distributed_MobilenetV3small_expanded_conv_5_project_BatchNorm_ReadVariableOp_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_5_project_BatchNorm_ReadVariableOp_to_fp16"), val = tensor<fp16, [40]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(167680)))];
            tensor<fp16, [40]> model_time_distributed_MobilenetV3small_expanded_conv_5_project_BatchNorm_ReadVariableOp_1_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_5_project_BatchNorm_ReadVariableOp_1_to_fp16"), val = tensor<fp16, [40]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(167872)))];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_expanded_conv_5_project_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_5_project_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.064p-10)];
            tensor<fp16, [20, 40, 14, 14]> model_time_distributed_MobilenetV3small_expanded_conv_5_project_BatchNorm_FusedBatchNormV3_nchw_cast_fp16 = batch_norm(beta = model_time_distributed_MobilenetV3small_expanded_conv_5_project_BatchNorm_ReadVariableOp_1_to_fp16, epsilon = model_time_distributed_MobilenetV3small_expanded_conv_5_project_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16, gamma = model_time_distributed_MobilenetV3small_expanded_conv_5_project_BatchNorm_ReadVariableOp_to_fp16, mean = model_time_distributed_MobilenetV3small_expanded_conv_5_project_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16, variance = model_time_distributed_MobilenetV3small_expanded_conv_5_project_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16, x = model_time_distributed_MobilenetV3small_expanded_conv_5_project_Conv2Dx_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_5_project_BatchNorm_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_5_project_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_5_project_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0"), val = tensor<int32, [4]>([0, 2, 3, 1])];
            tensor<fp16, [20, 14, 14, 40]> transpose_231 = transpose(perm = model_time_distributed_MobilenetV3small_expanded_conv_5_project_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_5_project_BatchNorm_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("transpose_53")];
            tensor<fp16, [20, 14, 14, 40]> model_time_distributed_MobilenetV3small_expanded_conv_5_Add_add_cast_fp16 = add(x = model_time_distributed_MobilenetV3small_expanded_conv_4_Add_add_cast_fp16, y = transpose_231)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_5_Add_add_cast_fp16")];
            tensor<int32, [4]> transpose_71_perm_0 = const()[name = tensor<string, []>("transpose_71_perm_0"), val = tensor<int32, [4]>([0, 3, 1, 2])];
            tensor<string, []> model_time_distributed_MobilenetV3small_expanded_conv_6_expand_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_6_expand_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_6_expand_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_6_expand_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_6_expand_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_6_expand_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_time_distributed_MobilenetV3small_expanded_conv_6_expand_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_6_expand_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_6_expand_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_6_expand_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [120, 40, 1, 1]> transpose_70_to_fp16_quantized = constexpr_affine_dequantize()[axis = tensor<int32, []>(0), name = tensor<string, []>("transpose_70_to_fp16_quantized"), quantized_data = tensor<int8, [120, 40, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(168064))), scale = tensor<fp16, [120]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(173120))), zero_point = tensor<int8, [120]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(172928)))];
            tensor<fp16, [20, 40, 14, 14]> transpose_230 = transpose(perm = transpose_71_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_5_Add_add_cast_fp16)[name = tensor<string, []>("transpose_52")];
            tensor<fp16, [20, 120, 14, 14]> model_time_distributed_MobilenetV3small_expanded_conv_6_expand_Conv2Dx_cast_fp16 = conv(dilations = model_time_distributed_MobilenetV3small_expanded_conv_6_expand_Conv2Dx_dilations_0, groups = model_time_distributed_MobilenetV3small_expanded_conv_6_expand_Conv2Dx_groups_0, pad = model_time_distributed_MobilenetV3small_expanded_conv_6_expand_Conv2Dx_pad_0, pad_type = model_time_distributed_MobilenetV3small_expanded_conv_6_expand_Conv2Dx_pad_type_0, strides = model_time_distributed_MobilenetV3small_expanded_conv_6_expand_Conv2Dx_strides_0, weight = transpose_70_to_fp16_quantized, x = transpose_230)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_6_expand_Conv2Dx_cast_fp16")];
            tensor<fp16, [120]> model_time_distributed_MobilenetV3small_expanded_conv_6_expand_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_6_expand_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16"), val = tensor<fp16, [120]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(173440)))];
            tensor<fp16, [120]> model_time_distributed_MobilenetV3small_expanded_conv_6_expand_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_6_expand_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16"), val = tensor<fp16, [120]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(173760)))];
            tensor<fp16, [120]> model_time_distributed_MobilenetV3small_expanded_conv_6_expand_BatchNorm_ReadVariableOp_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_6_expand_BatchNorm_ReadVariableOp_to_fp16"), val = tensor<fp16, [120]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(174080)))];
            tensor<fp16, [120]> model_time_distributed_MobilenetV3small_expanded_conv_6_expand_BatchNorm_ReadVariableOp_1_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_6_expand_BatchNorm_ReadVariableOp_1_to_fp16"), val = tensor<fp16, [120]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(174400)))];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_expanded_conv_6_expand_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_6_expand_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.064p-10)];
            tensor<fp16, [20, 120, 14, 14]> model_time_distributed_MobilenetV3small_expanded_conv_6_expand_BatchNorm_FusedBatchNormV3_nchw_cast_fp16 = batch_norm(beta = model_time_distributed_MobilenetV3small_expanded_conv_6_expand_BatchNorm_ReadVariableOp_1_to_fp16, epsilon = model_time_distributed_MobilenetV3small_expanded_conv_6_expand_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16, gamma = model_time_distributed_MobilenetV3small_expanded_conv_6_expand_BatchNorm_ReadVariableOp_to_fp16, mean = model_time_distributed_MobilenetV3small_expanded_conv_6_expand_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16, variance = model_time_distributed_MobilenetV3small_expanded_conv_6_expand_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16, x = model_time_distributed_MobilenetV3small_expanded_conv_6_expand_Conv2Dx_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_6_expand_BatchNorm_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_6_expand_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_6_expand_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0"), val = tensor<int32, [4]>([0, 2, 3, 1])];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_tf_math_add_11_Add_y_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_add_11_Add_y_to_fp16"), val = tensor<fp16, []>(0x1.8p+1)];
            tensor<fp16, [20, 14, 14, 120]> transpose_229 = transpose(perm = model_time_distributed_MobilenetV3small_expanded_conv_6_expand_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_6_expand_BatchNorm_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("transpose_51")];
            tensor<fp16, [20, 14, 14, 120]> model_time_distributed_MobilenetV3small_tf_math_add_11_Add_cast_fp16 = add(x = transpose_229, y = model_time_distributed_MobilenetV3small_tf_math_add_11_Add_y_to_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_add_11_Add_cast_fp16")];
            tensor<fp16, [20, 14, 14, 120]> model_time_distributed_MobilenetV3small_re_lu_16_Relu6_cast_fp16 = relu6(x = model_time_distributed_MobilenetV3small_tf_math_add_11_Add_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_re_lu_16_Relu6_cast_fp16")];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_tf_math_multiply_11_Mul_y_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_multiply_11_Mul_y_to_fp16"), val = tensor<fp16, []>(0x1.554p-3)];
            tensor<fp16, [20, 14, 14, 120]> model_time_distributed_MobilenetV3small_tf_math_multiply_11_Mul_cast_fp16 = mul(x = model_time_distributed_MobilenetV3small_re_lu_16_Relu6_cast_fp16, y = model_time_distributed_MobilenetV3small_tf_math_multiply_11_Mul_y_to_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_multiply_11_Mul_cast_fp16")];
            tensor<fp16, [20, 14, 14, 120]> model_time_distributed_MobilenetV3small_multiply_7_mul_cast_fp16 = mul(x = transpose_229, y = model_time_distributed_MobilenetV3small_tf_math_multiply_11_Mul_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_multiply_7_mul_cast_fp16")];
            tensor<int32, [4]> transpose_74_perm_0 = const()[name = tensor<string, []>("transpose_74_perm_0"), val = tensor<int32, [4]>([0, 3, 1, 2])];
            tensor<string, []> model_time_distributed_MobilenetV3small_expanded_conv_6_depthwise_depthwisex_pad_type_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_6_depthwise_depthwisex_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_6_depthwise_depthwisex_strides_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_6_depthwise_depthwisex_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_6_depthwise_depthwisex_dilations_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_6_depthwise_depthwisex_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_time_distributed_MobilenetV3small_expanded_conv_6_depthwise_depthwisex_groups_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_6_depthwise_depthwisex_groups_0"), val = tensor<int32, []>(120)];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_6_depthwise_depthwisex_pad_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_6_depthwise_depthwisex_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [120, 1, 5, 5]> transpose_73_to_fp16_quantized = constexpr_affine_dequantize()[axis = tensor<int32, []>(0), name = tensor<string, []>("transpose_73_to_fp16_quantized"), quantized_data = tensor<int8, [120, 1, 5, 5]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(174720))), scale = tensor<fp16, [120]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(177792))), zero_point = tensor<int8, [120]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(172928)))];
            tensor<fp16, [20, 120, 14, 14]> transpose_228 = transpose(perm = transpose_74_perm_0, x = model_time_distributed_MobilenetV3small_multiply_7_mul_cast_fp16)[name = tensor<string, []>("transpose_50")];
            tensor<fp16, [20, 120, 14, 14]> model_time_distributed_MobilenetV3small_expanded_conv_6_depthwise_depthwisex_cast_fp16 = conv(dilations = model_time_distributed_MobilenetV3small_expanded_conv_6_depthwise_depthwisex_dilations_0, groups = model_time_distributed_MobilenetV3small_expanded_conv_6_depthwise_depthwisex_groups_0, pad = model_time_distributed_MobilenetV3small_expanded_conv_6_depthwise_depthwisex_pad_0, pad_type = model_time_distributed_MobilenetV3small_expanded_conv_6_depthwise_depthwisex_pad_type_0, strides = model_time_distributed_MobilenetV3small_expanded_conv_6_depthwise_depthwisex_strides_0, weight = transpose_73_to_fp16_quantized, x = transpose_228)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_6_depthwise_depthwisex_cast_fp16")];
            tensor<fp16, [120]> model_time_distributed_MobilenetV3small_expanded_conv_6_depthwise_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_6_depthwise_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16"), val = tensor<fp16, [120]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(178112)))];
            tensor<fp16, [120]> model_time_distributed_MobilenetV3small_expanded_conv_6_depthwise_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_6_depthwise_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16"), val = tensor<fp16, [120]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(178432)))];
            tensor<fp16, [120]> model_time_distributed_MobilenetV3small_expanded_conv_6_depthwise_BatchNorm_ReadVariableOp_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_6_depthwise_BatchNorm_ReadVariableOp_to_fp16"), val = tensor<fp16, [120]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(178752)))];
            tensor<fp16, [120]> model_time_distributed_MobilenetV3small_expanded_conv_6_depthwise_BatchNorm_ReadVariableOp_1_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_6_depthwise_BatchNorm_ReadVariableOp_1_to_fp16"), val = tensor<fp16, [120]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(179072)))];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_expanded_conv_6_depthwise_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_6_depthwise_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.064p-10)];
            tensor<fp16, [20, 120, 14, 14]> model_time_distributed_MobilenetV3small_expanded_conv_6_depthwise_BatchNorm_FusedBatchNormV3_nchw_cast_fp16 = batch_norm(beta = model_time_distributed_MobilenetV3small_expanded_conv_6_depthwise_BatchNorm_ReadVariableOp_1_to_fp16, epsilon = model_time_distributed_MobilenetV3small_expanded_conv_6_depthwise_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16, gamma = model_time_distributed_MobilenetV3small_expanded_conv_6_depthwise_BatchNorm_ReadVariableOp_to_fp16, mean = model_time_distributed_MobilenetV3small_expanded_conv_6_depthwise_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16, variance = model_time_distributed_MobilenetV3small_expanded_conv_6_depthwise_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16, x = model_time_distributed_MobilenetV3small_expanded_conv_6_depthwise_depthwisex_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_6_depthwise_BatchNorm_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_6_depthwise_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_6_depthwise_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0"), val = tensor<int32, [4]>([0, 2, 3, 1])];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_tf_math_add_12_Add_y_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_add_12_Add_y_to_fp16"), val = tensor<fp16, []>(0x1.8p+1)];
            tensor<fp16, [20, 14, 14, 120]> transpose_227 = transpose(perm = model_time_distributed_MobilenetV3small_expanded_conv_6_depthwise_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_6_depthwise_BatchNorm_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("transpose_49")];
            tensor<fp16, [20, 14, 14, 120]> model_time_distributed_MobilenetV3small_tf_math_add_12_Add_cast_fp16 = add(x = transpose_227, y = model_time_distributed_MobilenetV3small_tf_math_add_12_Add_y_to_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_add_12_Add_cast_fp16")];
            tensor<fp16, [20, 14, 14, 120]> model_time_distributed_MobilenetV3small_re_lu_17_Relu6_cast_fp16 = relu6(x = model_time_distributed_MobilenetV3small_tf_math_add_12_Add_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_re_lu_17_Relu6_cast_fp16")];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_tf_math_multiply_12_Mul_y_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_multiply_12_Mul_y_to_fp16"), val = tensor<fp16, []>(0x1.554p-3)];
            tensor<fp16, [20, 14, 14, 120]> model_time_distributed_MobilenetV3small_tf_math_multiply_12_Mul_cast_fp16 = mul(x = model_time_distributed_MobilenetV3small_re_lu_17_Relu6_cast_fp16, y = model_time_distributed_MobilenetV3small_tf_math_multiply_12_Mul_y_to_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_multiply_12_Mul_cast_fp16")];
            tensor<fp16, [20, 14, 14, 120]> model_time_distributed_MobilenetV3small_multiply_8_mul_cast_fp16 = mul(x = transpose_227, y = model_time_distributed_MobilenetV3small_tf_math_multiply_12_Mul_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_multiply_8_mul_cast_fp16")];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_6_squeeze_excite_AvgPool_Mean_axes_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_6_squeeze_excite_AvgPool_Mean_axes_0"), val = tensor<int32, [2]>([1, 2])];
            tensor<bool, []> model_time_distributed_MobilenetV3small_expanded_conv_6_squeeze_excite_AvgPool_Mean_keep_dims_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_6_squeeze_excite_AvgPool_Mean_keep_dims_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [20, 1, 1, 120]> model_time_distributed_MobilenetV3small_expanded_conv_6_squeeze_excite_AvgPool_Mean_cast_fp16 = reduce_mean(axes = model_time_distributed_MobilenetV3small_expanded_conv_6_squeeze_excite_AvgPool_Mean_axes_0, keep_dims = model_time_distributed_MobilenetV3small_expanded_conv_6_squeeze_excite_AvgPool_Mean_keep_dims_0, x = model_time_distributed_MobilenetV3small_multiply_8_mul_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_6_squeeze_excite_AvgPool_Mean_cast_fp16")];
            tensor<int32, [4]> transpose_77_perm_0 = const()[name = tensor<string, []>("transpose_77_perm_0"), val = tensor<int32, [4]>([0, 3, 1, 2])];
            tensor<string, []> model_time_distributed_MobilenetV3small_expanded_conv_6_squeeze_excite_Conv_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_6_squeeze_excite_Conv_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_6_squeeze_excite_Conv_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_6_squeeze_excite_Conv_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_6_squeeze_excite_Conv_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_6_squeeze_excite_Conv_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_time_distributed_MobilenetV3small_expanded_conv_6_squeeze_excite_Conv_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_6_squeeze_excite_Conv_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_6_squeeze_excite_Conv_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_6_squeeze_excite_Conv_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [32, 120, 1, 1]> conv_8_weight_0_to_fp16_quantized = constexpr_affine_dequantize()[axis = tensor<int32, []>(0), name = tensor<string, []>("conv_8_weight_0_to_fp16_quantized"), quantized_data = tensor<int8, [32, 120, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(179392))), scale = tensor<fp16, [32]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(183424))), zero_point = tensor<int8, [32]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(183296)))];
            tensor<fp16, [32]> conv_8_bias_0_to_fp16 = const()[name = tensor<string, []>("conv_8_bias_0_to_fp16"), val = tensor<fp16, [32]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(183552)))];
            tensor<fp16, [20, 120, 1, 1]> transpose_226 = transpose(perm = transpose_77_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_6_squeeze_excite_AvgPool_Mean_cast_fp16)[name = tensor<string, []>("transpose_48")];
            tensor<fp16, [20, 32, 1, 1]> conv_8_cast_fp16 = conv(bias = conv_8_bias_0_to_fp16, dilations = model_time_distributed_MobilenetV3small_expanded_conv_6_squeeze_excite_Conv_Conv2Dx_dilations_0, groups = model_time_distributed_MobilenetV3small_expanded_conv_6_squeeze_excite_Conv_Conv2Dx_groups_0, pad = model_time_distributed_MobilenetV3small_expanded_conv_6_squeeze_excite_Conv_Conv2Dx_pad_0, pad_type = model_time_distributed_MobilenetV3small_expanded_conv_6_squeeze_excite_Conv_Conv2Dx_pad_type_0, strides = model_time_distributed_MobilenetV3small_expanded_conv_6_squeeze_excite_Conv_Conv2Dx_strides_0, weight = conv_8_weight_0_to_fp16_quantized, x = transpose_226)[name = tensor<string, []>("conv_8_cast_fp16")];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_6_squeeze_excite_Conv_Conv2D_perm_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_6_squeeze_excite_Conv_Conv2D_perm_0"), val = tensor<int32, [4]>([0, 2, 3, 1])];
            tensor<fp16, [20, 1, 1, 32]> transpose_225 = transpose(perm = model_time_distributed_MobilenetV3small_expanded_conv_6_squeeze_excite_Conv_Conv2D_perm_0, x = conv_8_cast_fp16)[name = tensor<string, []>("transpose_47")];
            tensor<fp16, [20, 1, 1, 32]> model_time_distributed_MobilenetV3small_expanded_conv_6_squeeze_excite_Relu_Relu_cast_fp16 = relu(x = transpose_225)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_6_squeeze_excite_Relu_Relu_cast_fp16")];
            tensor<int32, [4]> transpose_79_perm_0 = const()[name = tensor<string, []>("transpose_79_perm_0"), val = tensor<int32, [4]>([0, 3, 1, 2])];
            tensor<string, []> model_time_distributed_MobilenetV3small_expanded_conv_6_squeeze_excite_Conv_1_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_6_squeeze_excite_Conv_1_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_6_squeeze_excite_Conv_1_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_6_squeeze_excite_Conv_1_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_6_squeeze_excite_Conv_1_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_6_squeeze_excite_Conv_1_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_time_distributed_MobilenetV3small_expanded_conv_6_squeeze_excite_Conv_1_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_6_squeeze_excite_Conv_1_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_6_squeeze_excite_Conv_1_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_6_squeeze_excite_Conv_1_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [120, 32, 1, 1]> conv_22_weight_0_to_fp16_quantized = constexpr_affine_dequantize()[axis = tensor<int32, []>(0), name = tensor<string, []>("conv_22_weight_0_to_fp16_quantized"), quantized_data = tensor<int8, [120, 32, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(183680))), scale = tensor<fp16, [120]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(187584))), zero_point = tensor<int8, [120]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(172928)))];
            tensor<fp16, [120]> conv_22_bias_0_to_fp16 = const()[name = tensor<string, []>("conv_22_bias_0_to_fp16"), val = tensor<fp16, [120]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(187904)))];
            tensor<fp16, [20, 32, 1, 1]> transpose_224 = transpose(perm = transpose_79_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_6_squeeze_excite_Relu_Relu_cast_fp16)[name = tensor<string, []>("transpose_46")];
            tensor<fp16, [20, 120, 1, 1]> conv_22_cast_fp16 = conv(bias = conv_22_bias_0_to_fp16, dilations = model_time_distributed_MobilenetV3small_expanded_conv_6_squeeze_excite_Conv_1_Conv2Dx_dilations_0, groups = model_time_distributed_MobilenetV3small_expanded_conv_6_squeeze_excite_Conv_1_Conv2Dx_groups_0, pad = model_time_distributed_MobilenetV3small_expanded_conv_6_squeeze_excite_Conv_1_Conv2Dx_pad_0, pad_type = model_time_distributed_MobilenetV3small_expanded_conv_6_squeeze_excite_Conv_1_Conv2Dx_pad_type_0, strides = model_time_distributed_MobilenetV3small_expanded_conv_6_squeeze_excite_Conv_1_Conv2Dx_strides_0, weight = conv_22_weight_0_to_fp16_quantized, x = transpose_224)[name = tensor<string, []>("conv_22_cast_fp16")];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_6_squeeze_excite_Conv_1_Conv2D_perm_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_6_squeeze_excite_Conv_1_Conv2D_perm_0"), val = tensor<int32, [4]>([0, 2, 3, 1])];
            tensor<fp16, [20, 1, 1, 120]> transpose_223 = transpose(perm = model_time_distributed_MobilenetV3small_expanded_conv_6_squeeze_excite_Conv_1_Conv2D_perm_0, x = conv_22_cast_fp16)[name = tensor<string, []>("transpose_45")];
            tensor<fp16, [20, 1, 1, 120]> model_time_distributed_MobilenetV3small_re_lu_18_Relu6_cast_fp16 = relu6(x = transpose_223)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_re_lu_18_Relu6_cast_fp16")];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_tf_math_multiply_13_Mul_y_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_multiply_13_Mul_y_to_fp16"), val = tensor<fp16, []>(0x1.554p-3)];
            tensor<fp16, [20, 1, 1, 120]> model_time_distributed_MobilenetV3small_tf_math_multiply_13_Mul_cast_fp16 = mul(x = model_time_distributed_MobilenetV3small_re_lu_18_Relu6_cast_fp16, y = model_time_distributed_MobilenetV3small_tf_math_multiply_13_Mul_y_to_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_multiply_13_Mul_cast_fp16")];
            tensor<fp16, [20, 14, 14, 120]> model_time_distributed_MobilenetV3small_expanded_conv_6_squeeze_excite_Mul_mul_cast_fp16 = mul(x = model_time_distributed_MobilenetV3small_multiply_8_mul_cast_fp16, y = model_time_distributed_MobilenetV3small_tf_math_multiply_13_Mul_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_6_squeeze_excite_Mul_mul_cast_fp16")];
            tensor<int32, [4]> transpose_81_perm_0 = const()[name = tensor<string, []>("transpose_81_perm_0"), val = tensor<int32, [4]>([0, 3, 1, 2])];
            tensor<string, []> model_time_distributed_MobilenetV3small_expanded_conv_6_project_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_6_project_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_6_project_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_6_project_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_6_project_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_6_project_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_time_distributed_MobilenetV3small_expanded_conv_6_project_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_6_project_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_6_project_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_6_project_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [48, 120, 1, 1]> transpose_80_to_fp16_quantized = constexpr_affine_dequantize()[axis = tensor<int32, []>(0), name = tensor<string, []>("transpose_80_to_fp16_quantized"), quantized_data = tensor<int8, [48, 120, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(188224))), scale = tensor<fp16, [48]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(194176))), zero_point = tensor<int8, [48]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(194048)))];
            tensor<fp16, [20, 120, 14, 14]> transpose_222 = transpose(perm = transpose_81_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_6_squeeze_excite_Mul_mul_cast_fp16)[name = tensor<string, []>("transpose_44")];
            tensor<fp16, [20, 48, 14, 14]> model_time_distributed_MobilenetV3small_expanded_conv_6_project_Conv2Dx_cast_fp16 = conv(dilations = model_time_distributed_MobilenetV3small_expanded_conv_6_project_Conv2Dx_dilations_0, groups = model_time_distributed_MobilenetV3small_expanded_conv_6_project_Conv2Dx_groups_0, pad = model_time_distributed_MobilenetV3small_expanded_conv_6_project_Conv2Dx_pad_0, pad_type = model_time_distributed_MobilenetV3small_expanded_conv_6_project_Conv2Dx_pad_type_0, strides = model_time_distributed_MobilenetV3small_expanded_conv_6_project_Conv2Dx_strides_0, weight = transpose_80_to_fp16_quantized, x = transpose_222)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_6_project_Conv2Dx_cast_fp16")];
            tensor<fp16, [48]> model_time_distributed_MobilenetV3small_expanded_conv_6_project_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_6_project_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16"), val = tensor<fp16, [48]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(194368)))];
            tensor<fp16, [48]> model_time_distributed_MobilenetV3small_expanded_conv_6_project_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_6_project_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16"), val = tensor<fp16, [48]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(194560)))];
            tensor<fp16, [48]> model_time_distributed_MobilenetV3small_expanded_conv_6_project_BatchNorm_ReadVariableOp_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_6_project_BatchNorm_ReadVariableOp_to_fp16"), val = tensor<fp16, [48]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(194752)))];
            tensor<fp16, [48]> model_time_distributed_MobilenetV3small_expanded_conv_6_project_BatchNorm_ReadVariableOp_1_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_6_project_BatchNorm_ReadVariableOp_1_to_fp16"), val = tensor<fp16, [48]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(194944)))];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_expanded_conv_6_project_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_6_project_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.064p-10)];
            tensor<fp16, [20, 48, 14, 14]> model_time_distributed_MobilenetV3small_expanded_conv_6_project_BatchNorm_FusedBatchNormV3_nchw_cast_fp16 = batch_norm(beta = model_time_distributed_MobilenetV3small_expanded_conv_6_project_BatchNorm_ReadVariableOp_1_to_fp16, epsilon = model_time_distributed_MobilenetV3small_expanded_conv_6_project_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16, gamma = model_time_distributed_MobilenetV3small_expanded_conv_6_project_BatchNorm_ReadVariableOp_to_fp16, mean = model_time_distributed_MobilenetV3small_expanded_conv_6_project_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16, variance = model_time_distributed_MobilenetV3small_expanded_conv_6_project_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16, x = model_time_distributed_MobilenetV3small_expanded_conv_6_project_Conv2Dx_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_6_project_BatchNorm_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_6_project_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_6_project_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0"), val = tensor<int32, [4]>([0, 2, 3, 1])];
            tensor<int32, [4]> transpose_84_perm_0 = const()[name = tensor<string, []>("transpose_84_perm_0"), val = tensor<int32, [4]>([0, 3, 1, 2])];
            tensor<string, []> model_time_distributed_MobilenetV3small_expanded_conv_7_expand_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_7_expand_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_7_expand_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_7_expand_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_7_expand_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_7_expand_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_time_distributed_MobilenetV3small_expanded_conv_7_expand_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_7_expand_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_7_expand_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_7_expand_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [144, 48, 1, 1]> transpose_83_to_fp16_quantized = constexpr_affine_dequantize()[axis = tensor<int32, []>(0), name = tensor<string, []>("transpose_83_to_fp16_quantized"), quantized_data = tensor<int8, [144, 48, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(195136))), scale = tensor<fp16, [144]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(202368))), zero_point = tensor<int8, [144]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(202112)))];
            tensor<fp16, [20, 14, 14, 48]> transpose_221 = transpose(perm = model_time_distributed_MobilenetV3small_expanded_conv_6_project_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_6_project_BatchNorm_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("transpose_43")];
            tensor<fp16, [20, 48, 14, 14]> transpose_220 = transpose(perm = transpose_84_perm_0, x = transpose_221)[name = tensor<string, []>("transpose_42")];
            tensor<fp16, [20, 144, 14, 14]> model_time_distributed_MobilenetV3small_expanded_conv_7_expand_Conv2Dx_cast_fp16 = conv(dilations = model_time_distributed_MobilenetV3small_expanded_conv_7_expand_Conv2Dx_dilations_0, groups = model_time_distributed_MobilenetV3small_expanded_conv_7_expand_Conv2Dx_groups_0, pad = model_time_distributed_MobilenetV3small_expanded_conv_7_expand_Conv2Dx_pad_0, pad_type = model_time_distributed_MobilenetV3small_expanded_conv_7_expand_Conv2Dx_pad_type_0, strides = model_time_distributed_MobilenetV3small_expanded_conv_7_expand_Conv2Dx_strides_0, weight = transpose_83_to_fp16_quantized, x = transpose_220)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_7_expand_Conv2Dx_cast_fp16")];
            tensor<fp16, [144]> model_time_distributed_MobilenetV3small_expanded_conv_7_expand_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_7_expand_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16"), val = tensor<fp16, [144]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(202752)))];
            tensor<fp16, [144]> model_time_distributed_MobilenetV3small_expanded_conv_7_expand_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_7_expand_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16"), val = tensor<fp16, [144]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(203136)))];
            tensor<fp16, [144]> model_time_distributed_MobilenetV3small_expanded_conv_7_expand_BatchNorm_ReadVariableOp_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_7_expand_BatchNorm_ReadVariableOp_to_fp16"), val = tensor<fp16, [144]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(203520)))];
            tensor<fp16, [144]> model_time_distributed_MobilenetV3small_expanded_conv_7_expand_BatchNorm_ReadVariableOp_1_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_7_expand_BatchNorm_ReadVariableOp_1_to_fp16"), val = tensor<fp16, [144]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(203904)))];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_expanded_conv_7_expand_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_7_expand_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.064p-10)];
            tensor<fp16, [20, 144, 14, 14]> model_time_distributed_MobilenetV3small_expanded_conv_7_expand_BatchNorm_FusedBatchNormV3_nchw_cast_fp16 = batch_norm(beta = model_time_distributed_MobilenetV3small_expanded_conv_7_expand_BatchNorm_ReadVariableOp_1_to_fp16, epsilon = model_time_distributed_MobilenetV3small_expanded_conv_7_expand_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16, gamma = model_time_distributed_MobilenetV3small_expanded_conv_7_expand_BatchNorm_ReadVariableOp_to_fp16, mean = model_time_distributed_MobilenetV3small_expanded_conv_7_expand_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16, variance = model_time_distributed_MobilenetV3small_expanded_conv_7_expand_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16, x = model_time_distributed_MobilenetV3small_expanded_conv_7_expand_Conv2Dx_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_7_expand_BatchNorm_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_7_expand_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_7_expand_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0"), val = tensor<int32, [4]>([0, 2, 3, 1])];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_tf_math_add_14_Add_y_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_add_14_Add_y_to_fp16"), val = tensor<fp16, []>(0x1.8p+1)];
            tensor<fp16, [20, 14, 14, 144]> transpose_219 = transpose(perm = model_time_distributed_MobilenetV3small_expanded_conv_7_expand_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_7_expand_BatchNorm_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("transpose_41")];
            tensor<fp16, [20, 14, 14, 144]> model_time_distributed_MobilenetV3small_tf_math_add_14_Add_cast_fp16 = add(x = transpose_219, y = model_time_distributed_MobilenetV3small_tf_math_add_14_Add_y_to_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_add_14_Add_cast_fp16")];
            tensor<fp16, [20, 14, 14, 144]> model_time_distributed_MobilenetV3small_re_lu_19_Relu6_cast_fp16 = relu6(x = model_time_distributed_MobilenetV3small_tf_math_add_14_Add_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_re_lu_19_Relu6_cast_fp16")];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_tf_math_multiply_14_Mul_y_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_multiply_14_Mul_y_to_fp16"), val = tensor<fp16, []>(0x1.554p-3)];
            tensor<fp16, [20, 14, 14, 144]> model_time_distributed_MobilenetV3small_tf_math_multiply_14_Mul_cast_fp16 = mul(x = model_time_distributed_MobilenetV3small_re_lu_19_Relu6_cast_fp16, y = model_time_distributed_MobilenetV3small_tf_math_multiply_14_Mul_y_to_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_multiply_14_Mul_cast_fp16")];
            tensor<fp16, [20, 14, 14, 144]> model_time_distributed_MobilenetV3small_multiply_9_mul_cast_fp16 = mul(x = transpose_219, y = model_time_distributed_MobilenetV3small_tf_math_multiply_14_Mul_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_multiply_9_mul_cast_fp16")];
            tensor<int32, [4]> transpose_87_perm_0 = const()[name = tensor<string, []>("transpose_87_perm_0"), val = tensor<int32, [4]>([0, 3, 1, 2])];
            tensor<string, []> model_time_distributed_MobilenetV3small_expanded_conv_7_depthwise_depthwisex_pad_type_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_7_depthwise_depthwisex_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_7_depthwise_depthwisex_strides_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_7_depthwise_depthwisex_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_7_depthwise_depthwisex_dilations_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_7_depthwise_depthwisex_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_time_distributed_MobilenetV3small_expanded_conv_7_depthwise_depthwisex_groups_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_7_depthwise_depthwisex_groups_0"), val = tensor<int32, []>(144)];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_7_depthwise_depthwisex_pad_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_7_depthwise_depthwisex_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [144, 1, 5, 5]> transpose_86_to_fp16_quantized = constexpr_affine_dequantize()[axis = tensor<int32, []>(0), name = tensor<string, []>("transpose_86_to_fp16_quantized"), quantized_data = tensor<int8, [144, 1, 5, 5]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(204288))), scale = tensor<fp16, [144]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(208000))), zero_point = tensor<int8, [144]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(202112)))];
            tensor<fp16, [20, 144, 14, 14]> transpose_218 = transpose(perm = transpose_87_perm_0, x = model_time_distributed_MobilenetV3small_multiply_9_mul_cast_fp16)[name = tensor<string, []>("transpose_40")];
            tensor<fp16, [20, 144, 14, 14]> model_time_distributed_MobilenetV3small_expanded_conv_7_depthwise_depthwisex_cast_fp16 = conv(dilations = model_time_distributed_MobilenetV3small_expanded_conv_7_depthwise_depthwisex_dilations_0, groups = model_time_distributed_MobilenetV3small_expanded_conv_7_depthwise_depthwisex_groups_0, pad = model_time_distributed_MobilenetV3small_expanded_conv_7_depthwise_depthwisex_pad_0, pad_type = model_time_distributed_MobilenetV3small_expanded_conv_7_depthwise_depthwisex_pad_type_0, strides = model_time_distributed_MobilenetV3small_expanded_conv_7_depthwise_depthwisex_strides_0, weight = transpose_86_to_fp16_quantized, x = transpose_218)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_7_depthwise_depthwisex_cast_fp16")];
            tensor<fp16, [144]> model_time_distributed_MobilenetV3small_expanded_conv_7_depthwise_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_7_depthwise_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16"), val = tensor<fp16, [144]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(208384)))];
            tensor<fp16, [144]> model_time_distributed_MobilenetV3small_expanded_conv_7_depthwise_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_7_depthwise_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16"), val = tensor<fp16, [144]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(208768)))];
            tensor<fp16, [144]> model_time_distributed_MobilenetV3small_expanded_conv_7_depthwise_BatchNorm_ReadVariableOp_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_7_depthwise_BatchNorm_ReadVariableOp_to_fp16"), val = tensor<fp16, [144]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(209152)))];
            tensor<fp16, [144]> model_time_distributed_MobilenetV3small_expanded_conv_7_depthwise_BatchNorm_ReadVariableOp_1_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_7_depthwise_BatchNorm_ReadVariableOp_1_to_fp16"), val = tensor<fp16, [144]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(209536)))];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_expanded_conv_7_depthwise_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_7_depthwise_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.064p-10)];
            tensor<fp16, [20, 144, 14, 14]> model_time_distributed_MobilenetV3small_expanded_conv_7_depthwise_BatchNorm_FusedBatchNormV3_nchw_cast_fp16 = batch_norm(beta = model_time_distributed_MobilenetV3small_expanded_conv_7_depthwise_BatchNorm_ReadVariableOp_1_to_fp16, epsilon = model_time_distributed_MobilenetV3small_expanded_conv_7_depthwise_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16, gamma = model_time_distributed_MobilenetV3small_expanded_conv_7_depthwise_BatchNorm_ReadVariableOp_to_fp16, mean = model_time_distributed_MobilenetV3small_expanded_conv_7_depthwise_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16, variance = model_time_distributed_MobilenetV3small_expanded_conv_7_depthwise_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16, x = model_time_distributed_MobilenetV3small_expanded_conv_7_depthwise_depthwisex_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_7_depthwise_BatchNorm_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_7_depthwise_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_7_depthwise_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0"), val = tensor<int32, [4]>([0, 2, 3, 1])];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_tf_math_add_15_Add_y_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_add_15_Add_y_to_fp16"), val = tensor<fp16, []>(0x1.8p+1)];
            tensor<fp16, [20, 14, 14, 144]> transpose_217 = transpose(perm = model_time_distributed_MobilenetV3small_expanded_conv_7_depthwise_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_7_depthwise_BatchNorm_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("transpose_39")];
            tensor<fp16, [20, 14, 14, 144]> model_time_distributed_MobilenetV3small_tf_math_add_15_Add_cast_fp16 = add(x = transpose_217, y = model_time_distributed_MobilenetV3small_tf_math_add_15_Add_y_to_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_add_15_Add_cast_fp16")];
            tensor<fp16, [20, 14, 14, 144]> model_time_distributed_MobilenetV3small_re_lu_20_Relu6_cast_fp16 = relu6(x = model_time_distributed_MobilenetV3small_tf_math_add_15_Add_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_re_lu_20_Relu6_cast_fp16")];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_tf_math_multiply_15_Mul_y_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_multiply_15_Mul_y_to_fp16"), val = tensor<fp16, []>(0x1.554p-3)];
            tensor<fp16, [20, 14, 14, 144]> model_time_distributed_MobilenetV3small_tf_math_multiply_15_Mul_cast_fp16 = mul(x = model_time_distributed_MobilenetV3small_re_lu_20_Relu6_cast_fp16, y = model_time_distributed_MobilenetV3small_tf_math_multiply_15_Mul_y_to_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_multiply_15_Mul_cast_fp16")];
            tensor<fp16, [20, 14, 14, 144]> model_time_distributed_MobilenetV3small_multiply_10_mul_cast_fp16 = mul(x = transpose_217, y = model_time_distributed_MobilenetV3small_tf_math_multiply_15_Mul_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_multiply_10_mul_cast_fp16")];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_7_squeeze_excite_AvgPool_Mean_axes_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_7_squeeze_excite_AvgPool_Mean_axes_0"), val = tensor<int32, [2]>([1, 2])];
            tensor<bool, []> model_time_distributed_MobilenetV3small_expanded_conv_7_squeeze_excite_AvgPool_Mean_keep_dims_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_7_squeeze_excite_AvgPool_Mean_keep_dims_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [20, 1, 1, 144]> model_time_distributed_MobilenetV3small_expanded_conv_7_squeeze_excite_AvgPool_Mean_cast_fp16 = reduce_mean(axes = model_time_distributed_MobilenetV3small_expanded_conv_7_squeeze_excite_AvgPool_Mean_axes_0, keep_dims = model_time_distributed_MobilenetV3small_expanded_conv_7_squeeze_excite_AvgPool_Mean_keep_dims_0, x = model_time_distributed_MobilenetV3small_multiply_10_mul_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_7_squeeze_excite_AvgPool_Mean_cast_fp16")];
            tensor<int32, [4]> transpose_90_perm_0 = const()[name = tensor<string, []>("transpose_90_perm_0"), val = tensor<int32, [4]>([0, 3, 1, 2])];
            tensor<string, []> model_time_distributed_MobilenetV3small_expanded_conv_7_squeeze_excite_Conv_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_7_squeeze_excite_Conv_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_7_squeeze_excite_Conv_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_7_squeeze_excite_Conv_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_7_squeeze_excite_Conv_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_7_squeeze_excite_Conv_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_time_distributed_MobilenetV3small_expanded_conv_7_squeeze_excite_Conv_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_7_squeeze_excite_Conv_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_7_squeeze_excite_Conv_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_7_squeeze_excite_Conv_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [40, 144, 1, 1]> conv_10_weight_0_to_fp16_quantized = constexpr_affine_dequantize()[axis = tensor<int32, []>(0), name = tensor<string, []>("conv_10_weight_0_to_fp16_quantized"), quantized_data = tensor<int8, [40, 144, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(209920))), scale = tensor<fp16, [40]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(215872))), zero_point = tensor<int8, [40]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(215744)))];
            tensor<fp16, [40]> conv_10_bias_0_to_fp16 = const()[name = tensor<string, []>("conv_10_bias_0_to_fp16"), val = tensor<fp16, [40]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(216064)))];
            tensor<fp16, [20, 144, 1, 1]> transpose_216 = transpose(perm = transpose_90_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_7_squeeze_excite_AvgPool_Mean_cast_fp16)[name = tensor<string, []>("transpose_38")];
            tensor<fp16, [20, 40, 1, 1]> conv_10_cast_fp16 = conv(bias = conv_10_bias_0_to_fp16, dilations = model_time_distributed_MobilenetV3small_expanded_conv_7_squeeze_excite_Conv_Conv2Dx_dilations_0, groups = model_time_distributed_MobilenetV3small_expanded_conv_7_squeeze_excite_Conv_Conv2Dx_groups_0, pad = model_time_distributed_MobilenetV3small_expanded_conv_7_squeeze_excite_Conv_Conv2Dx_pad_0, pad_type = model_time_distributed_MobilenetV3small_expanded_conv_7_squeeze_excite_Conv_Conv2Dx_pad_type_0, strides = model_time_distributed_MobilenetV3small_expanded_conv_7_squeeze_excite_Conv_Conv2Dx_strides_0, weight = conv_10_weight_0_to_fp16_quantized, x = transpose_216)[name = tensor<string, []>("conv_10_cast_fp16")];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_7_squeeze_excite_Conv_Conv2D_perm_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_7_squeeze_excite_Conv_Conv2D_perm_0"), val = tensor<int32, [4]>([0, 2, 3, 1])];
            tensor<fp16, [20, 1, 1, 40]> transpose_215 = transpose(perm = model_time_distributed_MobilenetV3small_expanded_conv_7_squeeze_excite_Conv_Conv2D_perm_0, x = conv_10_cast_fp16)[name = tensor<string, []>("transpose_37")];
            tensor<fp16, [20, 1, 1, 40]> model_time_distributed_MobilenetV3small_expanded_conv_7_squeeze_excite_Relu_Relu_cast_fp16 = relu(x = transpose_215)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_7_squeeze_excite_Relu_Relu_cast_fp16")];
            tensor<int32, [4]> transpose_92_perm_0 = const()[name = tensor<string, []>("transpose_92_perm_0"), val = tensor<int32, [4]>([0, 3, 1, 2])];
            tensor<string, []> model_time_distributed_MobilenetV3small_expanded_conv_7_squeeze_excite_Conv_1_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_7_squeeze_excite_Conv_1_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_7_squeeze_excite_Conv_1_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_7_squeeze_excite_Conv_1_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_7_squeeze_excite_Conv_1_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_7_squeeze_excite_Conv_1_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_time_distributed_MobilenetV3small_expanded_conv_7_squeeze_excite_Conv_1_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_7_squeeze_excite_Conv_1_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_7_squeeze_excite_Conv_1_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_7_squeeze_excite_Conv_1_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [144, 40, 1, 1]> conv_23_weight_0_to_fp16_quantized = constexpr_affine_dequantize()[axis = tensor<int32, []>(0), name = tensor<string, []>("conv_23_weight_0_to_fp16_quantized"), quantized_data = tensor<int8, [144, 40, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(216256))), scale = tensor<fp16, [144]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(222080))), zero_point = tensor<int8, [144]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(202112)))];
            tensor<fp16, [144]> conv_23_bias_0_to_fp16 = const()[name = tensor<string, []>("conv_23_bias_0_to_fp16"), val = tensor<fp16, [144]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(222464)))];
            tensor<fp16, [20, 40, 1, 1]> transpose_214 = transpose(perm = transpose_92_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_7_squeeze_excite_Relu_Relu_cast_fp16)[name = tensor<string, []>("transpose_36")];
            tensor<fp16, [20, 144, 1, 1]> conv_23_cast_fp16 = conv(bias = conv_23_bias_0_to_fp16, dilations = model_time_distributed_MobilenetV3small_expanded_conv_7_squeeze_excite_Conv_1_Conv2Dx_dilations_0, groups = model_time_distributed_MobilenetV3small_expanded_conv_7_squeeze_excite_Conv_1_Conv2Dx_groups_0, pad = model_time_distributed_MobilenetV3small_expanded_conv_7_squeeze_excite_Conv_1_Conv2Dx_pad_0, pad_type = model_time_distributed_MobilenetV3small_expanded_conv_7_squeeze_excite_Conv_1_Conv2Dx_pad_type_0, strides = model_time_distributed_MobilenetV3small_expanded_conv_7_squeeze_excite_Conv_1_Conv2Dx_strides_0, weight = conv_23_weight_0_to_fp16_quantized, x = transpose_214)[name = tensor<string, []>("conv_23_cast_fp16")];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_7_squeeze_excite_Conv_1_Conv2D_perm_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_7_squeeze_excite_Conv_1_Conv2D_perm_0"), val = tensor<int32, [4]>([0, 2, 3, 1])];
            tensor<fp16, [20, 1, 1, 144]> transpose_213 = transpose(perm = model_time_distributed_MobilenetV3small_expanded_conv_7_squeeze_excite_Conv_1_Conv2D_perm_0, x = conv_23_cast_fp16)[name = tensor<string, []>("transpose_35")];
            tensor<fp16, [20, 1, 1, 144]> model_time_distributed_MobilenetV3small_re_lu_21_Relu6_cast_fp16 = relu6(x = transpose_213)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_re_lu_21_Relu6_cast_fp16")];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_tf_math_multiply_16_Mul_y_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_multiply_16_Mul_y_to_fp16"), val = tensor<fp16, []>(0x1.554p-3)];
            tensor<fp16, [20, 1, 1, 144]> model_time_distributed_MobilenetV3small_tf_math_multiply_16_Mul_cast_fp16 = mul(x = model_time_distributed_MobilenetV3small_re_lu_21_Relu6_cast_fp16, y = model_time_distributed_MobilenetV3small_tf_math_multiply_16_Mul_y_to_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_multiply_16_Mul_cast_fp16")];
            tensor<fp16, [20, 14, 14, 144]> model_time_distributed_MobilenetV3small_expanded_conv_7_squeeze_excite_Mul_mul_cast_fp16 = mul(x = model_time_distributed_MobilenetV3small_multiply_10_mul_cast_fp16, y = model_time_distributed_MobilenetV3small_tf_math_multiply_16_Mul_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_7_squeeze_excite_Mul_mul_cast_fp16")];
            tensor<int32, [4]> transpose_94_perm_0 = const()[name = tensor<string, []>("transpose_94_perm_0"), val = tensor<int32, [4]>([0, 3, 1, 2])];
            tensor<string, []> model_time_distributed_MobilenetV3small_expanded_conv_7_project_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_7_project_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_7_project_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_7_project_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_7_project_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_7_project_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_time_distributed_MobilenetV3small_expanded_conv_7_project_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_7_project_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_7_project_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_7_project_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [48, 144, 1, 1]> transpose_93_to_fp16_quantized = constexpr_affine_dequantize()[axis = tensor<int32, []>(0), name = tensor<string, []>("transpose_93_to_fp16_quantized"), quantized_data = tensor<int8, [48, 144, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(222848))), scale = tensor<fp16, [48]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(229952))), zero_point = tensor<int8, [48]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(229824)))];
            tensor<fp16, [20, 144, 14, 14]> transpose_212 = transpose(perm = transpose_94_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_7_squeeze_excite_Mul_mul_cast_fp16)[name = tensor<string, []>("transpose_34")];
            tensor<fp16, [20, 48, 14, 14]> model_time_distributed_MobilenetV3small_expanded_conv_7_project_Conv2Dx_cast_fp16 = conv(dilations = model_time_distributed_MobilenetV3small_expanded_conv_7_project_Conv2Dx_dilations_0, groups = model_time_distributed_MobilenetV3small_expanded_conv_7_project_Conv2Dx_groups_0, pad = model_time_distributed_MobilenetV3small_expanded_conv_7_project_Conv2Dx_pad_0, pad_type = model_time_distributed_MobilenetV3small_expanded_conv_7_project_Conv2Dx_pad_type_0, strides = model_time_distributed_MobilenetV3small_expanded_conv_7_project_Conv2Dx_strides_0, weight = transpose_93_to_fp16_quantized, x = transpose_212)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_7_project_Conv2Dx_cast_fp16")];
            tensor<fp16, [48]> model_time_distributed_MobilenetV3small_expanded_conv_7_project_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_7_project_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16"), val = tensor<fp16, [48]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(230144)))];
            tensor<fp16, [48]> model_time_distributed_MobilenetV3small_expanded_conv_7_project_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_7_project_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16"), val = tensor<fp16, [48]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(230336)))];
            tensor<fp16, [48]> model_time_distributed_MobilenetV3small_expanded_conv_7_project_BatchNorm_ReadVariableOp_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_7_project_BatchNorm_ReadVariableOp_to_fp16"), val = tensor<fp16, [48]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(230528)))];
            tensor<fp16, [48]> model_time_distributed_MobilenetV3small_expanded_conv_7_project_BatchNorm_ReadVariableOp_1_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_7_project_BatchNorm_ReadVariableOp_1_to_fp16"), val = tensor<fp16, [48]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(230720)))];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_expanded_conv_7_project_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_7_project_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.064p-10)];
            tensor<fp16, [20, 48, 14, 14]> model_time_distributed_MobilenetV3small_expanded_conv_7_project_BatchNorm_FusedBatchNormV3_nchw_cast_fp16 = batch_norm(beta = model_time_distributed_MobilenetV3small_expanded_conv_7_project_BatchNorm_ReadVariableOp_1_to_fp16, epsilon = model_time_distributed_MobilenetV3small_expanded_conv_7_project_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16, gamma = model_time_distributed_MobilenetV3small_expanded_conv_7_project_BatchNorm_ReadVariableOp_to_fp16, mean = model_time_distributed_MobilenetV3small_expanded_conv_7_project_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16, variance = model_time_distributed_MobilenetV3small_expanded_conv_7_project_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16, x = model_time_distributed_MobilenetV3small_expanded_conv_7_project_Conv2Dx_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_7_project_BatchNorm_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_7_project_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_7_project_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0"), val = tensor<int32, [4]>([0, 2, 3, 1])];
            tensor<fp16, [20, 14, 14, 48]> transpose_211 = transpose(perm = model_time_distributed_MobilenetV3small_expanded_conv_7_project_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_7_project_BatchNorm_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("transpose_33")];
            tensor<fp16, [20, 14, 14, 48]> model_time_distributed_MobilenetV3small_expanded_conv_7_Add_add_cast_fp16 = add(x = transpose_221, y = transpose_211)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_7_Add_add_cast_fp16")];
            tensor<int32, [4]> transpose_97_perm_0 = const()[name = tensor<string, []>("transpose_97_perm_0"), val = tensor<int32, [4]>([0, 3, 1, 2])];
            tensor<string, []> model_time_distributed_MobilenetV3small_expanded_conv_8_expand_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_8_expand_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_8_expand_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_8_expand_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_8_expand_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_8_expand_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_time_distributed_MobilenetV3small_expanded_conv_8_expand_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_8_expand_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_8_expand_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_8_expand_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [288, 48, 1, 1]> transpose_96_to_fp16_quantized = constexpr_affine_dequantize()[axis = tensor<int32, []>(0), name = tensor<string, []>("transpose_96_to_fp16_quantized"), quantized_data = tensor<int8, [288, 48, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(230912))), scale = tensor<fp16, [288]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(245184))), zero_point = tensor<int8, [288]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(244800)))];
            tensor<fp16, [20, 48, 14, 14]> transpose_210 = transpose(perm = transpose_97_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_7_Add_add_cast_fp16)[name = tensor<string, []>("transpose_32")];
            tensor<fp16, [20, 288, 14, 14]> model_time_distributed_MobilenetV3small_expanded_conv_8_expand_Conv2Dx_cast_fp16 = conv(dilations = model_time_distributed_MobilenetV3small_expanded_conv_8_expand_Conv2Dx_dilations_0, groups = model_time_distributed_MobilenetV3small_expanded_conv_8_expand_Conv2Dx_groups_0, pad = model_time_distributed_MobilenetV3small_expanded_conv_8_expand_Conv2Dx_pad_0, pad_type = model_time_distributed_MobilenetV3small_expanded_conv_8_expand_Conv2Dx_pad_type_0, strides = model_time_distributed_MobilenetV3small_expanded_conv_8_expand_Conv2Dx_strides_0, weight = transpose_96_to_fp16_quantized, x = transpose_210)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_8_expand_Conv2Dx_cast_fp16")];
            tensor<fp16, [288]> model_time_distributed_MobilenetV3small_expanded_conv_8_expand_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_8_expand_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16"), val = tensor<fp16, [288]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(245824)))];
            tensor<fp16, [288]> model_time_distributed_MobilenetV3small_expanded_conv_8_expand_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_8_expand_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16"), val = tensor<fp16, [288]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(246464)))];
            tensor<fp16, [288]> model_time_distributed_MobilenetV3small_expanded_conv_8_expand_BatchNorm_ReadVariableOp_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_8_expand_BatchNorm_ReadVariableOp_to_fp16"), val = tensor<fp16, [288]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(247104)))];
            tensor<fp16, [288]> model_time_distributed_MobilenetV3small_expanded_conv_8_expand_BatchNorm_ReadVariableOp_1_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_8_expand_BatchNorm_ReadVariableOp_1_to_fp16"), val = tensor<fp16, [288]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(247744)))];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_expanded_conv_8_expand_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_8_expand_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.064p-10)];
            tensor<fp16, [20, 288, 14, 14]> model_time_distributed_MobilenetV3small_expanded_conv_8_expand_BatchNorm_FusedBatchNormV3_nchw_cast_fp16 = batch_norm(beta = model_time_distributed_MobilenetV3small_expanded_conv_8_expand_BatchNorm_ReadVariableOp_1_to_fp16, epsilon = model_time_distributed_MobilenetV3small_expanded_conv_8_expand_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16, gamma = model_time_distributed_MobilenetV3small_expanded_conv_8_expand_BatchNorm_ReadVariableOp_to_fp16, mean = model_time_distributed_MobilenetV3small_expanded_conv_8_expand_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16, variance = model_time_distributed_MobilenetV3small_expanded_conv_8_expand_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16, x = model_time_distributed_MobilenetV3small_expanded_conv_8_expand_Conv2Dx_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_8_expand_BatchNorm_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_8_expand_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_8_expand_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0"), val = tensor<int32, [4]>([0, 2, 3, 1])];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_tf_math_add_17_Add_y_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_add_17_Add_y_to_fp16"), val = tensor<fp16, []>(0x1.8p+1)];
            tensor<fp16, [20, 14, 14, 288]> transpose_209 = transpose(perm = model_time_distributed_MobilenetV3small_expanded_conv_8_expand_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_8_expand_BatchNorm_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("transpose_31")];
            tensor<fp16, [20, 14, 14, 288]> model_time_distributed_MobilenetV3small_tf_math_add_17_Add_cast_fp16 = add(x = transpose_209, y = model_time_distributed_MobilenetV3small_tf_math_add_17_Add_y_to_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_add_17_Add_cast_fp16")];
            tensor<fp16, [20, 14, 14, 288]> model_time_distributed_MobilenetV3small_re_lu_22_Relu6_cast_fp16 = relu6(x = model_time_distributed_MobilenetV3small_tf_math_add_17_Add_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_re_lu_22_Relu6_cast_fp16")];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_tf_math_multiply_17_Mul_y_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_multiply_17_Mul_y_to_fp16"), val = tensor<fp16, []>(0x1.554p-3)];
            tensor<fp16, [20, 14, 14, 288]> model_time_distributed_MobilenetV3small_tf_math_multiply_17_Mul_cast_fp16 = mul(x = model_time_distributed_MobilenetV3small_re_lu_22_Relu6_cast_fp16, y = model_time_distributed_MobilenetV3small_tf_math_multiply_17_Mul_y_to_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_multiply_17_Mul_cast_fp16")];
            tensor<fp16, [20, 14, 14, 288]> model_time_distributed_MobilenetV3small_multiply_11_mul_cast_fp16 = mul(x = transpose_209, y = model_time_distributed_MobilenetV3small_tf_math_multiply_17_Mul_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_multiply_11_mul_cast_fp16")];
            tensor<string, []> pad_3_mode_0 = const()[name = tensor<string, []>("pad_3_mode_0"), val = tensor<string, []>("constant")];
            tensor<int32, [4]> transpose_142_perm_0 = const()[name = tensor<string, []>("transpose_142_perm_0"), val = tensor<int32, [4]>([0, 3, 1, 2])];
            tensor<int32, [8]> pad_7_pad_0 = const()[name = tensor<string, []>("pad_7_pad_0"), val = tensor<int32, [8]>([0, 0, 0, 0, 1, 2, 1, 2])];
            tensor<fp16, []> const_3_to_fp16 = const()[name = tensor<string, []>("const_3_to_fp16"), val = tensor<fp16, []>(0x0p+0)];
            tensor<fp16, [20, 288, 14, 14]> transpose_208 = transpose(perm = transpose_142_perm_0, x = model_time_distributed_MobilenetV3small_multiply_11_mul_cast_fp16)[name = tensor<string, []>("transpose_30")];
            tensor<fp16, [20, 288, 17, 17]> pad_7_cast_fp16 = pad(constant_val = const_3_to_fp16, mode = pad_3_mode_0, pad = pad_7_pad_0, x = transpose_208)[name = tensor<string, []>("pad_7_cast_fp16")];
            tensor<string, []> model_time_distributed_MobilenetV3small_expanded_conv_8_depthwise_depthwisex_pad_type_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_8_depthwise_depthwisex_pad_type_0"), val = tensor<string, []>("valid")];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_8_depthwise_depthwisex_strides_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_8_depthwise_depthwisex_strides_0"), val = tensor<int32, [2]>([2, 2])];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_8_depthwise_depthwisex_dilations_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_8_depthwise_depthwisex_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_time_distributed_MobilenetV3small_expanded_conv_8_depthwise_depthwisex_groups_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_8_depthwise_depthwisex_groups_0"), val = tensor<int32, []>(288)];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_8_depthwise_depthwisex_pad_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_8_depthwise_depthwisex_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [288, 1, 5, 5]> transpose_99_to_fp16_quantized = constexpr_affine_dequantize()[axis = tensor<int32, []>(0), name = tensor<string, []>("transpose_99_to_fp16_quantized"), quantized_data = tensor<int8, [288, 1, 5, 5]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(248384))), scale = tensor<fp16, [288]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(255680))), zero_point = tensor<int8, [288]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(244800)))];
            tensor<fp16, [20, 288, 7, 7]> model_time_distributed_MobilenetV3small_expanded_conv_8_depthwise_depthwisex_cast_fp16 = conv(dilations = model_time_distributed_MobilenetV3small_expanded_conv_8_depthwise_depthwisex_dilations_0, groups = model_time_distributed_MobilenetV3small_expanded_conv_8_depthwise_depthwisex_groups_0, pad = model_time_distributed_MobilenetV3small_expanded_conv_8_depthwise_depthwisex_pad_0, pad_type = model_time_distributed_MobilenetV3small_expanded_conv_8_depthwise_depthwisex_pad_type_0, strides = model_time_distributed_MobilenetV3small_expanded_conv_8_depthwise_depthwisex_strides_0, weight = transpose_99_to_fp16_quantized, x = pad_7_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_8_depthwise_depthwisex_cast_fp16")];
            tensor<fp16, [288]> model_time_distributed_MobilenetV3small_expanded_conv_8_depthwise_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_8_depthwise_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16"), val = tensor<fp16, [288]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(256320)))];
            tensor<fp16, [288]> model_time_distributed_MobilenetV3small_expanded_conv_8_depthwise_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_8_depthwise_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16"), val = tensor<fp16, [288]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(256960)))];
            tensor<fp16, [288]> model_time_distributed_MobilenetV3small_expanded_conv_8_depthwise_BatchNorm_ReadVariableOp_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_8_depthwise_BatchNorm_ReadVariableOp_to_fp16"), val = tensor<fp16, [288]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(257600)))];
            tensor<fp16, [288]> model_time_distributed_MobilenetV3small_expanded_conv_8_depthwise_BatchNorm_ReadVariableOp_1_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_8_depthwise_BatchNorm_ReadVariableOp_1_to_fp16"), val = tensor<fp16, [288]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(258240)))];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_expanded_conv_8_depthwise_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_8_depthwise_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.064p-10)];
            tensor<fp16, [20, 288, 7, 7]> model_time_distributed_MobilenetV3small_expanded_conv_8_depthwise_BatchNorm_FusedBatchNormV3_nchw_cast_fp16 = batch_norm(beta = model_time_distributed_MobilenetV3small_expanded_conv_8_depthwise_BatchNorm_ReadVariableOp_1_to_fp16, epsilon = model_time_distributed_MobilenetV3small_expanded_conv_8_depthwise_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16, gamma = model_time_distributed_MobilenetV3small_expanded_conv_8_depthwise_BatchNorm_ReadVariableOp_to_fp16, mean = model_time_distributed_MobilenetV3small_expanded_conv_8_depthwise_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16, variance = model_time_distributed_MobilenetV3small_expanded_conv_8_depthwise_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16, x = model_time_distributed_MobilenetV3small_expanded_conv_8_depthwise_depthwisex_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_8_depthwise_BatchNorm_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_8_depthwise_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_8_depthwise_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0"), val = tensor<int32, [4]>([0, 2, 3, 1])];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_tf_math_add_18_Add_y_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_add_18_Add_y_to_fp16"), val = tensor<fp16, []>(0x1.8p+1)];
            tensor<fp16, [20, 7, 7, 288]> transpose_207 = transpose(perm = model_time_distributed_MobilenetV3small_expanded_conv_8_depthwise_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_8_depthwise_BatchNorm_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("transpose_29")];
            tensor<fp16, [20, 7, 7, 288]> model_time_distributed_MobilenetV3small_tf_math_add_18_Add_cast_fp16 = add(x = transpose_207, y = model_time_distributed_MobilenetV3small_tf_math_add_18_Add_y_to_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_add_18_Add_cast_fp16")];
            tensor<fp16, [20, 7, 7, 288]> model_time_distributed_MobilenetV3small_re_lu_23_Relu6_cast_fp16 = relu6(x = model_time_distributed_MobilenetV3small_tf_math_add_18_Add_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_re_lu_23_Relu6_cast_fp16")];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_tf_math_multiply_18_Mul_y_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_multiply_18_Mul_y_to_fp16"), val = tensor<fp16, []>(0x1.554p-3)];
            tensor<fp16, [20, 7, 7, 288]> model_time_distributed_MobilenetV3small_tf_math_multiply_18_Mul_cast_fp16 = mul(x = model_time_distributed_MobilenetV3small_re_lu_23_Relu6_cast_fp16, y = model_time_distributed_MobilenetV3small_tf_math_multiply_18_Mul_y_to_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_multiply_18_Mul_cast_fp16")];
            tensor<fp16, [20, 7, 7, 288]> model_time_distributed_MobilenetV3small_multiply_12_mul_cast_fp16 = mul(x = transpose_207, y = model_time_distributed_MobilenetV3small_tf_math_multiply_18_Mul_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_multiply_12_mul_cast_fp16")];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_8_squeeze_excite_AvgPool_Mean_axes_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_8_squeeze_excite_AvgPool_Mean_axes_0"), val = tensor<int32, [2]>([1, 2])];
            tensor<bool, []> model_time_distributed_MobilenetV3small_expanded_conv_8_squeeze_excite_AvgPool_Mean_keep_dims_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_8_squeeze_excite_AvgPool_Mean_keep_dims_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [20, 1, 1, 288]> model_time_distributed_MobilenetV3small_expanded_conv_8_squeeze_excite_AvgPool_Mean_cast_fp16 = reduce_mean(axes = model_time_distributed_MobilenetV3small_expanded_conv_8_squeeze_excite_AvgPool_Mean_axes_0, keep_dims = model_time_distributed_MobilenetV3small_expanded_conv_8_squeeze_excite_AvgPool_Mean_keep_dims_0, x = model_time_distributed_MobilenetV3small_multiply_12_mul_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_8_squeeze_excite_AvgPool_Mean_cast_fp16")];
            tensor<int32, [4]> transpose_103_perm_0 = const()[name = tensor<string, []>("transpose_103_perm_0"), val = tensor<int32, [4]>([0, 3, 1, 2])];
            tensor<string, []> model_time_distributed_MobilenetV3small_expanded_conv_8_squeeze_excite_Conv_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_8_squeeze_excite_Conv_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_8_squeeze_excite_Conv_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_8_squeeze_excite_Conv_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_8_squeeze_excite_Conv_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_8_squeeze_excite_Conv_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_time_distributed_MobilenetV3small_expanded_conv_8_squeeze_excite_Conv_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_8_squeeze_excite_Conv_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_8_squeeze_excite_Conv_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_8_squeeze_excite_Conv_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [72, 288, 1, 1]> conv_12_weight_0_to_fp16_quantized = constexpr_affine_dequantize()[axis = tensor<int32, []>(0), name = tensor<string, []>("conv_12_weight_0_to_fp16_quantized"), quantized_data = tensor<int8, [72, 288, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(258880))), scale = tensor<fp16, [72]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(279872))), zero_point = tensor<int8, [72]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(279680)))];
            tensor<fp16, [72]> conv_12_bias_0_to_fp16 = const()[name = tensor<string, []>("conv_12_bias_0_to_fp16"), val = tensor<fp16, [72]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(280128)))];
            tensor<fp16, [20, 288, 1, 1]> transpose_206 = transpose(perm = transpose_103_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_8_squeeze_excite_AvgPool_Mean_cast_fp16)[name = tensor<string, []>("transpose_28")];
            tensor<fp16, [20, 72, 1, 1]> conv_12_cast_fp16 = conv(bias = conv_12_bias_0_to_fp16, dilations = model_time_distributed_MobilenetV3small_expanded_conv_8_squeeze_excite_Conv_Conv2Dx_dilations_0, groups = model_time_distributed_MobilenetV3small_expanded_conv_8_squeeze_excite_Conv_Conv2Dx_groups_0, pad = model_time_distributed_MobilenetV3small_expanded_conv_8_squeeze_excite_Conv_Conv2Dx_pad_0, pad_type = model_time_distributed_MobilenetV3small_expanded_conv_8_squeeze_excite_Conv_Conv2Dx_pad_type_0, strides = model_time_distributed_MobilenetV3small_expanded_conv_8_squeeze_excite_Conv_Conv2Dx_strides_0, weight = conv_12_weight_0_to_fp16_quantized, x = transpose_206)[name = tensor<string, []>("conv_12_cast_fp16")];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_8_squeeze_excite_Conv_Conv2D_perm_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_8_squeeze_excite_Conv_Conv2D_perm_0"), val = tensor<int32, [4]>([0, 2, 3, 1])];
            tensor<fp16, [20, 1, 1, 72]> transpose_205 = transpose(perm = model_time_distributed_MobilenetV3small_expanded_conv_8_squeeze_excite_Conv_Conv2D_perm_0, x = conv_12_cast_fp16)[name = tensor<string, []>("transpose_27")];
            tensor<fp16, [20, 1, 1, 72]> model_time_distributed_MobilenetV3small_expanded_conv_8_squeeze_excite_Relu_Relu_cast_fp16 = relu(x = transpose_205)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_8_squeeze_excite_Relu_Relu_cast_fp16")];
            tensor<int32, [4]> transpose_105_perm_0 = const()[name = tensor<string, []>("transpose_105_perm_0"), val = tensor<int32, [4]>([0, 3, 1, 2])];
            tensor<string, []> model_time_distributed_MobilenetV3small_expanded_conv_8_squeeze_excite_Conv_1_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_8_squeeze_excite_Conv_1_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_8_squeeze_excite_Conv_1_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_8_squeeze_excite_Conv_1_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_8_squeeze_excite_Conv_1_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_8_squeeze_excite_Conv_1_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_time_distributed_MobilenetV3small_expanded_conv_8_squeeze_excite_Conv_1_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_8_squeeze_excite_Conv_1_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_8_squeeze_excite_Conv_1_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_8_squeeze_excite_Conv_1_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [288, 72, 1, 1]> conv_24_weight_0_to_fp16_quantized = constexpr_affine_dequantize()[axis = tensor<int32, []>(0), name = tensor<string, []>("conv_24_weight_0_to_fp16_quantized"), quantized_data = tensor<int8, [288, 72, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(280384))), scale = tensor<fp16, [288]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(301184))), zero_point = tensor<int8, [288]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(244800)))];
            tensor<fp16, [288]> conv_24_bias_0_to_fp16 = const()[name = tensor<string, []>("conv_24_bias_0_to_fp16"), val = tensor<fp16, [288]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(301824)))];
            tensor<fp16, [20, 72, 1, 1]> transpose_204 = transpose(perm = transpose_105_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_8_squeeze_excite_Relu_Relu_cast_fp16)[name = tensor<string, []>("transpose_26")];
            tensor<fp16, [20, 288, 1, 1]> conv_24_cast_fp16 = conv(bias = conv_24_bias_0_to_fp16, dilations = model_time_distributed_MobilenetV3small_expanded_conv_8_squeeze_excite_Conv_1_Conv2Dx_dilations_0, groups = model_time_distributed_MobilenetV3small_expanded_conv_8_squeeze_excite_Conv_1_Conv2Dx_groups_0, pad = model_time_distributed_MobilenetV3small_expanded_conv_8_squeeze_excite_Conv_1_Conv2Dx_pad_0, pad_type = model_time_distributed_MobilenetV3small_expanded_conv_8_squeeze_excite_Conv_1_Conv2Dx_pad_type_0, strides = model_time_distributed_MobilenetV3small_expanded_conv_8_squeeze_excite_Conv_1_Conv2Dx_strides_0, weight = conv_24_weight_0_to_fp16_quantized, x = transpose_204)[name = tensor<string, []>("conv_24_cast_fp16")];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_8_squeeze_excite_Conv_1_Conv2D_perm_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_8_squeeze_excite_Conv_1_Conv2D_perm_0"), val = tensor<int32, [4]>([0, 2, 3, 1])];
            tensor<fp16, [20, 1, 1, 288]> transpose_203 = transpose(perm = model_time_distributed_MobilenetV3small_expanded_conv_8_squeeze_excite_Conv_1_Conv2D_perm_0, x = conv_24_cast_fp16)[name = tensor<string, []>("transpose_25")];
            tensor<fp16, [20, 1, 1, 288]> model_time_distributed_MobilenetV3small_re_lu_24_Relu6_cast_fp16 = relu6(x = transpose_203)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_re_lu_24_Relu6_cast_fp16")];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_tf_math_multiply_19_Mul_y_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_multiply_19_Mul_y_to_fp16"), val = tensor<fp16, []>(0x1.554p-3)];
            tensor<fp16, [20, 1, 1, 288]> model_time_distributed_MobilenetV3small_tf_math_multiply_19_Mul_cast_fp16 = mul(x = model_time_distributed_MobilenetV3small_re_lu_24_Relu6_cast_fp16, y = model_time_distributed_MobilenetV3small_tf_math_multiply_19_Mul_y_to_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_multiply_19_Mul_cast_fp16")];
            tensor<fp16, [20, 7, 7, 288]> model_time_distributed_MobilenetV3small_expanded_conv_8_squeeze_excite_Mul_mul_cast_fp16 = mul(x = model_time_distributed_MobilenetV3small_multiply_12_mul_cast_fp16, y = model_time_distributed_MobilenetV3small_tf_math_multiply_19_Mul_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_8_squeeze_excite_Mul_mul_cast_fp16")];
            tensor<int32, [4]> transpose_107_perm_0 = const()[name = tensor<string, []>("transpose_107_perm_0"), val = tensor<int32, [4]>([0, 3, 1, 2])];
            tensor<string, []> model_time_distributed_MobilenetV3small_expanded_conv_8_project_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_8_project_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_8_project_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_8_project_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_8_project_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_8_project_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_time_distributed_MobilenetV3small_expanded_conv_8_project_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_8_project_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_8_project_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_8_project_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [96, 288, 1, 1]> transpose_106_to_fp16_quantized = constexpr_affine_dequantize()[axis = tensor<int32, []>(0), name = tensor<string, []>("transpose_106_to_fp16_quantized"), quantized_data = tensor<int8, [96, 288, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(302464))), scale = tensor<fp16, [96]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(330368))), zero_point = tensor<int8, [96]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(330176)))];
            tensor<fp16, [20, 288, 7, 7]> transpose_202 = transpose(perm = transpose_107_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_8_squeeze_excite_Mul_mul_cast_fp16)[name = tensor<string, []>("transpose_24")];
            tensor<fp16, [20, 96, 7, 7]> model_time_distributed_MobilenetV3small_expanded_conv_8_project_Conv2Dx_cast_fp16 = conv(dilations = model_time_distributed_MobilenetV3small_expanded_conv_8_project_Conv2Dx_dilations_0, groups = model_time_distributed_MobilenetV3small_expanded_conv_8_project_Conv2Dx_groups_0, pad = model_time_distributed_MobilenetV3small_expanded_conv_8_project_Conv2Dx_pad_0, pad_type = model_time_distributed_MobilenetV3small_expanded_conv_8_project_Conv2Dx_pad_type_0, strides = model_time_distributed_MobilenetV3small_expanded_conv_8_project_Conv2Dx_strides_0, weight = transpose_106_to_fp16_quantized, x = transpose_202)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_8_project_Conv2Dx_cast_fp16")];
            tensor<fp16, [96]> model_time_distributed_MobilenetV3small_expanded_conv_8_project_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_8_project_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16"), val = tensor<fp16, [96]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(330624)))];
            tensor<fp16, [96]> model_time_distributed_MobilenetV3small_expanded_conv_8_project_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_8_project_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16"), val = tensor<fp16, [96]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(330880)))];
            tensor<fp16, [96]> model_time_distributed_MobilenetV3small_expanded_conv_8_project_BatchNorm_ReadVariableOp_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_8_project_BatchNorm_ReadVariableOp_to_fp16"), val = tensor<fp16, [96]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(331136)))];
            tensor<fp16, [96]> model_time_distributed_MobilenetV3small_expanded_conv_8_project_BatchNorm_ReadVariableOp_1_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_8_project_BatchNorm_ReadVariableOp_1_to_fp16"), val = tensor<fp16, [96]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(331392)))];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_expanded_conv_8_project_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_8_project_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.064p-10)];
            tensor<fp16, [20, 96, 7, 7]> model_time_distributed_MobilenetV3small_expanded_conv_8_project_BatchNorm_FusedBatchNormV3_nchw_cast_fp16 = batch_norm(beta = model_time_distributed_MobilenetV3small_expanded_conv_8_project_BatchNorm_ReadVariableOp_1_to_fp16, epsilon = model_time_distributed_MobilenetV3small_expanded_conv_8_project_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16, gamma = model_time_distributed_MobilenetV3small_expanded_conv_8_project_BatchNorm_ReadVariableOp_to_fp16, mean = model_time_distributed_MobilenetV3small_expanded_conv_8_project_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16, variance = model_time_distributed_MobilenetV3small_expanded_conv_8_project_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16, x = model_time_distributed_MobilenetV3small_expanded_conv_8_project_Conv2Dx_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_8_project_BatchNorm_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_8_project_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_8_project_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0"), val = tensor<int32, [4]>([0, 2, 3, 1])];
            tensor<int32, [4]> transpose_110_perm_0 = const()[name = tensor<string, []>("transpose_110_perm_0"), val = tensor<int32, [4]>([0, 3, 1, 2])];
            tensor<string, []> model_time_distributed_MobilenetV3small_expanded_conv_9_expand_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_9_expand_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_9_expand_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_9_expand_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_9_expand_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_9_expand_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_time_distributed_MobilenetV3small_expanded_conv_9_expand_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_9_expand_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_9_expand_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_9_expand_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [576, 96, 1, 1]> transpose_109_to_fp16_quantized = constexpr_affine_dequantize()[axis = tensor<int32, []>(0), name = tensor<string, []>("transpose_109_to_fp16_quantized"), quantized_data = tensor<int8, [576, 96, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(331648))), scale = tensor<fp16, [576]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(387648))), zero_point = tensor<int8, [576]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(387008)))];
            tensor<fp16, [20, 7, 7, 96]> transpose_201 = transpose(perm = model_time_distributed_MobilenetV3small_expanded_conv_8_project_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_8_project_BatchNorm_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("transpose_23")];
            tensor<fp16, [20, 96, 7, 7]> transpose_200 = transpose(perm = transpose_110_perm_0, x = transpose_201)[name = tensor<string, []>("transpose_22")];
            tensor<fp16, [20, 576, 7, 7]> model_time_distributed_MobilenetV3small_expanded_conv_9_expand_Conv2Dx_cast_fp16 = conv(dilations = model_time_distributed_MobilenetV3small_expanded_conv_9_expand_Conv2Dx_dilations_0, groups = model_time_distributed_MobilenetV3small_expanded_conv_9_expand_Conv2Dx_groups_0, pad = model_time_distributed_MobilenetV3small_expanded_conv_9_expand_Conv2Dx_pad_0, pad_type = model_time_distributed_MobilenetV3small_expanded_conv_9_expand_Conv2Dx_pad_type_0, strides = model_time_distributed_MobilenetV3small_expanded_conv_9_expand_Conv2Dx_strides_0, weight = transpose_109_to_fp16_quantized, x = transpose_200)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_9_expand_Conv2Dx_cast_fp16")];
            tensor<fp16, [576]> model_time_distributed_MobilenetV3small_expanded_conv_9_expand_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_9_expand_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16"), val = tensor<fp16, [576]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(388864)))];
            tensor<fp16, [576]> model_time_distributed_MobilenetV3small_expanded_conv_9_expand_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_9_expand_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16"), val = tensor<fp16, [576]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(390080)))];
            tensor<fp16, [576]> model_time_distributed_MobilenetV3small_expanded_conv_9_expand_BatchNorm_ReadVariableOp_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_9_expand_BatchNorm_ReadVariableOp_to_fp16"), val = tensor<fp16, [576]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(391296)))];
            tensor<fp16, [576]> model_time_distributed_MobilenetV3small_expanded_conv_9_expand_BatchNorm_ReadVariableOp_1_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_9_expand_BatchNorm_ReadVariableOp_1_to_fp16"), val = tensor<fp16, [576]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(392512)))];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_expanded_conv_9_expand_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_9_expand_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.064p-10)];
            tensor<fp16, [20, 576, 7, 7]> model_time_distributed_MobilenetV3small_expanded_conv_9_expand_BatchNorm_FusedBatchNormV3_nchw_cast_fp16 = batch_norm(beta = model_time_distributed_MobilenetV3small_expanded_conv_9_expand_BatchNorm_ReadVariableOp_1_to_fp16, epsilon = model_time_distributed_MobilenetV3small_expanded_conv_9_expand_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16, gamma = model_time_distributed_MobilenetV3small_expanded_conv_9_expand_BatchNorm_ReadVariableOp_to_fp16, mean = model_time_distributed_MobilenetV3small_expanded_conv_9_expand_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16, variance = model_time_distributed_MobilenetV3small_expanded_conv_9_expand_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16, x = model_time_distributed_MobilenetV3small_expanded_conv_9_expand_Conv2Dx_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_9_expand_BatchNorm_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_9_expand_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_9_expand_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0"), val = tensor<int32, [4]>([0, 2, 3, 1])];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_tf_math_add_20_Add_y_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_add_20_Add_y_to_fp16"), val = tensor<fp16, []>(0x1.8p+1)];
            tensor<fp16, [20, 7, 7, 576]> transpose_199 = transpose(perm = model_time_distributed_MobilenetV3small_expanded_conv_9_expand_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_9_expand_BatchNorm_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("transpose_21")];
            tensor<fp16, [20, 7, 7, 576]> model_time_distributed_MobilenetV3small_tf_math_add_20_Add_cast_fp16 = add(x = transpose_199, y = model_time_distributed_MobilenetV3small_tf_math_add_20_Add_y_to_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_add_20_Add_cast_fp16")];
            tensor<fp16, [20, 7, 7, 576]> model_time_distributed_MobilenetV3small_re_lu_25_Relu6_cast_fp16 = relu6(x = model_time_distributed_MobilenetV3small_tf_math_add_20_Add_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_re_lu_25_Relu6_cast_fp16")];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_tf_math_multiply_20_Mul_y_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_multiply_20_Mul_y_to_fp16"), val = tensor<fp16, []>(0x1.554p-3)];
            tensor<fp16, [20, 7, 7, 576]> model_time_distributed_MobilenetV3small_tf_math_multiply_20_Mul_cast_fp16 = mul(x = model_time_distributed_MobilenetV3small_re_lu_25_Relu6_cast_fp16, y = model_time_distributed_MobilenetV3small_tf_math_multiply_20_Mul_y_to_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_multiply_20_Mul_cast_fp16")];
            tensor<fp16, [20, 7, 7, 576]> model_time_distributed_MobilenetV3small_multiply_13_mul_cast_fp16 = mul(x = transpose_199, y = model_time_distributed_MobilenetV3small_tf_math_multiply_20_Mul_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_multiply_13_mul_cast_fp16")];
            tensor<int32, [4]> transpose_113_perm_0 = const()[name = tensor<string, []>("transpose_113_perm_0"), val = tensor<int32, [4]>([0, 3, 1, 2])];
            tensor<string, []> model_time_distributed_MobilenetV3small_expanded_conv_9_depthwise_depthwisex_pad_type_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_9_depthwise_depthwisex_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_9_depthwise_depthwisex_strides_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_9_depthwise_depthwisex_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_9_depthwise_depthwisex_dilations_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_9_depthwise_depthwisex_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_time_distributed_MobilenetV3small_expanded_conv_9_depthwise_depthwisex_groups_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_9_depthwise_depthwisex_groups_0"), val = tensor<int32, []>(576)];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_9_depthwise_depthwisex_pad_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_9_depthwise_depthwisex_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [576, 1, 5, 5]> transpose_112_to_fp16_quantized = constexpr_affine_dequantize()[axis = tensor<int32, []>(0), name = tensor<string, []>("transpose_112_to_fp16_quantized"), quantized_data = tensor<int8, [576, 1, 5, 5]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(393728))), scale = tensor<fp16, [576]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(408192))), zero_point = tensor<int8, [576]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(387008)))];
            tensor<fp16, [20, 576, 7, 7]> transpose_198 = transpose(perm = transpose_113_perm_0, x = model_time_distributed_MobilenetV3small_multiply_13_mul_cast_fp16)[name = tensor<string, []>("transpose_20")];
            tensor<fp16, [20, 576, 7, 7]> model_time_distributed_MobilenetV3small_expanded_conv_9_depthwise_depthwisex_cast_fp16 = conv(dilations = model_time_distributed_MobilenetV3small_expanded_conv_9_depthwise_depthwisex_dilations_0, groups = model_time_distributed_MobilenetV3small_expanded_conv_9_depthwise_depthwisex_groups_0, pad = model_time_distributed_MobilenetV3small_expanded_conv_9_depthwise_depthwisex_pad_0, pad_type = model_time_distributed_MobilenetV3small_expanded_conv_9_depthwise_depthwisex_pad_type_0, strides = model_time_distributed_MobilenetV3small_expanded_conv_9_depthwise_depthwisex_strides_0, weight = transpose_112_to_fp16_quantized, x = transpose_198)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_9_depthwise_depthwisex_cast_fp16")];
            tensor<fp16, [576]> model_time_distributed_MobilenetV3small_expanded_conv_9_depthwise_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_9_depthwise_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16"), val = tensor<fp16, [576]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(409408)))];
            tensor<fp16, [576]> model_time_distributed_MobilenetV3small_expanded_conv_9_depthwise_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_9_depthwise_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16"), val = tensor<fp16, [576]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(410624)))];
            tensor<fp16, [576]> model_time_distributed_MobilenetV3small_expanded_conv_9_depthwise_BatchNorm_ReadVariableOp_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_9_depthwise_BatchNorm_ReadVariableOp_to_fp16"), val = tensor<fp16, [576]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(411840)))];
            tensor<fp16, [576]> model_time_distributed_MobilenetV3small_expanded_conv_9_depthwise_BatchNorm_ReadVariableOp_1_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_9_depthwise_BatchNorm_ReadVariableOp_1_to_fp16"), val = tensor<fp16, [576]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(413056)))];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_expanded_conv_9_depthwise_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_9_depthwise_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.064p-10)];
            tensor<fp16, [20, 576, 7, 7]> model_time_distributed_MobilenetV3small_expanded_conv_9_depthwise_BatchNorm_FusedBatchNormV3_nchw_cast_fp16 = batch_norm(beta = model_time_distributed_MobilenetV3small_expanded_conv_9_depthwise_BatchNorm_ReadVariableOp_1_to_fp16, epsilon = model_time_distributed_MobilenetV3small_expanded_conv_9_depthwise_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16, gamma = model_time_distributed_MobilenetV3small_expanded_conv_9_depthwise_BatchNorm_ReadVariableOp_to_fp16, mean = model_time_distributed_MobilenetV3small_expanded_conv_9_depthwise_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16, variance = model_time_distributed_MobilenetV3small_expanded_conv_9_depthwise_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16, x = model_time_distributed_MobilenetV3small_expanded_conv_9_depthwise_depthwisex_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_9_depthwise_BatchNorm_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_9_depthwise_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_9_depthwise_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0"), val = tensor<int32, [4]>([0, 2, 3, 1])];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_tf_math_add_21_Add_y_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_add_21_Add_y_to_fp16"), val = tensor<fp16, []>(0x1.8p+1)];
            tensor<fp16, [20, 7, 7, 576]> transpose_197 = transpose(perm = model_time_distributed_MobilenetV3small_expanded_conv_9_depthwise_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_9_depthwise_BatchNorm_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("transpose_19")];
            tensor<fp16, [20, 7, 7, 576]> model_time_distributed_MobilenetV3small_tf_math_add_21_Add_cast_fp16 = add(x = transpose_197, y = model_time_distributed_MobilenetV3small_tf_math_add_21_Add_y_to_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_add_21_Add_cast_fp16")];
            tensor<fp16, [20, 7, 7, 576]> model_time_distributed_MobilenetV3small_re_lu_26_Relu6_cast_fp16 = relu6(x = model_time_distributed_MobilenetV3small_tf_math_add_21_Add_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_re_lu_26_Relu6_cast_fp16")];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_tf_math_multiply_21_Mul_y_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_multiply_21_Mul_y_to_fp16"), val = tensor<fp16, []>(0x1.554p-3)];
            tensor<fp16, [20, 7, 7, 576]> model_time_distributed_MobilenetV3small_tf_math_multiply_21_Mul_cast_fp16 = mul(x = model_time_distributed_MobilenetV3small_re_lu_26_Relu6_cast_fp16, y = model_time_distributed_MobilenetV3small_tf_math_multiply_21_Mul_y_to_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_multiply_21_Mul_cast_fp16")];
            tensor<fp16, [20, 7, 7, 576]> model_time_distributed_MobilenetV3small_multiply_14_mul_cast_fp16 = mul(x = transpose_197, y = model_time_distributed_MobilenetV3small_tf_math_multiply_21_Mul_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_multiply_14_mul_cast_fp16")];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_9_squeeze_excite_AvgPool_Mean_axes_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_9_squeeze_excite_AvgPool_Mean_axes_0"), val = tensor<int32, [2]>([1, 2])];
            tensor<bool, []> model_time_distributed_MobilenetV3small_expanded_conv_9_squeeze_excite_AvgPool_Mean_keep_dims_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_9_squeeze_excite_AvgPool_Mean_keep_dims_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [20, 1, 1, 576]> model_time_distributed_MobilenetV3small_expanded_conv_9_squeeze_excite_AvgPool_Mean_cast_fp16 = reduce_mean(axes = model_time_distributed_MobilenetV3small_expanded_conv_9_squeeze_excite_AvgPool_Mean_axes_0, keep_dims = model_time_distributed_MobilenetV3small_expanded_conv_9_squeeze_excite_AvgPool_Mean_keep_dims_0, x = model_time_distributed_MobilenetV3small_multiply_14_mul_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_9_squeeze_excite_AvgPool_Mean_cast_fp16")];
            tensor<int32, [4]> transpose_116_perm_0 = const()[name = tensor<string, []>("transpose_116_perm_0"), val = tensor<int32, [4]>([0, 3, 1, 2])];
            tensor<string, []> model_time_distributed_MobilenetV3small_expanded_conv_9_squeeze_excite_Conv_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_9_squeeze_excite_Conv_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_9_squeeze_excite_Conv_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_9_squeeze_excite_Conv_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_9_squeeze_excite_Conv_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_9_squeeze_excite_Conv_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_time_distributed_MobilenetV3small_expanded_conv_9_squeeze_excite_Conv_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_9_squeeze_excite_Conv_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_9_squeeze_excite_Conv_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_9_squeeze_excite_Conv_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [144, 576, 1, 1]> conv_14_weight_0_to_fp16_quantized = constexpr_affine_dequantize()[axis = tensor<int32, []>(0), name = tensor<string, []>("conv_14_weight_0_to_fp16_quantized"), quantized_data = tensor<int8, [144, 576, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(414272))), scale = tensor<fp16, [144]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(497280))), zero_point = tensor<int8, [144]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(202112)))];
            tensor<fp16, [144]> conv_14_bias_0_to_fp16 = const()[name = tensor<string, []>("conv_14_bias_0_to_fp16"), val = tensor<fp16, [144]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(497664)))];
            tensor<fp16, [20, 576, 1, 1]> transpose_196 = transpose(perm = transpose_116_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_9_squeeze_excite_AvgPool_Mean_cast_fp16)[name = tensor<string, []>("transpose_18")];
            tensor<fp16, [20, 144, 1, 1]> conv_14_cast_fp16 = conv(bias = conv_14_bias_0_to_fp16, dilations = model_time_distributed_MobilenetV3small_expanded_conv_9_squeeze_excite_Conv_Conv2Dx_dilations_0, groups = model_time_distributed_MobilenetV3small_expanded_conv_9_squeeze_excite_Conv_Conv2Dx_groups_0, pad = model_time_distributed_MobilenetV3small_expanded_conv_9_squeeze_excite_Conv_Conv2Dx_pad_0, pad_type = model_time_distributed_MobilenetV3small_expanded_conv_9_squeeze_excite_Conv_Conv2Dx_pad_type_0, strides = model_time_distributed_MobilenetV3small_expanded_conv_9_squeeze_excite_Conv_Conv2Dx_strides_0, weight = conv_14_weight_0_to_fp16_quantized, x = transpose_196)[name = tensor<string, []>("conv_14_cast_fp16")];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_9_squeeze_excite_Conv_Conv2D_perm_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_9_squeeze_excite_Conv_Conv2D_perm_0"), val = tensor<int32, [4]>([0, 2, 3, 1])];
            tensor<fp16, [20, 1, 1, 144]> transpose_195 = transpose(perm = model_time_distributed_MobilenetV3small_expanded_conv_9_squeeze_excite_Conv_Conv2D_perm_0, x = conv_14_cast_fp16)[name = tensor<string, []>("transpose_17")];
            tensor<fp16, [20, 1, 1, 144]> model_time_distributed_MobilenetV3small_expanded_conv_9_squeeze_excite_Relu_Relu_cast_fp16 = relu(x = transpose_195)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_9_squeeze_excite_Relu_Relu_cast_fp16")];
            tensor<int32, [4]> transpose_118_perm_0 = const()[name = tensor<string, []>("transpose_118_perm_0"), val = tensor<int32, [4]>([0, 3, 1, 2])];
            tensor<string, []> model_time_distributed_MobilenetV3small_expanded_conv_9_squeeze_excite_Conv_1_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_9_squeeze_excite_Conv_1_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_9_squeeze_excite_Conv_1_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_9_squeeze_excite_Conv_1_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_9_squeeze_excite_Conv_1_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_9_squeeze_excite_Conv_1_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_time_distributed_MobilenetV3small_expanded_conv_9_squeeze_excite_Conv_1_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_9_squeeze_excite_Conv_1_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_9_squeeze_excite_Conv_1_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_9_squeeze_excite_Conv_1_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [576, 144, 1, 1]> conv_25_weight_0_to_fp16_quantized = constexpr_affine_dequantize()[axis = tensor<int32, []>(0), name = tensor<string, []>("conv_25_weight_0_to_fp16_quantized"), quantized_data = tensor<int8, [576, 144, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(498048))), scale = tensor<fp16, [576]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(581056))), zero_point = tensor<int8, [576]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(387008)))];
            tensor<fp16, [576]> conv_25_bias_0_to_fp16 = const()[name = tensor<string, []>("conv_25_bias_0_to_fp16"), val = tensor<fp16, [576]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(582272)))];
            tensor<fp16, [20, 144, 1, 1]> transpose_194 = transpose(perm = transpose_118_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_9_squeeze_excite_Relu_Relu_cast_fp16)[name = tensor<string, []>("transpose_16")];
            tensor<fp16, [20, 576, 1, 1]> conv_25_cast_fp16 = conv(bias = conv_25_bias_0_to_fp16, dilations = model_time_distributed_MobilenetV3small_expanded_conv_9_squeeze_excite_Conv_1_Conv2Dx_dilations_0, groups = model_time_distributed_MobilenetV3small_expanded_conv_9_squeeze_excite_Conv_1_Conv2Dx_groups_0, pad = model_time_distributed_MobilenetV3small_expanded_conv_9_squeeze_excite_Conv_1_Conv2Dx_pad_0, pad_type = model_time_distributed_MobilenetV3small_expanded_conv_9_squeeze_excite_Conv_1_Conv2Dx_pad_type_0, strides = model_time_distributed_MobilenetV3small_expanded_conv_9_squeeze_excite_Conv_1_Conv2Dx_strides_0, weight = conv_25_weight_0_to_fp16_quantized, x = transpose_194)[name = tensor<string, []>("conv_25_cast_fp16")];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_9_squeeze_excite_Conv_1_Conv2D_perm_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_9_squeeze_excite_Conv_1_Conv2D_perm_0"), val = tensor<int32, [4]>([0, 2, 3, 1])];
            tensor<fp16, [20, 1, 1, 576]> transpose_193 = transpose(perm = model_time_distributed_MobilenetV3small_expanded_conv_9_squeeze_excite_Conv_1_Conv2D_perm_0, x = conv_25_cast_fp16)[name = tensor<string, []>("transpose_15")];
            tensor<fp16, [20, 1, 1, 576]> model_time_distributed_MobilenetV3small_re_lu_27_Relu6_cast_fp16 = relu6(x = transpose_193)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_re_lu_27_Relu6_cast_fp16")];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_tf_math_multiply_22_Mul_y_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_multiply_22_Mul_y_to_fp16"), val = tensor<fp16, []>(0x1.554p-3)];
            tensor<fp16, [20, 1, 1, 576]> model_time_distributed_MobilenetV3small_tf_math_multiply_22_Mul_cast_fp16 = mul(x = model_time_distributed_MobilenetV3small_re_lu_27_Relu6_cast_fp16, y = model_time_distributed_MobilenetV3small_tf_math_multiply_22_Mul_y_to_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_multiply_22_Mul_cast_fp16")];
            tensor<fp16, [20, 7, 7, 576]> model_time_distributed_MobilenetV3small_expanded_conv_9_squeeze_excite_Mul_mul_cast_fp16 = mul(x = model_time_distributed_MobilenetV3small_multiply_14_mul_cast_fp16, y = model_time_distributed_MobilenetV3small_tf_math_multiply_22_Mul_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_9_squeeze_excite_Mul_mul_cast_fp16")];
            tensor<int32, [4]> transpose_120_perm_0 = const()[name = tensor<string, []>("transpose_120_perm_0"), val = tensor<int32, [4]>([0, 3, 1, 2])];
            tensor<string, []> model_time_distributed_MobilenetV3small_expanded_conv_9_project_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_9_project_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_9_project_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_9_project_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_9_project_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_9_project_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_time_distributed_MobilenetV3small_expanded_conv_9_project_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_9_project_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_9_project_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_9_project_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [96, 576, 1, 1]> transpose_119_to_fp16_quantized = constexpr_affine_dequantize()[axis = tensor<int32, []>(0), name = tensor<string, []>("transpose_119_to_fp16_quantized"), quantized_data = tensor<int8, [96, 576, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(583488))), scale = tensor<fp16, [96]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(639040))), zero_point = tensor<int8, [96]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(638848)))];
            tensor<fp16, [20, 576, 7, 7]> transpose_192 = transpose(perm = transpose_120_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_9_squeeze_excite_Mul_mul_cast_fp16)[name = tensor<string, []>("transpose_14")];
            tensor<fp16, [20, 96, 7, 7]> model_time_distributed_MobilenetV3small_expanded_conv_9_project_Conv2Dx_cast_fp16 = conv(dilations = model_time_distributed_MobilenetV3small_expanded_conv_9_project_Conv2Dx_dilations_0, groups = model_time_distributed_MobilenetV3small_expanded_conv_9_project_Conv2Dx_groups_0, pad = model_time_distributed_MobilenetV3small_expanded_conv_9_project_Conv2Dx_pad_0, pad_type = model_time_distributed_MobilenetV3small_expanded_conv_9_project_Conv2Dx_pad_type_0, strides = model_time_distributed_MobilenetV3small_expanded_conv_9_project_Conv2Dx_strides_0, weight = transpose_119_to_fp16_quantized, x = transpose_192)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_9_project_Conv2Dx_cast_fp16")];
            tensor<fp16, [96]> model_time_distributed_MobilenetV3small_expanded_conv_9_project_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_9_project_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16"), val = tensor<fp16, [96]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(639296)))];
            tensor<fp16, [96]> model_time_distributed_MobilenetV3small_expanded_conv_9_project_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_9_project_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16"), val = tensor<fp16, [96]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(639552)))];
            tensor<fp16, [96]> model_time_distributed_MobilenetV3small_expanded_conv_9_project_BatchNorm_ReadVariableOp_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_9_project_BatchNorm_ReadVariableOp_to_fp16"), val = tensor<fp16, [96]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(639808)))];
            tensor<fp16, [96]> model_time_distributed_MobilenetV3small_expanded_conv_9_project_BatchNorm_ReadVariableOp_1_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_9_project_BatchNorm_ReadVariableOp_1_to_fp16"), val = tensor<fp16, [96]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(640064)))];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_expanded_conv_9_project_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_9_project_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.064p-10)];
            tensor<fp16, [20, 96, 7, 7]> model_time_distributed_MobilenetV3small_expanded_conv_9_project_BatchNorm_FusedBatchNormV3_nchw_cast_fp16 = batch_norm(beta = model_time_distributed_MobilenetV3small_expanded_conv_9_project_BatchNorm_ReadVariableOp_1_to_fp16, epsilon = model_time_distributed_MobilenetV3small_expanded_conv_9_project_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16, gamma = model_time_distributed_MobilenetV3small_expanded_conv_9_project_BatchNorm_ReadVariableOp_to_fp16, mean = model_time_distributed_MobilenetV3small_expanded_conv_9_project_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16, variance = model_time_distributed_MobilenetV3small_expanded_conv_9_project_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16, x = model_time_distributed_MobilenetV3small_expanded_conv_9_project_Conv2Dx_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_9_project_BatchNorm_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_9_project_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_9_project_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0"), val = tensor<int32, [4]>([0, 2, 3, 1])];
            tensor<fp16, [20, 7, 7, 96]> transpose_191 = transpose(perm = model_time_distributed_MobilenetV3small_expanded_conv_9_project_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_9_project_BatchNorm_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("transpose_13")];
            tensor<fp16, [20, 7, 7, 96]> model_time_distributed_MobilenetV3small_expanded_conv_9_Add_add_cast_fp16 = add(x = transpose_201, y = transpose_191)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_9_Add_add_cast_fp16")];
            tensor<int32, [4]> transpose_123_perm_0 = const()[name = tensor<string, []>("transpose_123_perm_0"), val = tensor<int32, [4]>([0, 3, 1, 2])];
            tensor<string, []> model_time_distributed_MobilenetV3small_expanded_conv_10_expand_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_10_expand_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_10_expand_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_10_expand_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_10_expand_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_10_expand_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_time_distributed_MobilenetV3small_expanded_conv_10_expand_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_10_expand_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_10_expand_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_10_expand_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [576, 96, 1, 1]> transpose_122_to_fp16_quantized = constexpr_affine_dequantize()[axis = tensor<int32, []>(0), name = tensor<string, []>("transpose_122_to_fp16_quantized"), quantized_data = tensor<int8, [576, 96, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(640320))), scale = tensor<fp16, [576]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(695680))), zero_point = tensor<int8, [576]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(387008)))];
            tensor<fp16, [20, 96, 7, 7]> transpose_190 = transpose(perm = transpose_123_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_9_Add_add_cast_fp16)[name = tensor<string, []>("transpose_12")];
            tensor<fp16, [20, 576, 7, 7]> model_time_distributed_MobilenetV3small_expanded_conv_10_expand_Conv2Dx_cast_fp16 = conv(dilations = model_time_distributed_MobilenetV3small_expanded_conv_10_expand_Conv2Dx_dilations_0, groups = model_time_distributed_MobilenetV3small_expanded_conv_10_expand_Conv2Dx_groups_0, pad = model_time_distributed_MobilenetV3small_expanded_conv_10_expand_Conv2Dx_pad_0, pad_type = model_time_distributed_MobilenetV3small_expanded_conv_10_expand_Conv2Dx_pad_type_0, strides = model_time_distributed_MobilenetV3small_expanded_conv_10_expand_Conv2Dx_strides_0, weight = transpose_122_to_fp16_quantized, x = transpose_190)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_10_expand_Conv2Dx_cast_fp16")];
            tensor<fp16, [576]> model_time_distributed_MobilenetV3small_expanded_conv_10_expand_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_10_expand_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16"), val = tensor<fp16, [576]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(696896)))];
            tensor<fp16, [576]> model_time_distributed_MobilenetV3small_expanded_conv_10_expand_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_10_expand_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16"), val = tensor<fp16, [576]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(698112)))];
            tensor<fp16, [576]> model_time_distributed_MobilenetV3small_expanded_conv_10_expand_BatchNorm_ReadVariableOp_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_10_expand_BatchNorm_ReadVariableOp_to_fp16"), val = tensor<fp16, [576]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(699328)))];
            tensor<fp16, [576]> model_time_distributed_MobilenetV3small_expanded_conv_10_expand_BatchNorm_ReadVariableOp_1_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_10_expand_BatchNorm_ReadVariableOp_1_to_fp16"), val = tensor<fp16, [576]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(700544)))];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_expanded_conv_10_expand_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_10_expand_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.064p-10)];
            tensor<fp16, [20, 576, 7, 7]> model_time_distributed_MobilenetV3small_expanded_conv_10_expand_BatchNorm_FusedBatchNormV3_nchw_cast_fp16 = batch_norm(beta = model_time_distributed_MobilenetV3small_expanded_conv_10_expand_BatchNorm_ReadVariableOp_1_to_fp16, epsilon = model_time_distributed_MobilenetV3small_expanded_conv_10_expand_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16, gamma = model_time_distributed_MobilenetV3small_expanded_conv_10_expand_BatchNorm_ReadVariableOp_to_fp16, mean = model_time_distributed_MobilenetV3small_expanded_conv_10_expand_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16, variance = model_time_distributed_MobilenetV3small_expanded_conv_10_expand_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16, x = model_time_distributed_MobilenetV3small_expanded_conv_10_expand_Conv2Dx_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_10_expand_BatchNorm_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_10_expand_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_10_expand_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0"), val = tensor<int32, [4]>([0, 2, 3, 1])];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_tf_math_add_23_Add_y_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_add_23_Add_y_to_fp16"), val = tensor<fp16, []>(0x1.8p+1)];
            tensor<fp16, [20, 7, 7, 576]> transpose_189 = transpose(perm = model_time_distributed_MobilenetV3small_expanded_conv_10_expand_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_10_expand_BatchNorm_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("transpose_11")];
            tensor<fp16, [20, 7, 7, 576]> model_time_distributed_MobilenetV3small_tf_math_add_23_Add_cast_fp16 = add(x = transpose_189, y = model_time_distributed_MobilenetV3small_tf_math_add_23_Add_y_to_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_add_23_Add_cast_fp16")];
            tensor<fp16, [20, 7, 7, 576]> model_time_distributed_MobilenetV3small_re_lu_28_Relu6_cast_fp16 = relu6(x = model_time_distributed_MobilenetV3small_tf_math_add_23_Add_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_re_lu_28_Relu6_cast_fp16")];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_tf_math_multiply_23_Mul_y_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_multiply_23_Mul_y_to_fp16"), val = tensor<fp16, []>(0x1.554p-3)];
            tensor<fp16, [20, 7, 7, 576]> model_time_distributed_MobilenetV3small_tf_math_multiply_23_Mul_cast_fp16 = mul(x = model_time_distributed_MobilenetV3small_re_lu_28_Relu6_cast_fp16, y = model_time_distributed_MobilenetV3small_tf_math_multiply_23_Mul_y_to_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_multiply_23_Mul_cast_fp16")];
            tensor<fp16, [20, 7, 7, 576]> model_time_distributed_MobilenetV3small_multiply_15_mul_cast_fp16 = mul(x = transpose_189, y = model_time_distributed_MobilenetV3small_tf_math_multiply_23_Mul_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_multiply_15_mul_cast_fp16")];
            tensor<int32, [4]> transpose_126_perm_0 = const()[name = tensor<string, []>("transpose_126_perm_0"), val = tensor<int32, [4]>([0, 3, 1, 2])];
            tensor<string, []> model_time_distributed_MobilenetV3small_expanded_conv_10_depthwise_depthwisex_pad_type_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_10_depthwise_depthwisex_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_10_depthwise_depthwisex_strides_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_10_depthwise_depthwisex_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_10_depthwise_depthwisex_dilations_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_10_depthwise_depthwisex_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_time_distributed_MobilenetV3small_expanded_conv_10_depthwise_depthwisex_groups_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_10_depthwise_depthwisex_groups_0"), val = tensor<int32, []>(576)];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_10_depthwise_depthwisex_pad_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_10_depthwise_depthwisex_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [576, 1, 5, 5]> transpose_125_to_fp16_quantized = constexpr_affine_dequantize()[axis = tensor<int32, []>(0), name = tensor<string, []>("transpose_125_to_fp16_quantized"), quantized_data = tensor<int8, [576, 1, 5, 5]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(701760))), scale = tensor<fp16, [576]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(716224))), zero_point = tensor<int8, [576]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(387008)))];
            tensor<fp16, [20, 576, 7, 7]> transpose_188 = transpose(perm = transpose_126_perm_0, x = model_time_distributed_MobilenetV3small_multiply_15_mul_cast_fp16)[name = tensor<string, []>("transpose_10")];
            tensor<fp16, [20, 576, 7, 7]> model_time_distributed_MobilenetV3small_expanded_conv_10_depthwise_depthwisex_cast_fp16 = conv(dilations = model_time_distributed_MobilenetV3small_expanded_conv_10_depthwise_depthwisex_dilations_0, groups = model_time_distributed_MobilenetV3small_expanded_conv_10_depthwise_depthwisex_groups_0, pad = model_time_distributed_MobilenetV3small_expanded_conv_10_depthwise_depthwisex_pad_0, pad_type = model_time_distributed_MobilenetV3small_expanded_conv_10_depthwise_depthwisex_pad_type_0, strides = model_time_distributed_MobilenetV3small_expanded_conv_10_depthwise_depthwisex_strides_0, weight = transpose_125_to_fp16_quantized, x = transpose_188)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_10_depthwise_depthwisex_cast_fp16")];
            tensor<fp16, [576]> model_time_distributed_MobilenetV3small_expanded_conv_10_depthwise_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_10_depthwise_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16"), val = tensor<fp16, [576]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(717440)))];
            tensor<fp16, [576]> model_time_distributed_MobilenetV3small_expanded_conv_10_depthwise_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_10_depthwise_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16"), val = tensor<fp16, [576]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(718656)))];
            tensor<fp16, [576]> model_time_distributed_MobilenetV3small_expanded_conv_10_depthwise_BatchNorm_ReadVariableOp_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_10_depthwise_BatchNorm_ReadVariableOp_to_fp16"), val = tensor<fp16, [576]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(719872)))];
            tensor<fp16, [576]> model_time_distributed_MobilenetV3small_expanded_conv_10_depthwise_BatchNorm_ReadVariableOp_1_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_10_depthwise_BatchNorm_ReadVariableOp_1_to_fp16"), val = tensor<fp16, [576]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(721088)))];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_expanded_conv_10_depthwise_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_10_depthwise_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.064p-10)];
            tensor<fp16, [20, 576, 7, 7]> model_time_distributed_MobilenetV3small_expanded_conv_10_depthwise_BatchNorm_FusedBatchNormV3_nchw_cast_fp16 = batch_norm(beta = model_time_distributed_MobilenetV3small_expanded_conv_10_depthwise_BatchNorm_ReadVariableOp_1_to_fp16, epsilon = model_time_distributed_MobilenetV3small_expanded_conv_10_depthwise_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16, gamma = model_time_distributed_MobilenetV3small_expanded_conv_10_depthwise_BatchNorm_ReadVariableOp_to_fp16, mean = model_time_distributed_MobilenetV3small_expanded_conv_10_depthwise_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16, variance = model_time_distributed_MobilenetV3small_expanded_conv_10_depthwise_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16, x = model_time_distributed_MobilenetV3small_expanded_conv_10_depthwise_depthwisex_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_10_depthwise_BatchNorm_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_10_depthwise_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_10_depthwise_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0"), val = tensor<int32, [4]>([0, 2, 3, 1])];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_tf_math_add_24_Add_y_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_add_24_Add_y_to_fp16"), val = tensor<fp16, []>(0x1.8p+1)];
            tensor<fp16, [20, 7, 7, 576]> transpose_187 = transpose(perm = model_time_distributed_MobilenetV3small_expanded_conv_10_depthwise_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_10_depthwise_BatchNorm_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("transpose_9")];
            tensor<fp16, [20, 7, 7, 576]> model_time_distributed_MobilenetV3small_tf_math_add_24_Add_cast_fp16 = add(x = transpose_187, y = model_time_distributed_MobilenetV3small_tf_math_add_24_Add_y_to_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_add_24_Add_cast_fp16")];
            tensor<fp16, [20, 7, 7, 576]> model_time_distributed_MobilenetV3small_re_lu_29_Relu6_cast_fp16 = relu6(x = model_time_distributed_MobilenetV3small_tf_math_add_24_Add_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_re_lu_29_Relu6_cast_fp16")];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_tf_math_multiply_24_Mul_y_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_multiply_24_Mul_y_to_fp16"), val = tensor<fp16, []>(0x1.554p-3)];
            tensor<fp16, [20, 7, 7, 576]> model_time_distributed_MobilenetV3small_tf_math_multiply_24_Mul_cast_fp16 = mul(x = model_time_distributed_MobilenetV3small_re_lu_29_Relu6_cast_fp16, y = model_time_distributed_MobilenetV3small_tf_math_multiply_24_Mul_y_to_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_multiply_24_Mul_cast_fp16")];
            tensor<fp16, [20, 7, 7, 576]> model_time_distributed_MobilenetV3small_multiply_16_mul_cast_fp16 = mul(x = transpose_187, y = model_time_distributed_MobilenetV3small_tf_math_multiply_24_Mul_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_multiply_16_mul_cast_fp16")];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_10_squeeze_excite_AvgPool_Mean_axes_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_10_squeeze_excite_AvgPool_Mean_axes_0"), val = tensor<int32, [2]>([1, 2])];
            tensor<bool, []> model_time_distributed_MobilenetV3small_expanded_conv_10_squeeze_excite_AvgPool_Mean_keep_dims_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_10_squeeze_excite_AvgPool_Mean_keep_dims_0"), val = tensor<bool, []>(true)];
            tensor<fp16, [20, 1, 1, 576]> model_time_distributed_MobilenetV3small_expanded_conv_10_squeeze_excite_AvgPool_Mean_cast_fp16 = reduce_mean(axes = model_time_distributed_MobilenetV3small_expanded_conv_10_squeeze_excite_AvgPool_Mean_axes_0, keep_dims = model_time_distributed_MobilenetV3small_expanded_conv_10_squeeze_excite_AvgPool_Mean_keep_dims_0, x = model_time_distributed_MobilenetV3small_multiply_16_mul_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_10_squeeze_excite_AvgPool_Mean_cast_fp16")];
            tensor<int32, [4]> transpose_129_perm_0 = const()[name = tensor<string, []>("transpose_129_perm_0"), val = tensor<int32, [4]>([0, 3, 1, 2])];
            tensor<string, []> model_time_distributed_MobilenetV3small_expanded_conv_10_squeeze_excite_Conv_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_10_squeeze_excite_Conv_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_10_squeeze_excite_Conv_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_10_squeeze_excite_Conv_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_10_squeeze_excite_Conv_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_10_squeeze_excite_Conv_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_time_distributed_MobilenetV3small_expanded_conv_10_squeeze_excite_Conv_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_10_squeeze_excite_Conv_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_10_squeeze_excite_Conv_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_10_squeeze_excite_Conv_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [144, 576, 1, 1]> conv_16_weight_0_to_fp16_quantized = constexpr_affine_dequantize()[axis = tensor<int32, []>(0), name = tensor<string, []>("conv_16_weight_0_to_fp16_quantized"), quantized_data = tensor<int8, [144, 576, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(722304))), scale = tensor<fp16, [144]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(805312))), zero_point = tensor<int8, [144]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(202112)))];
            tensor<fp16, [144]> conv_16_bias_0_to_fp16 = const()[name = tensor<string, []>("conv_16_bias_0_to_fp16"), val = tensor<fp16, [144]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(805696)))];
            tensor<fp16, [20, 576, 1, 1]> transpose_186 = transpose(perm = transpose_129_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_10_squeeze_excite_AvgPool_Mean_cast_fp16)[name = tensor<string, []>("transpose_8")];
            tensor<fp16, [20, 144, 1, 1]> conv_16_cast_fp16 = conv(bias = conv_16_bias_0_to_fp16, dilations = model_time_distributed_MobilenetV3small_expanded_conv_10_squeeze_excite_Conv_Conv2Dx_dilations_0, groups = model_time_distributed_MobilenetV3small_expanded_conv_10_squeeze_excite_Conv_Conv2Dx_groups_0, pad = model_time_distributed_MobilenetV3small_expanded_conv_10_squeeze_excite_Conv_Conv2Dx_pad_0, pad_type = model_time_distributed_MobilenetV3small_expanded_conv_10_squeeze_excite_Conv_Conv2Dx_pad_type_0, strides = model_time_distributed_MobilenetV3small_expanded_conv_10_squeeze_excite_Conv_Conv2Dx_strides_0, weight = conv_16_weight_0_to_fp16_quantized, x = transpose_186)[name = tensor<string, []>("conv_16_cast_fp16")];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_10_squeeze_excite_Conv_Conv2D_perm_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_10_squeeze_excite_Conv_Conv2D_perm_0"), val = tensor<int32, [4]>([0, 2, 3, 1])];
            tensor<fp16, [20, 1, 1, 144]> transpose_185 = transpose(perm = model_time_distributed_MobilenetV3small_expanded_conv_10_squeeze_excite_Conv_Conv2D_perm_0, x = conv_16_cast_fp16)[name = tensor<string, []>("transpose_7")];
            tensor<fp16, [20, 1, 1, 144]> model_time_distributed_MobilenetV3small_expanded_conv_10_squeeze_excite_Relu_Relu_cast_fp16 = relu(x = transpose_185)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_10_squeeze_excite_Relu_Relu_cast_fp16")];
            tensor<int32, [4]> transpose_131_perm_0 = const()[name = tensor<string, []>("transpose_131_perm_0"), val = tensor<int32, [4]>([0, 3, 1, 2])];
            tensor<string, []> model_time_distributed_MobilenetV3small_expanded_conv_10_squeeze_excite_Conv_1_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_10_squeeze_excite_Conv_1_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_10_squeeze_excite_Conv_1_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_10_squeeze_excite_Conv_1_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_10_squeeze_excite_Conv_1_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_10_squeeze_excite_Conv_1_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_time_distributed_MobilenetV3small_expanded_conv_10_squeeze_excite_Conv_1_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_10_squeeze_excite_Conv_1_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_10_squeeze_excite_Conv_1_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_10_squeeze_excite_Conv_1_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [576, 144, 1, 1]> conv_26_weight_0_to_fp16_quantized = constexpr_affine_dequantize()[axis = tensor<int32, []>(0), name = tensor<string, []>("conv_26_weight_0_to_fp16_quantized"), quantized_data = tensor<int8, [576, 144, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(806080))), scale = tensor<fp16, [576]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(889088))), zero_point = tensor<int8, [576]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(387008)))];
            tensor<fp16, [576]> conv_26_bias_0_to_fp16 = const()[name = tensor<string, []>("conv_26_bias_0_to_fp16"), val = tensor<fp16, [576]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(890304)))];
            tensor<fp16, [20, 144, 1, 1]> transpose_184 = transpose(perm = transpose_131_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_10_squeeze_excite_Relu_Relu_cast_fp16)[name = tensor<string, []>("transpose_6")];
            tensor<fp16, [20, 576, 1, 1]> conv_26_cast_fp16 = conv(bias = conv_26_bias_0_to_fp16, dilations = model_time_distributed_MobilenetV3small_expanded_conv_10_squeeze_excite_Conv_1_Conv2Dx_dilations_0, groups = model_time_distributed_MobilenetV3small_expanded_conv_10_squeeze_excite_Conv_1_Conv2Dx_groups_0, pad = model_time_distributed_MobilenetV3small_expanded_conv_10_squeeze_excite_Conv_1_Conv2Dx_pad_0, pad_type = model_time_distributed_MobilenetV3small_expanded_conv_10_squeeze_excite_Conv_1_Conv2Dx_pad_type_0, strides = model_time_distributed_MobilenetV3small_expanded_conv_10_squeeze_excite_Conv_1_Conv2Dx_strides_0, weight = conv_26_weight_0_to_fp16_quantized, x = transpose_184)[name = tensor<string, []>("conv_26_cast_fp16")];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_10_squeeze_excite_Conv_1_Conv2D_perm_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_10_squeeze_excite_Conv_1_Conv2D_perm_0"), val = tensor<int32, [4]>([0, 2, 3, 1])];
            tensor<fp16, [20, 1, 1, 576]> transpose_183 = transpose(perm = model_time_distributed_MobilenetV3small_expanded_conv_10_squeeze_excite_Conv_1_Conv2D_perm_0, x = conv_26_cast_fp16)[name = tensor<string, []>("transpose_5")];
            tensor<fp16, [20, 1, 1, 576]> model_time_distributed_MobilenetV3small_re_lu_30_Relu6_cast_fp16 = relu6(x = transpose_183)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_re_lu_30_Relu6_cast_fp16")];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_tf_math_multiply_25_Mul_y_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_multiply_25_Mul_y_to_fp16"), val = tensor<fp16, []>(0x1.554p-3)];
            tensor<fp16, [20, 1, 1, 576]> model_time_distributed_MobilenetV3small_tf_math_multiply_25_Mul_cast_fp16 = mul(x = model_time_distributed_MobilenetV3small_re_lu_30_Relu6_cast_fp16, y = model_time_distributed_MobilenetV3small_tf_math_multiply_25_Mul_y_to_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_multiply_25_Mul_cast_fp16")];
            tensor<fp16, [20, 7, 7, 576]> model_time_distributed_MobilenetV3small_expanded_conv_10_squeeze_excite_Mul_mul_cast_fp16 = mul(x = model_time_distributed_MobilenetV3small_multiply_16_mul_cast_fp16, y = model_time_distributed_MobilenetV3small_tf_math_multiply_25_Mul_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_10_squeeze_excite_Mul_mul_cast_fp16")];
            tensor<int32, [4]> transpose_133_perm_0 = const()[name = tensor<string, []>("transpose_133_perm_0"), val = tensor<int32, [4]>([0, 3, 1, 2])];
            tensor<string, []> model_time_distributed_MobilenetV3small_expanded_conv_10_project_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_10_project_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_10_project_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_10_project_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_expanded_conv_10_project_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_10_project_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_time_distributed_MobilenetV3small_expanded_conv_10_project_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_10_project_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_10_project_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_10_project_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [96, 576, 1, 1]> transpose_132_to_fp16_quantized = constexpr_affine_dequantize()[axis = tensor<int32, []>(0), name = tensor<string, []>("transpose_132_to_fp16_quantized"), quantized_data = tensor<int8, [96, 576, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(891520))), scale = tensor<fp16, [96]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(947072))), zero_point = tensor<int8, [96]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(946880)))];
            tensor<fp16, [20, 576, 7, 7]> transpose_182 = transpose(perm = transpose_133_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_10_squeeze_excite_Mul_mul_cast_fp16)[name = tensor<string, []>("transpose_4")];
            tensor<fp16, [20, 96, 7, 7]> model_time_distributed_MobilenetV3small_expanded_conv_10_project_Conv2Dx_cast_fp16 = conv(dilations = model_time_distributed_MobilenetV3small_expanded_conv_10_project_Conv2Dx_dilations_0, groups = model_time_distributed_MobilenetV3small_expanded_conv_10_project_Conv2Dx_groups_0, pad = model_time_distributed_MobilenetV3small_expanded_conv_10_project_Conv2Dx_pad_0, pad_type = model_time_distributed_MobilenetV3small_expanded_conv_10_project_Conv2Dx_pad_type_0, strides = model_time_distributed_MobilenetV3small_expanded_conv_10_project_Conv2Dx_strides_0, weight = transpose_132_to_fp16_quantized, x = transpose_182)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_10_project_Conv2Dx_cast_fp16")];
            tensor<fp16, [96]> model_time_distributed_MobilenetV3small_expanded_conv_10_project_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_10_project_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16"), val = tensor<fp16, [96]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(947328)))];
            tensor<fp16, [96]> model_time_distributed_MobilenetV3small_expanded_conv_10_project_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_10_project_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16"), val = tensor<fp16, [96]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(947584)))];
            tensor<fp16, [96]> model_time_distributed_MobilenetV3small_expanded_conv_10_project_BatchNorm_ReadVariableOp_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_10_project_BatchNorm_ReadVariableOp_to_fp16"), val = tensor<fp16, [96]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(947840)))];
            tensor<fp16, [96]> model_time_distributed_MobilenetV3small_expanded_conv_10_project_BatchNorm_ReadVariableOp_1_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_10_project_BatchNorm_ReadVariableOp_1_to_fp16"), val = tensor<fp16, [96]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(948096)))];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_expanded_conv_10_project_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_10_project_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.064p-10)];
            tensor<fp16, [20, 96, 7, 7]> model_time_distributed_MobilenetV3small_expanded_conv_10_project_BatchNorm_FusedBatchNormV3_nchw_cast_fp16 = batch_norm(beta = model_time_distributed_MobilenetV3small_expanded_conv_10_project_BatchNorm_ReadVariableOp_1_to_fp16, epsilon = model_time_distributed_MobilenetV3small_expanded_conv_10_project_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16, gamma = model_time_distributed_MobilenetV3small_expanded_conv_10_project_BatchNorm_ReadVariableOp_to_fp16, mean = model_time_distributed_MobilenetV3small_expanded_conv_10_project_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16, variance = model_time_distributed_MobilenetV3small_expanded_conv_10_project_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16, x = model_time_distributed_MobilenetV3small_expanded_conv_10_project_Conv2Dx_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_10_project_BatchNorm_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_expanded_conv_10_project_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_10_project_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0"), val = tensor<int32, [4]>([0, 2, 3, 1])];
            tensor<fp16, [20, 7, 7, 96]> transpose_181 = transpose(perm = model_time_distributed_MobilenetV3small_expanded_conv_10_project_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_10_project_BatchNorm_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("transpose_3")];
            tensor<fp16, [20, 7, 7, 96]> model_time_distributed_MobilenetV3small_expanded_conv_10_Add_add_cast_fp16 = add(x = model_time_distributed_MobilenetV3small_expanded_conv_9_Add_add_cast_fp16, y = transpose_181)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_expanded_conv_10_Add_add_cast_fp16")];
            tensor<int32, [4]> transpose_136_perm_0 = const()[name = tensor<string, []>("transpose_136_perm_0"), val = tensor<int32, [4]>([0, 3, 1, 2])];
            tensor<string, []> model_time_distributed_MobilenetV3small_Conv_1_Conv2Dx_pad_type_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_Conv_1_Conv2Dx_pad_type_0"), val = tensor<string, []>("same")];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_Conv_1_Conv2Dx_strides_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_Conv_1_Conv2Dx_strides_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, [2]> model_time_distributed_MobilenetV3small_Conv_1_Conv2Dx_dilations_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_Conv_1_Conv2Dx_dilations_0"), val = tensor<int32, [2]>([1, 1])];
            tensor<int32, []> model_time_distributed_MobilenetV3small_Conv_1_Conv2Dx_groups_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_Conv_1_Conv2Dx_groups_0"), val = tensor<int32, []>(1)];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_Conv_1_Conv2Dx_pad_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_Conv_1_Conv2Dx_pad_0"), val = tensor<int32, [4]>([0, 0, 0, 0])];
            tensor<fp16, [576, 96, 1, 1]> transpose_135_to_fp16_quantized = constexpr_affine_dequantize()[axis = tensor<int32, []>(0), name = tensor<string, []>("transpose_135_to_fp16_quantized"), quantized_data = tensor<int8, [576, 96, 1, 1]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(948352))), scale = tensor<fp16, [576]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(1003712))), zero_point = tensor<int8, [576]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(387008)))];
            tensor<fp16, [20, 96, 7, 7]> transpose_180 = transpose(perm = transpose_136_perm_0, x = model_time_distributed_MobilenetV3small_expanded_conv_10_Add_add_cast_fp16)[name = tensor<string, []>("transpose_2")];
            tensor<fp16, [20, 576, 7, 7]> model_time_distributed_MobilenetV3small_Conv_1_Conv2Dx_cast_fp16 = conv(dilations = model_time_distributed_MobilenetV3small_Conv_1_Conv2Dx_dilations_0, groups = model_time_distributed_MobilenetV3small_Conv_1_Conv2Dx_groups_0, pad = model_time_distributed_MobilenetV3small_Conv_1_Conv2Dx_pad_0, pad_type = model_time_distributed_MobilenetV3small_Conv_1_Conv2Dx_pad_type_0, strides = model_time_distributed_MobilenetV3small_Conv_1_Conv2Dx_strides_0, weight = transpose_135_to_fp16_quantized, x = transpose_180)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_Conv_1_Conv2Dx_cast_fp16")];
            tensor<fp16, [576]> model_time_distributed_MobilenetV3small_Conv_1_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_Conv_1_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16"), val = tensor<fp16, [576]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(1004928)))];
            tensor<fp16, [576]> model_time_distributed_MobilenetV3small_Conv_1_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_Conv_1_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16"), val = tensor<fp16, [576]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(1006144)))];
            tensor<fp16, [576]> model_time_distributed_MobilenetV3small_Conv_1_BatchNorm_ReadVariableOp_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_Conv_1_BatchNorm_ReadVariableOp_to_fp16"), val = tensor<fp16, [576]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(1007360)))];
            tensor<fp16, [576]> model_time_distributed_MobilenetV3small_Conv_1_BatchNorm_ReadVariableOp_1_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_Conv_1_BatchNorm_ReadVariableOp_1_to_fp16"), val = tensor<fp16, [576]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(1008576)))];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_Conv_1_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_Conv_1_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16"), val = tensor<fp16, []>(0x1.064p-10)];
            tensor<fp16, [20, 576, 7, 7]> model_time_distributed_MobilenetV3small_Conv_1_BatchNorm_FusedBatchNormV3_nchw_cast_fp16 = batch_norm(beta = model_time_distributed_MobilenetV3small_Conv_1_BatchNorm_ReadVariableOp_1_to_fp16, epsilon = model_time_distributed_MobilenetV3small_Conv_1_BatchNorm_FusedBatchNormV3_nchw_epsilon_0_to_fp16, gamma = model_time_distributed_MobilenetV3small_Conv_1_BatchNorm_ReadVariableOp_to_fp16, mean = model_time_distributed_MobilenetV3small_Conv_1_BatchNorm_FusedBatchNormV3_ReadVariableOp_to_fp16, variance = model_time_distributed_MobilenetV3small_Conv_1_BatchNorm_FusedBatchNormV3_ReadVariableOp_1_to_fp16, x = model_time_distributed_MobilenetV3small_Conv_1_Conv2Dx_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_Conv_1_BatchNorm_FusedBatchNormV3_nchw_cast_fp16")];
            tensor<int32, [4]> model_time_distributed_MobilenetV3small_Conv_1_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_Conv_1_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0"), val = tensor<int32, [4]>([0, 2, 3, 1])];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_tf_math_add_26_Add_y_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_add_26_Add_y_to_fp16"), val = tensor<fp16, []>(0x1.8p+1)];
            tensor<fp16, [20, 7, 7, 576]> transpose_179 = transpose(perm = model_time_distributed_MobilenetV3small_Conv_1_BatchNorm_FusedBatchNormV3_to_NHWC_perm_0, x = model_time_distributed_MobilenetV3small_Conv_1_BatchNorm_FusedBatchNormV3_nchw_cast_fp16)[name = tensor<string, []>("transpose_1")];
            tensor<fp16, [20, 7, 7, 576]> model_time_distributed_MobilenetV3small_tf_math_add_26_Add_cast_fp16 = add(x = transpose_179, y = model_time_distributed_MobilenetV3small_tf_math_add_26_Add_y_to_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_add_26_Add_cast_fp16")];
            tensor<fp16, [20, 7, 7, 576]> model_time_distributed_MobilenetV3small_re_lu_31_Relu6_cast_fp16 = relu6(x = model_time_distributed_MobilenetV3small_tf_math_add_26_Add_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_re_lu_31_Relu6_cast_fp16")];
            tensor<fp16, []> model_time_distributed_MobilenetV3small_tf_math_multiply_26_Mul_y_to_fp16 = const()[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_multiply_26_Mul_y_to_fp16"), val = tensor<fp16, []>(0x1.554p-3)];
            tensor<fp16, [20, 7, 7, 576]> model_time_distributed_MobilenetV3small_tf_math_multiply_26_Mul_cast_fp16 = mul(x = model_time_distributed_MobilenetV3small_re_lu_31_Relu6_cast_fp16, y = model_time_distributed_MobilenetV3small_tf_math_multiply_26_Mul_y_to_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_tf_math_multiply_26_Mul_cast_fp16")];
            tensor<fp16, [20, 7, 7, 576]> model_time_distributed_MobilenetV3small_multiply_17_mul_cast_fp16 = mul(x = transpose_179, y = model_time_distributed_MobilenetV3small_tf_math_multiply_26_Mul_cast_fp16)[name = tensor<string, []>("model_time_distributed_MobilenetV3small_multiply_17_mul_cast_fp16")];
            tensor<int32, [2]> model_time_distributed_1_global_average_pooling2d_Mean_axes_0 = const()[name = tensor<string, []>("model_time_distributed_1_global_average_pooling2d_Mean_axes_0"), val = tensor<int32, [2]>([1, 2])];
            tensor<bool, []> model_time_distributed_1_global_average_pooling2d_Mean_keep_dims_0 = const()[name = tensor<string, []>("model_time_distributed_1_global_average_pooling2d_Mean_keep_dims_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [20, 576]> model_time_distributed_1_global_average_pooling2d_Mean_cast_fp16 = reduce_mean(axes = model_time_distributed_1_global_average_pooling2d_Mean_axes_0, keep_dims = model_time_distributed_1_global_average_pooling2d_Mean_keep_dims_0, x = model_time_distributed_MobilenetV3small_multiply_17_mul_cast_fp16)[name = tensor<string, []>("model_time_distributed_1_global_average_pooling2d_Mean_cast_fp16")];
            tensor<fp16, [1, 20, 576]> model_time_distributed_1_Reshape_1_cast_fp16 = reshape(shape = model_time_distributed_1_Reshape_1_shape, x = model_time_distributed_1_global_average_pooling2d_Mean_cast_fp16)[name = tensor<string, []>("model_time_distributed_1_Reshape_1_cast_fp16")];
            tensor<string, []> model_bidirectional_forward_lstm_PartitionedCall_transpose_cast_fp16_to_fp32_dtype_0 = const()[name = tensor<string, []>("model_bidirectional_forward_lstm_PartitionedCall_transpose_cast_fp16_to_fp32_dtype_0"), val = tensor<string, []>("fp32")];
            tensor<int32, []> slice_by_index_0 = const()[name = tensor<string, []>("slice_by_index_0"), val = tensor<int32, []>(20)];
            tensor<string, []> tf_make_list_0_dtype_0 = const()[name = tensor<string, []>("tf_make_list_0_dtype_0"), val = tensor<string, []>("fp32")];
            tensor<bool, []> tf_make_list_0_dynamic_length_0 = const()[name = tensor<string, []>("tf_make_list_0_dynamic_length_0"), val = tensor<bool, []>(true)];
            tensor<int32, []> tf_make_list_0_elem_shape0_0 = const()[name = tensor<string, []>("tf_make_list_0_elem_shape0_0"), val = tensor<int32, []>(1)];
            tensor<int32, []> tf_make_list_0_elem_shape1_0 = const()[name = tensor<string, []>("tf_make_list_0_elem_shape1_0"), val = tensor<int32, []>(576)];
            list<tensor<fp32, [1, 576]>, 20> tf_make_list_0 = make_list(dtype = tf_make_list_0_dtype_0, dynamic_length = tf_make_list_0_dynamic_length_0, elem_shape = (tf_make_list_0_elem_shape0_0, tf_make_list_0_elem_shape1_0), init_length = slice_by_index_0)[name = tensor<string, []>("tf_make_list_0")];
            tensor<int32, [20]> range_1d_0 = const()[name = tensor<string, []>("range_1d_0"), val = tensor<int32, [20]>([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])];
            tensor<fp16, [20, 1, 576]> transpose_178 = transpose(perm = model_bidirectional_forward_lstm_PartitionedCall_transpose_perm, x = model_time_distributed_1_Reshape_1_cast_fp16)[name = tensor<string, []>("transpose_0")];
            tensor<fp32, [20, 1, 576]> cast_52 = cast(dtype = model_bidirectional_forward_lstm_PartitionedCall_transpose_cast_fp16_to_fp32_dtype_0, x = transpose_178)[name = tensor<string, []>("cast_14")];
            list<tensor<fp32, [1, 576]>, 20> model_bidirectional_forward_lstm_PartitionedCall_TensorArrayUnstack_TensorListFromTensor = list_scatter(indices = range_1d_0, ls = tf_make_list_0, value = cast_52)[name = tensor<string, []>("model_bidirectional_forward_lstm_PartitionedCall_TensorArrayUnstack_TensorListFromTensor")];
            tensor<fp16, [20, 1, 576]> model_bidirectional_backward_lstm_PartitionedCall_ReverseV2_cast_fp16 = reverse(axes = model_bidirectional_backward_lstm_PartitionedCall_ReverseV2_axis, x = transpose_178)[name = tensor<string, []>("model_bidirectional_backward_lstm_PartitionedCall_ReverseV2_cast_fp16")];
            tensor<string, []> model_bidirectional_backward_lstm_PartitionedCall_ReverseV2_cast_fp16_to_fp32_dtype_0 = const()[name = tensor<string, []>("model_bidirectional_backward_lstm_PartitionedCall_ReverseV2_cast_fp16_to_fp32_dtype_0"), val = tensor<string, []>("fp32")];
            tensor<int32, []> model_bidirectional_forward_lstm_PartitionedCall_strided_slice = const()[name = tensor<string, []>("model_bidirectional_forward_lstm_PartitionedCall_strided_slice"), val = tensor<int32, []>(20)];
            tensor<int32, []> model_bidirectional_backward_lstm_PartitionedCall_strided_slice = const()[name = tensor<string, []>("model_bidirectional_backward_lstm_PartitionedCall_strided_slice"), val = tensor<int32, []>(20)];
            tensor<int32, []> slice_by_index_1 = const()[name = tensor<string, []>("slice_by_index_1"), val = tensor<int32, []>(20)];
            tensor<string, []> tf_make_list_1_dtype_0 = const()[name = tensor<string, []>("tf_make_list_1_dtype_0"), val = tensor<string, []>("fp32")];
            tensor<bool, []> tf_make_list_1_dynamic_length_0 = const()[name = tensor<string, []>("tf_make_list_1_dynamic_length_0"), val = tensor<bool, []>(true)];
            tensor<int32, []> tf_make_list_1_elem_shape0_0 = const()[name = tensor<string, []>("tf_make_list_1_elem_shape0_0"), val = tensor<int32, []>(1)];
            tensor<int32, []> tf_make_list_1_elem_shape1_0 = const()[name = tensor<string, []>("tf_make_list_1_elem_shape1_0"), val = tensor<int32, []>(576)];
            list<tensor<fp32, [1, 576]>, 20> tf_make_list_1 = make_list(dtype = tf_make_list_1_dtype_0, dynamic_length = tf_make_list_1_dynamic_length_0, elem_shape = (tf_make_list_1_elem_shape0_0, tf_make_list_1_elem_shape1_0), init_length = slice_by_index_1)[name = tensor<string, []>("tf_make_list_1")];
            tensor<int32, [20]> range_1d_1 = const()[name = tensor<string, []>("range_1d_1"), val = tensor<int32, [20]>([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19])];
            tensor<fp32, [20, 1, 576]> cast_51 = cast(dtype = model_bidirectional_backward_lstm_PartitionedCall_ReverseV2_cast_fp16_to_fp32_dtype_0, x = model_bidirectional_backward_lstm_PartitionedCall_ReverseV2_cast_fp16)[name = tensor<string, []>("cast_13")];
            list<tensor<fp32, [1, 576]>, 20> model_bidirectional_backward_lstm_PartitionedCall_TensorArrayUnstack_TensorListFromTensor = list_scatter(indices = range_1d_1, ls = tf_make_list_1, value = cast_51)[name = tensor<string, []>("model_bidirectional_backward_lstm_PartitionedCall_TensorArrayUnstack_TensorListFromTensor")];
            tensor<fp32, [1, 64]> model_bidirectional_forward_lstm_zeros = const()[name = tensor<string, []>("model_bidirectional_forward_lstm_zeros"), val = tensor<fp32, [1, 64]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(1009792)))];
            tensor<fp32, [1, 64]> model_bidirectional_forward_lstm_zeros_1 = const()[name = tensor<string, []>("model_bidirectional_forward_lstm_zeros_1"), val = tensor<fp32, [1, 64]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(1010112)))];
            tensor<fp32, [1, 64]> model_bidirectional_backward_lstm_zeros = const()[name = tensor<string, []>("model_bidirectional_backward_lstm_zeros"), val = tensor<fp32, [1, 64]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(1010432)))];
            tensor<fp32, [1, 64]> model_bidirectional_backward_lstm_zeros_1 = const()[name = tensor<string, []>("model_bidirectional_backward_lstm_zeros_1"), val = tensor<fp32, [1, 64]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(1010752)))];
            tensor<int32, []> model_bidirectional_forward_lstm_PartitionedCall_while_0, list<tensor<fp32, [1, 64]>, ?> model_bidirectional_forward_lstm_PartitionedCall_while_1, tensor<fp32, [1, 64]> model_bidirectional_forward_lstm_PartitionedCall_while_2, tensor<fp32, [1, 64]> model_bidirectional_forward_lstm_PartitionedCall_while_3 = while_loop(loop_vars = (model_bidirectional_forward_lstm_PartitionedCall_time, model_bidirectional_forward_lstm_PartitionedCall_TensorArrayV2_1, model_bidirectional_forward_lstm_zeros, model_bidirectional_forward_lstm_zeros_1))[name = tensor<string, []>("model_bidirectional_forward_lstm_PartitionedCall_while_renamed")]
                (tensor<int32, []> model_bidirectional_forward_lstm_PartitionedCall_time_x0_1_1, list<tensor<fp32, [1, 64]>, ?> model_bidirectional_forward_lstm_PartitionedCall_TensorArrayV2_1_x0, tensor<fp32, [1, 64]> model_bidirectional_forward_lstm_zeros_x0_1_1, tensor<fp32, [1, 64]> model_bidirectional_forward_lstm_zeros_1_x0_1_1) {
                    tensor<bool, []> model_bidirectional_forward_lstm_PartitionedCall_while_while_cond_19230_while_Less = less(x = model_bidirectional_forward_lstm_PartitionedCall_time_x0_1_1, y = model_bidirectional_forward_lstm_PartitionedCall_strided_slice)[name = tensor<string, []>("model_bidirectional_forward_lstm_PartitionedCall_while_while_cond_19230_while_Less")];
                } -> (model_bidirectional_forward_lstm_PartitionedCall_while_while_cond_19230_while_Less)
                (tensor<int32, []> model_bidirectional_forward_lstm_PartitionedCall_time_x0_1_1_1, list<tensor<fp32, [1, 64]>, ?> model_bidirectional_forward_lstm_PartitionedCall_TensorArrayV2_1_x0_1, tensor<fp32, [1, 64]> model_bidirectional_forward_lstm_zeros_x0_1_1_1, tensor<fp32, [1, 64]> model_bidirectional_forward_lstm_zeros_1_x0_1_1_1) {
                    tensor<int32, []> model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_split_split_dim = const()[name = tensor<string, []>("model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_split_split_dim"), val = tensor<int32, []>(1)];
                    tensor<int32, []> model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_TensorArrayV2Write_TensorListSetItem_index = const()[name = tensor<string, []>("model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_TensorArrayV2Write_TensorListSetItem_index"), val = tensor<int32, []>(0)];
                    tensor<int32, []> model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_add_2_y = const()[name = tensor<string, []>("model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_add_2_y"), val = tensor<int32, []>(1)];
                    tensor<int32, []> model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_add_2 = add(x = model_bidirectional_forward_lstm_PartitionedCall_time_x0_1_1_1, y = model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_add_2_y)[name = tensor<string, []>("model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_add_2")];
                    tensor<fp32, [1, 576]> model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_TensorArrayV2Read_TensorListGetItem = list_read(index = model_bidirectional_forward_lstm_PartitionedCall_time_x0_1_1_1, ls = model_bidirectional_forward_lstm_PartitionedCall_TensorArrayUnstack_TensorListFromTensor)[name = tensor<string, []>("model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_TensorArrayV2Read_TensorListGetItem")];
                    tensor<bool, []> model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_MatMul_1_transpose_x_1 = const()[name = tensor<string, []>("model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_MatMul_1_transpose_x_1"), val = tensor<bool, []>(false)];
                    tensor<bool, []> model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_MatMul_1_transpose_y_1 = const()[name = tensor<string, []>("model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_MatMul_1_transpose_y_1"), val = tensor<bool, []>(false)];
                    tensor<string, []> model_bidirectional_forward_lstm_zeros_x0_to_fp16_dtype_0 = const()[name = tensor<string, []>("model_bidirectional_forward_lstm_zeros_x0_to_fp16_dtype_0"), val = tensor<string, []>("fp16")];
                    tensor<fp16, [64, 256]> Func_model_bidirectional_forward_lstm_PartitionedCall_input__4_to_fp16_quantized = constexpr_affine_dequantize()[axis = tensor<int32, []>(1), name = tensor<string, []>("Func_model_bidirectional_forward_lstm_PartitionedCall_input__4_to_fp16_quantized"), quantized_data = tensor<int8, [64, 256]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(1011072))), scale = tensor<fp16, [256]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(1027840))), zero_point = tensor<int8, [256]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(1027520)))];
                    tensor<fp16, [1, 64]> cast_50 = cast(dtype = model_bidirectional_forward_lstm_zeros_x0_to_fp16_dtype_0, x = model_bidirectional_forward_lstm_zeros_x0_1_1_1)[name = tensor<string, []>("cast_12")];
                    tensor<fp16, [1, 256]> model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_MatMul_1_cast_fp16 = matmul(transpose_x = model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_MatMul_1_transpose_x_1, transpose_y = model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_MatMul_1_transpose_y_1, x = cast_50, y = Func_model_bidirectional_forward_lstm_PartitionedCall_input__4_to_fp16_quantized)[name = tensor<string, []>("model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_MatMul_1_cast_fp16")];
                    tensor<bool, []> model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_MatMul_transpose_x_1 = const()[name = tensor<string, []>("model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_MatMul_transpose_x_1"), val = tensor<bool, []>(false)];
                    tensor<bool, []> model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_MatMul_transpose_y_1 = const()[name = tensor<string, []>("model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_MatMul_transpose_y_1"), val = tensor<bool, []>(false)];
                    tensor<string, []> model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_TensorArrayV2Read_TensorListGetItem_to_fp16_dtype_0 = const()[name = tensor<string, []>("model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_TensorArrayV2Read_TensorListGetItem_to_fp16_dtype_0"), val = tensor<string, []>("fp16")];
                    tensor<fp16, [576, 256]> Func_model_bidirectional_forward_lstm_PartitionedCall_input__3_to_fp16_quantized = constexpr_affine_dequantize()[axis = tensor<int32, []>(1), name = tensor<string, []>("Func_model_bidirectional_forward_lstm_PartitionedCall_input__3_to_fp16_quantized"), quantized_data = tensor<int8, [576, 256]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(1028416))), scale = tensor<fp16, [256]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(1175936))), zero_point = tensor<int8, [256]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(1027520)))];
                    tensor<fp16, [1, 576]> cast_49 = cast(dtype = model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_TensorArrayV2Read_TensorListGetItem_to_fp16_dtype_0, x = model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_TensorArrayV2Read_TensorListGetItem)[name = tensor<string, []>("cast_11")];
                    tensor<fp16, [1, 256]> model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_MatMul_cast_fp16 = matmul(transpose_x = model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_MatMul_transpose_x_1, transpose_y = model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_MatMul_transpose_y_1, x = cast_49, y = Func_model_bidirectional_forward_lstm_PartitionedCall_input__3_to_fp16_quantized)[name = tensor<string, []>("model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_MatMul_cast_fp16")];
                    tensor<fp16, [1, 256]> model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_add_cast_fp16 = add(x = model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_MatMul_cast_fp16, y = model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_MatMul_1_cast_fp16)[name = tensor<string, []>("model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_add_cast_fp16")];
                    tensor<fp16, [256]> Func_model_bidirectional_forward_lstm_PartitionedCall_input__5_to_fp16 = const()[name = tensor<string, []>("Func_model_bidirectional_forward_lstm_PartitionedCall_input__5_to_fp16"), val = tensor<fp16, [256]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(1176512)))];
                    tensor<fp16, [1, 256]> model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_BiasAdd_cast_fp16 = add(x = model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_add_cast_fp16, y = Func_model_bidirectional_forward_lstm_PartitionedCall_input__5_to_fp16)[name = tensor<string, []>("model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_BiasAdd_cast_fp16")];
                    tensor<int32, []> model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_split_num_splits_1 = const()[name = tensor<string, []>("model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_split_num_splits_1"), val = tensor<int32, []>(4)];
                    tensor<fp16, [1, 64]> model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_split_cast_fp16_0, tensor<fp16, [1, 64]> model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_split_cast_fp16_1, tensor<fp16, [1, 64]> model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_split_cast_fp16_2, tensor<fp16, [1, 64]> model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_split_cast_fp16_3 = split(axis = model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_split_split_dim, num_splits = model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_split_num_splits_1, x = model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_BiasAdd_cast_fp16)[name = tensor<string, []>("model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_split_cast_fp16")];
                    tensor<fp16, [1, 64]> model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_Sigmoid_cast_fp16 = sigmoid(x = model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_split_cast_fp16_0)[name = tensor<string, []>("model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_Sigmoid_cast_fp16")];
                    tensor<fp16, [1, 64]> model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_Sigmoid_1_cast_fp16 = sigmoid(x = model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_split_cast_fp16_1)[name = tensor<string, []>("model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_Sigmoid_1_cast_fp16")];
                    tensor<fp16, [1, 64]> model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_Tanh_cast_fp16 = tanh(x = model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_split_cast_fp16_2)[name = tensor<string, []>("model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_Tanh_cast_fp16")];
                    tensor<fp16, [1, 64]> model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_Sigmoid_2_cast_fp16 = sigmoid(x = model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_split_cast_fp16_3)[name = tensor<string, []>("model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_Sigmoid_2_cast_fp16")];
                    tensor<string, []> model_bidirectional_forward_lstm_zeros_1_x0_to_fp16_dtype_0 = const()[name = tensor<string, []>("model_bidirectional_forward_lstm_zeros_1_x0_to_fp16_dtype_0"), val = tensor<string, []>("fp16")];
                    tensor<fp16, [1, 64]> cast_48 = cast(dtype = model_bidirectional_forward_lstm_zeros_1_x0_to_fp16_dtype_0, x = model_bidirectional_forward_lstm_zeros_1_x0_1_1_1)[name = tensor<string, []>("cast_10")];
                    tensor<fp16, [1, 64]> model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_mul_cast_fp16 = mul(x = model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_Sigmoid_1_cast_fp16, y = cast_48)[name = tensor<string, []>("model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_mul_cast_fp16")];
                    tensor<fp16, [1, 64]> model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_mul_1_cast_fp16 = mul(x = model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_Sigmoid_cast_fp16, y = model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_Tanh_cast_fp16)[name = tensor<string, []>("model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_mul_1_cast_fp16")];
                    tensor<fp16, [1, 64]> model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_add_1_cast_fp16 = add(x = model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_mul_cast_fp16, y = model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_mul_1_cast_fp16)[name = tensor<string, []>("model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_add_1_cast_fp16")];
                    tensor<string, []> model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_add_1_cast_fp16_to_fp32_dtype_0 = const()[name = tensor<string, []>("model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_add_1_cast_fp16_to_fp32_dtype_0"), val = tensor<string, []>("fp32")];
                    tensor<fp16, [1, 64]> model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_Tanh_1_cast_fp16 = tanh(x = model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_add_1_cast_fp16)[name = tensor<string, []>("model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_Tanh_1_cast_fp16")];
                    tensor<fp16, [1, 64]> model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_mul_2_cast_fp16 = mul(x = model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_Sigmoid_2_cast_fp16, y = model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_Tanh_1_cast_fp16)[name = tensor<string, []>("model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_mul_2_cast_fp16")];
                    tensor<string, []> model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_mul_2_cast_fp16_to_fp32_dtype_0 = const()[name = tensor<string, []>("model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_mul_2_cast_fp16_to_fp32_dtype_0"), val = tensor<string, []>("fp32")];
                    tensor<fp32, [1, 64]> cast_46 = cast(dtype = model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_mul_2_cast_fp16_to_fp32_dtype_0, x = model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_mul_2_cast_fp16)[name = tensor<string, []>("cast_9")];
                    list<tensor<fp32, [1, 64]>, ?> model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_TensorArrayV2Write_TensorListSetItem = list_write(index = model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_TensorArrayV2Write_TensorListSetItem_index, ls = model_bidirectional_forward_lstm_PartitionedCall_TensorArrayV2_1_x0_1, value = cast_46)[name = tensor<string, []>("model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_TensorArrayV2Write_TensorListSetItem")];
                    tensor<fp32, [1, 64]> cast_47 = cast(dtype = model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_add_1_cast_fp16_to_fp32_dtype_0, x = model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_add_1_cast_fp16)[name = tensor<string, []>("cast_8")];
                } -> (model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_add_2, model_bidirectional_forward_lstm_PartitionedCall_while_while_body_19231_while_TensorArrayV2Write_TensorListSetItem, cast_46, cast_47);
            tensor<int32, []> model_bidirectional_backward_lstm_PartitionedCall_while_0, list<tensor<fp32, [1, 64]>, ?> model_bidirectional_backward_lstm_PartitionedCall_while_1, tensor<fp32, [1, 64]> model_bidirectional_backward_lstm_PartitionedCall_while_2, tensor<fp32, [1, 64]> model_bidirectional_backward_lstm_PartitionedCall_while_3 = while_loop(loop_vars = (model_bidirectional_backward_lstm_PartitionedCall_time, model_bidirectional_backward_lstm_PartitionedCall_TensorArrayV2_1, model_bidirectional_backward_lstm_zeros, model_bidirectional_backward_lstm_zeros_1))[name = tensor<string, []>("model_bidirectional_backward_lstm_PartitionedCall_while_renamed")]
                (tensor<int32, []> model_bidirectional_backward_lstm_PartitionedCall_time_x0_1_1, list<tensor<fp32, [1, 64]>, ?> model_bidirectional_backward_lstm_PartitionedCall_TensorArrayV2_1_x0, tensor<fp32, [1, 64]> model_bidirectional_backward_lstm_zeros_x0_1_1, tensor<fp32, [1, 64]> model_bidirectional_backward_lstm_zeros_1_x0_1_1) {
                    tensor<bool, []> model_bidirectional_backward_lstm_PartitionedCall_while_while_cond_19657_while_Less = less(x = model_bidirectional_backward_lstm_PartitionedCall_time_x0_1_1, y = model_bidirectional_backward_lstm_PartitionedCall_strided_slice)[name = tensor<string, []>("model_bidirectional_backward_lstm_PartitionedCall_while_while_cond_19657_while_Less")];
                } -> (model_bidirectional_backward_lstm_PartitionedCall_while_while_cond_19657_while_Less)
                (tensor<int32, []> model_bidirectional_backward_lstm_PartitionedCall_time_x0_1_1_1, list<tensor<fp32, [1, 64]>, ?> model_bidirectional_backward_lstm_PartitionedCall_TensorArrayV2_1_x0_1, tensor<fp32, [1, 64]> model_bidirectional_backward_lstm_zeros_x0_1_1_1, tensor<fp32, [1, 64]> model_bidirectional_backward_lstm_zeros_1_x0_1_1_1) {
                    tensor<int32, []> model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_split_split_dim = const()[name = tensor<string, []>("model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_split_split_dim"), val = tensor<int32, []>(1)];
                    tensor<int32, []> model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_TensorArrayV2Write_TensorListSetItem_index = const()[name = tensor<string, []>("model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_TensorArrayV2Write_TensorListSetItem_index"), val = tensor<int32, []>(0)];
                    tensor<int32, []> model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_add_2_y = const()[name = tensor<string, []>("model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_add_2_y"), val = tensor<int32, []>(1)];
                    tensor<int32, []> model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_add_2 = add(x = model_bidirectional_backward_lstm_PartitionedCall_time_x0_1_1_1, y = model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_add_2_y)[name = tensor<string, []>("model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_add_2")];
                    tensor<fp32, [1, 576]> model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_TensorArrayV2Read_TensorListGetItem = list_read(index = model_bidirectional_backward_lstm_PartitionedCall_time_x0_1_1_1, ls = model_bidirectional_backward_lstm_PartitionedCall_TensorArrayUnstack_TensorListFromTensor)[name = tensor<string, []>("model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_TensorArrayV2Read_TensorListGetItem")];
                    tensor<bool, []> model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_MatMul_1_transpose_x_1 = const()[name = tensor<string, []>("model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_MatMul_1_transpose_x_1"), val = tensor<bool, []>(false)];
                    tensor<bool, []> model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_MatMul_1_transpose_y_1 = const()[name = tensor<string, []>("model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_MatMul_1_transpose_y_1"), val = tensor<bool, []>(false)];
                    tensor<string, []> model_bidirectional_backward_lstm_zeros_x0_to_fp16_dtype_0 = const()[name = tensor<string, []>("model_bidirectional_backward_lstm_zeros_x0_to_fp16_dtype_0"), val = tensor<string, []>("fp16")];
                    tensor<fp16, [64, 256]> Func_model_bidirectional_backward_lstm_PartitionedCall_input__15_to_fp16_quantized = constexpr_affine_dequantize()[axis = tensor<int32, []>(1), name = tensor<string, []>("Func_model_bidirectional_backward_lstm_PartitionedCall_input__15_to_fp16_quantized"), quantized_data = tensor<int8, [64, 256]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(1177088))), scale = tensor<fp16, [256]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(1193856))), zero_point = tensor<int8, [256]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(1193536)))];
                    tensor<fp16, [1, 64]> cast_45 = cast(dtype = model_bidirectional_backward_lstm_zeros_x0_to_fp16_dtype_0, x = model_bidirectional_backward_lstm_zeros_x0_1_1_1)[name = tensor<string, []>("cast_7")];
                    tensor<fp16, [1, 256]> model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_MatMul_1_cast_fp16 = matmul(transpose_x = model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_MatMul_1_transpose_x_1, transpose_y = model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_MatMul_1_transpose_y_1, x = cast_45, y = Func_model_bidirectional_backward_lstm_PartitionedCall_input__15_to_fp16_quantized)[name = tensor<string, []>("model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_MatMul_1_cast_fp16")];
                    tensor<bool, []> model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_MatMul_transpose_x_1 = const()[name = tensor<string, []>("model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_MatMul_transpose_x_1"), val = tensor<bool, []>(false)];
                    tensor<bool, []> model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_MatMul_transpose_y_1 = const()[name = tensor<string, []>("model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_MatMul_transpose_y_1"), val = tensor<bool, []>(false)];
                    tensor<string, []> model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_TensorArrayV2Read_TensorListGetItem_to_fp16_dtype_0 = const()[name = tensor<string, []>("model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_TensorArrayV2Read_TensorListGetItem_to_fp16_dtype_0"), val = tensor<string, []>("fp16")];
                    tensor<fp16, [576, 256]> Func_model_bidirectional_backward_lstm_PartitionedCall_input__14_to_fp16_quantized = constexpr_affine_dequantize()[axis = tensor<int32, []>(1), name = tensor<string, []>("Func_model_bidirectional_backward_lstm_PartitionedCall_input__14_to_fp16_quantized"), quantized_data = tensor<int8, [576, 256]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(1194432))), scale = tensor<fp16, [256]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(1341952))), zero_point = tensor<int8, [256]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(1193536)))];
                    tensor<fp16, [1, 576]> cast_44 = cast(dtype = model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_TensorArrayV2Read_TensorListGetItem_to_fp16_dtype_0, x = model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_TensorArrayV2Read_TensorListGetItem)[name = tensor<string, []>("cast_6")];
                    tensor<fp16, [1, 256]> model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_MatMul_cast_fp16 = matmul(transpose_x = model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_MatMul_transpose_x_1, transpose_y = model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_MatMul_transpose_y_1, x = cast_44, y = Func_model_bidirectional_backward_lstm_PartitionedCall_input__14_to_fp16_quantized)[name = tensor<string, []>("model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_MatMul_cast_fp16")];
                    tensor<fp16, [1, 256]> model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_add_cast_fp16 = add(x = model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_MatMul_cast_fp16, y = model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_MatMul_1_cast_fp16)[name = tensor<string, []>("model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_add_cast_fp16")];
                    tensor<fp16, [256]> Func_model_bidirectional_backward_lstm_PartitionedCall_input__16_to_fp16 = const()[name = tensor<string, []>("Func_model_bidirectional_backward_lstm_PartitionedCall_input__16_to_fp16"), val = tensor<fp16, [256]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(1342528)))];
                    tensor<fp16, [1, 256]> model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_BiasAdd_cast_fp16 = add(x = model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_add_cast_fp16, y = Func_model_bidirectional_backward_lstm_PartitionedCall_input__16_to_fp16)[name = tensor<string, []>("model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_BiasAdd_cast_fp16")];
                    tensor<int32, []> model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_split_num_splits_1 = const()[name = tensor<string, []>("model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_split_num_splits_1"), val = tensor<int32, []>(4)];
                    tensor<fp16, [1, 64]> model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_split_cast_fp16_0, tensor<fp16, [1, 64]> model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_split_cast_fp16_1, tensor<fp16, [1, 64]> model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_split_cast_fp16_2, tensor<fp16, [1, 64]> model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_split_cast_fp16_3 = split(axis = model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_split_split_dim, num_splits = model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_split_num_splits_1, x = model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_BiasAdd_cast_fp16)[name = tensor<string, []>("model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_split_cast_fp16")];
                    tensor<fp16, [1, 64]> model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_Sigmoid_cast_fp16 = sigmoid(x = model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_split_cast_fp16_0)[name = tensor<string, []>("model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_Sigmoid_cast_fp16")];
                    tensor<fp16, [1, 64]> model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_Sigmoid_1_cast_fp16 = sigmoid(x = model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_split_cast_fp16_1)[name = tensor<string, []>("model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_Sigmoid_1_cast_fp16")];
                    tensor<fp16, [1, 64]> model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_Tanh_cast_fp16 = tanh(x = model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_split_cast_fp16_2)[name = tensor<string, []>("model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_Tanh_cast_fp16")];
                    tensor<fp16, [1, 64]> model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_Sigmoid_2_cast_fp16 = sigmoid(x = model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_split_cast_fp16_3)[name = tensor<string, []>("model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_Sigmoid_2_cast_fp16")];
                    tensor<string, []> model_bidirectional_backward_lstm_zeros_1_x0_to_fp16_dtype_0 = const()[name = tensor<string, []>("model_bidirectional_backward_lstm_zeros_1_x0_to_fp16_dtype_0"), val = tensor<string, []>("fp16")];
                    tensor<fp16, [1, 64]> cast_43 = cast(dtype = model_bidirectional_backward_lstm_zeros_1_x0_to_fp16_dtype_0, x = model_bidirectional_backward_lstm_zeros_1_x0_1_1_1)[name = tensor<string, []>("cast_5")];
                    tensor<fp16, [1, 64]> model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_mul_cast_fp16 = mul(x = model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_Sigmoid_1_cast_fp16, y = cast_43)[name = tensor<string, []>("model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_mul_cast_fp16")];
                    tensor<fp16, [1, 64]> model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_mul_1_cast_fp16 = mul(x = model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_Sigmoid_cast_fp16, y = model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_Tanh_cast_fp16)[name = tensor<string, []>("model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_mul_1_cast_fp16")];
                    tensor<fp16, [1, 64]> model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_add_1_cast_fp16 = add(x = model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_mul_cast_fp16, y = model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_mul_1_cast_fp16)[name = tensor<string, []>("model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_add_1_cast_fp16")];
                    tensor<string, []> model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_add_1_cast_fp16_to_fp32_dtype_0 = const()[name = tensor<string, []>("model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_add_1_cast_fp16_to_fp32_dtype_0"), val = tensor<string, []>("fp32")];
                    tensor<fp16, [1, 64]> model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_Tanh_1_cast_fp16 = tanh(x = model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_add_1_cast_fp16)[name = tensor<string, []>("model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_Tanh_1_cast_fp16")];
                    tensor<fp16, [1, 64]> model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_mul_2_cast_fp16 = mul(x = model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_Sigmoid_2_cast_fp16, y = model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_Tanh_1_cast_fp16)[name = tensor<string, []>("model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_mul_2_cast_fp16")];
                    tensor<string, []> model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_mul_2_cast_fp16_to_fp32_dtype_0 = const()[name = tensor<string, []>("model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_mul_2_cast_fp16_to_fp32_dtype_0"), val = tensor<string, []>("fp32")];
                    tensor<fp32, [1, 64]> cast_41 = cast(dtype = model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_mul_2_cast_fp16_to_fp32_dtype_0, x = model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_mul_2_cast_fp16)[name = tensor<string, []>("cast_4")];
                    list<tensor<fp32, [1, 64]>, ?> model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_TensorArrayV2Write_TensorListSetItem = list_write(index = model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_TensorArrayV2Write_TensorListSetItem_index, ls = model_bidirectional_backward_lstm_PartitionedCall_TensorArrayV2_1_x0_1, value = cast_41)[name = tensor<string, []>("model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_TensorArrayV2Write_TensorListSetItem")];
                    tensor<fp32, [1, 64]> cast_42 = cast(dtype = model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_add_1_cast_fp16_to_fp32_dtype_0, x = model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_add_1_cast_fp16)[name = tensor<string, []>("cast_3")];
                } -> (model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_add_2, model_bidirectional_backward_lstm_PartitionedCall_while_while_body_19658_while_TensorArrayV2Write_TensorListSetItem, cast_41, cast_42);
            tensor<int32, [1]> range_1d_2 = const()[name = tensor<string, []>("range_1d_2"), val = tensor<int32, [1]>([0])];
            tensor<fp32, [1, 1, 64]> model_bidirectional_forward_lstm_PartitionedCall_TensorArrayV2Stack_TensorListStack = list_gather(indices = range_1d_2, ls = model_bidirectional_forward_lstm_PartitionedCall_while_1)[name = tensor<string, []>("model_bidirectional_forward_lstm_PartitionedCall_TensorArrayV2Stack_TensorListStack")];
            tensor<int32, [1]> range_1d_3 = const()[name = tensor<string, []>("range_1d_3"), val = tensor<int32, [1]>([0])];
            tensor<fp32, [1, 1, 64]> model_bidirectional_backward_lstm_PartitionedCall_TensorArrayV2Stack_TensorListStack = list_gather(indices = range_1d_3, ls = model_bidirectional_backward_lstm_PartitionedCall_while_1)[name = tensor<string, []>("model_bidirectional_backward_lstm_PartitionedCall_TensorArrayV2Stack_TensorListStack")];
            tensor<int32, [3]> model_bidirectional_forward_lstm_PartitionedCall_strided_slice_2_begin_0 = const()[name = tensor<string, []>("model_bidirectional_forward_lstm_PartitionedCall_strided_slice_2_begin_0"), val = tensor<int32, [3]>([-1, 0, 0])];
            tensor<int32, [3]> model_bidirectional_forward_lstm_PartitionedCall_strided_slice_2_end_0 = const()[name = tensor<string, []>("model_bidirectional_forward_lstm_PartitionedCall_strided_slice_2_end_0"), val = tensor<int32, [3]>([0, 0, 0])];
            tensor<int32, [3]> model_bidirectional_forward_lstm_PartitionedCall_strided_slice_2_stride_0 = const()[name = tensor<string, []>("model_bidirectional_forward_lstm_PartitionedCall_strided_slice_2_stride_0"), val = tensor<int32, [3]>([1, 1, 1])];
            tensor<bool, [3]> model_bidirectional_forward_lstm_PartitionedCall_strided_slice_2_begin_mask_0 = const()[name = tensor<string, []>("model_bidirectional_forward_lstm_PartitionedCall_strided_slice_2_begin_mask_0"), val = tensor<bool, [3]>([false, true, true])];
            tensor<bool, [3]> model_bidirectional_forward_lstm_PartitionedCall_strided_slice_2_end_mask_0 = const()[name = tensor<string, []>("model_bidirectional_forward_lstm_PartitionedCall_strided_slice_2_end_mask_0"), val = tensor<bool, [3]>([false, true, true])];
            tensor<bool, [3]> model_bidirectional_forward_lstm_PartitionedCall_strided_slice_2_squeeze_mask_0 = const()[name = tensor<string, []>("model_bidirectional_forward_lstm_PartitionedCall_strided_slice_2_squeeze_mask_0"), val = tensor<bool, [3]>([true, false, false])];
            tensor<string, []> model_bidirectional_forward_lstm_PartitionedCall_TensorArrayV2Stack_TensorListStack_to_fp16_dtype_0 = const()[name = tensor<string, []>("model_bidirectional_forward_lstm_PartitionedCall_TensorArrayV2Stack_TensorListStack_to_fp16_dtype_0"), val = tensor<string, []>("fp16")];
            tensor<fp16, [1, 1, 64]> cast_40 = cast(dtype = model_bidirectional_forward_lstm_PartitionedCall_TensorArrayV2Stack_TensorListStack_to_fp16_dtype_0, x = model_bidirectional_forward_lstm_PartitionedCall_TensorArrayV2Stack_TensorListStack)[name = tensor<string, []>("cast_2")];
            tensor<fp16, [1, 64]> model_bidirectional_forward_lstm_PartitionedCall_strided_slice_2_cast_fp16 = slice_by_index(begin = model_bidirectional_forward_lstm_PartitionedCall_strided_slice_2_begin_0, begin_mask = model_bidirectional_forward_lstm_PartitionedCall_strided_slice_2_begin_mask_0, end = model_bidirectional_forward_lstm_PartitionedCall_strided_slice_2_end_0, end_mask = model_bidirectional_forward_lstm_PartitionedCall_strided_slice_2_end_mask_0, squeeze_mask = model_bidirectional_forward_lstm_PartitionedCall_strided_slice_2_squeeze_mask_0, stride = model_bidirectional_forward_lstm_PartitionedCall_strided_slice_2_stride_0, x = cast_40)[name = tensor<string, []>("model_bidirectional_forward_lstm_PartitionedCall_strided_slice_2_cast_fp16")];
            tensor<int32, [3]> model_bidirectional_backward_lstm_PartitionedCall_strided_slice_2_begin_0 = const()[name = tensor<string, []>("model_bidirectional_backward_lstm_PartitionedCall_strided_slice_2_begin_0"), val = tensor<int32, [3]>([-1, 0, 0])];
            tensor<int32, [3]> model_bidirectional_backward_lstm_PartitionedCall_strided_slice_2_end_0 = const()[name = tensor<string, []>("model_bidirectional_backward_lstm_PartitionedCall_strided_slice_2_end_0"), val = tensor<int32, [3]>([0, 0, 0])];
            tensor<int32, [3]> model_bidirectional_backward_lstm_PartitionedCall_strided_slice_2_stride_0 = const()[name = tensor<string, []>("model_bidirectional_backward_lstm_PartitionedCall_strided_slice_2_stride_0"), val = tensor<int32, [3]>([1, 1, 1])];
            tensor<bool, [3]> model_bidirectional_backward_lstm_PartitionedCall_strided_slice_2_begin_mask_0 = const()[name = tensor<string, []>("model_bidirectional_backward_lstm_PartitionedCall_strided_slice_2_begin_mask_0"), val = tensor<bool, [3]>([false, true, true])];
            tensor<bool, [3]> model_bidirectional_backward_lstm_PartitionedCall_strided_slice_2_end_mask_0 = const()[name = tensor<string, []>("model_bidirectional_backward_lstm_PartitionedCall_strided_slice_2_end_mask_0"), val = tensor<bool, [3]>([false, true, true])];
            tensor<bool, [3]> model_bidirectional_backward_lstm_PartitionedCall_strided_slice_2_squeeze_mask_0 = const()[name = tensor<string, []>("model_bidirectional_backward_lstm_PartitionedCall_strided_slice_2_squeeze_mask_0"), val = tensor<bool, [3]>([true, false, false])];
            tensor<string, []> model_bidirectional_backward_lstm_PartitionedCall_TensorArrayV2Stack_TensorListStack_to_fp16_dtype_0 = const()[name = tensor<string, []>("model_bidirectional_backward_lstm_PartitionedCall_TensorArrayV2Stack_TensorListStack_to_fp16_dtype_0"), val = tensor<string, []>("fp16")];
            tensor<fp16, [1, 1, 64]> cast_39 = cast(dtype = model_bidirectional_backward_lstm_PartitionedCall_TensorArrayV2Stack_TensorListStack_to_fp16_dtype_0, x = model_bidirectional_backward_lstm_PartitionedCall_TensorArrayV2Stack_TensorListStack)[name = tensor<string, []>("cast_1")];
            tensor<fp16, [1, 64]> model_bidirectional_backward_lstm_PartitionedCall_strided_slice_2_cast_fp16 = slice_by_index(begin = model_bidirectional_backward_lstm_PartitionedCall_strided_slice_2_begin_0, begin_mask = model_bidirectional_backward_lstm_PartitionedCall_strided_slice_2_begin_mask_0, end = model_bidirectional_backward_lstm_PartitionedCall_strided_slice_2_end_0, end_mask = model_bidirectional_backward_lstm_PartitionedCall_strided_slice_2_end_mask_0, squeeze_mask = model_bidirectional_backward_lstm_PartitionedCall_strided_slice_2_squeeze_mask_0, stride = model_bidirectional_backward_lstm_PartitionedCall_strided_slice_2_stride_0, x = cast_39)[name = tensor<string, []>("model_bidirectional_backward_lstm_PartitionedCall_strided_slice_2_cast_fp16")];
            tensor<bool, []> model_bidirectional_concat_interleave_0 = const()[name = tensor<string, []>("model_bidirectional_concat_interleave_0"), val = tensor<bool, []>(false)];
            tensor<fp16, [1, 128]> model_bidirectional_concat_cast_fp16 = concat(axis = model_bidirectional_concat_axis, interleave = model_bidirectional_concat_interleave_0, values = (model_bidirectional_forward_lstm_PartitionedCall_strided_slice_2_cast_fp16, model_bidirectional_backward_lstm_PartitionedCall_strided_slice_2_cast_fp16))[name = tensor<string, []>("model_bidirectional_concat_cast_fp16")];
            tensor<fp16, [1, 128]> transpose_138_cast_fp16_to_fp32_to_fp16 = const()[name = tensor<string, []>("transpose_138_cast_fp16_to_fp32_to_fp16"), val = tensor<fp16, [1, 128]>(BLOBFILE(path = tensor<string, []>("@model_path/weights/weight.bin"), offset = tensor<uint64, []>(1343104)))];
            tensor<fp16, [1]> model_dense_BiasAdd_bias_0_to_fp16 = const()[name = tensor<string, []>("model_dense_BiasAdd_bias_0_to_fp16"), val = tensor<fp16, [1]>([0x1.7c4p-14])];
            tensor<fp16, [1, 1]> model_dense_BiasAdd_cast_fp16 = linear(bias = model_dense_BiasAdd_bias_0_to_fp16, weight = transpose_138_cast_fp16_to_fp32_to_fp16, x = model_bidirectional_concat_cast_fp16)[name = tensor<string, []>("model_dense_BiasAdd_cast_fp16")];
            tensor<fp16, [1, 1]> model_dense_Sigmoid_cast_fp16 = sigmoid(x = model_dense_BiasAdd_cast_fp16)[name = tensor<string, []>("model_dense_Sigmoid_cast_fp16")];
            tensor<string, []> model_dense_Sigmoid_cast_fp16_to_fp32_dtype_0 = const()[name = tensor<string, []>("model_dense_Sigmoid_cast_fp16_to_fp32_dtype_0"), val = tensor<string, []>("fp32")];
            tensor<fp32, [1, 1]> Identity = cast(dtype = model_dense_Sigmoid_cast_fp16_to_fp32_dtype_0, x = model_dense_Sigmoid_cast_fp16)[name = tensor<string, []>("cast_0")];
        } -> (Identity);
}